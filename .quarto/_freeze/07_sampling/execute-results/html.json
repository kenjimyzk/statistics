{
  "hash": "102e9ab82807bb8cb8b79da56744bddc",
  "result": {
    "engine": "knitr",
    "markdown": "# 第7回 標本分布 {.unnumbered}\n\n![標本分布](figure/07_sampling/infographic.png)\n\n## 今回の目標\n\n-   母集団と標本の関係を理解する。\n-   **大数の法則** と **中心極限定理** をシミュレーションで体感する。\n-   標本分布の概念を理解する。\n\n## 母集団と標本\n\n### 基本的な定義\n\n-   **母集団 (Population)**: 調査対象全体の集まり。知りたい情報を持つ全ての対象を指します（例：日本人全員の身長、ある企業の全製品）。\n-   **標本 (Sample)**: 母集団から一部を取り出したもの（例：ランダムに選んだ1000人、工場から抜き取った100個の製品）。\n\n**重要な事実**: 私たちが実際に手にするデータの多くは**標本**です。母集団全体のデータを得ることは、コストや時間の制約から現実的ではありません。\n\n### ランダム標本 (Random Sample)\n\n標本が母集団から**無作為に抽出**されたとき、これを**ランダム標本**と呼びます。\n\nランダム標本の特徴：\n- 母集団のどの要素も等しい確率で選ばれる\n- 各抽出が互いに独立である\n- 母集団を偏りなく代表する\n\n**横断面データ**（ある時点での複数の個体のデータ）は、通常ランダム標本と考えます。\n例：2024年1月に実施した1000人の消費者調査データ\n\n### 推測統計学 (Inferential Statistics)\n\n**標本から母集団の特徴を推測すること**を推測統計学といいます。\n\n- **記述統計学**：手元のデータを要約・記述する（これまで学んできたこと）\n- **推測統計学**：標本データから母集団について結論を導く（これから学ぶこと）\n\n### 確率変数としての母集団\n\n推測統計学では、母集団を**確率変数**と仮定します。\n\nなぜ確率変数として扱うのか：\n- 母集団から標本を抽出する行為は「ランダムな試行」\n- 同じ母集団から何度も標本を取れば、毎回異なる値が得られる\n- この不確実性を数学的に扱うために、確率変数の枠組みを使う\n\n### ランダム標本の数学的性質\n\nサイズ $N$ のランダム標本 $X_1, X_2, \\ldots, X_N$ は：\n\n1. **N個の母集団のコピー**と考えることができる\n2. それぞれが**独立同一分布 (i.i.d.: independent and identically distributed)** に従う確率変数\n\n**独立同一分布とは**：\n- **同一分布 (identically distributed)**: 全ての $X_i$ が同じ母集団分布に従う\n- **独立 (independent)**: 各 $X_i$ の値は互いに影響を与えない\n\n数学的には：\n$$X_1, X_2, \\ldots, X_N \\sim \\text{i.i.d.} \\quad F(\\cdot)$$\n\nここで $F(\\cdot)$ は母集団の分布を表します。\n\n**具体例**：\n- 母集団：ある会社の全従業員の年収（平均500万円、標準偏差100万円の正規分布に従うと仮定）\n- ランダム標本（N=100）：無作為に選んだ100人の年収データ $X_1, \\ldots, X_{100}$\n- 各 $X_i$ は独立に $N(500, 100^2)$ から抽出された確率変数\n\n### なぜ標本を使うのか\n\n- 母集団全体を調べるのはコストがかかる（全数調査）\n- 時間的・物理的に不可能な場合もある\n- 少数のサンプルから全体の傾向を推測できる\n\n### 母数と統計量\n\n| 用語 | 説明 | 記号 |\n|------|------|------|\n| 母平均 | 母集団の平均 | $\\mu$ |\n| 母分散 | 母集団の分散 | $\\sigma^2$ |\n| 標本平均 | 標本の平均 | $\\bar{x}$ |\n| 標本分散 | 標本の分散 | $s^2$ |\n\n### 母集団と標本のイメージ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nset.seed(1)\n\n# 母集団（例：正規分布） {.unnumbered}\npopulation <- rnorm(10000, mean = 50, sd = 10)\n\n# 標本（そこから100個ランダムに抽出） {.unnumbered}\nsample_data <- sample(population, 100)\n\n# データフレーム化 {.unnumbered}\ndf_pop <- data.frame(value = population, type = \"Population\")\ndf_samp <- data.frame(value = sample_data, type = \"Sample\")\ndf_all <- bind_rows(df_pop, df_samp)\n\n# ヒストグラムで比較（密度表示） {.unnumbered}\nggplot(df_all, aes(x = value, fill = type)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_density(alpha = 0.5) +\n  labs(title = \"母集団と標本の分布比較\", x = \"値\", y = \"密度\")\n```\n\n::: {.cell-output-display}\n![](07_sampling_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## 大数の法則 (Law of Large Numbers)\n\nサンプルサイズ（標本の大きさ）$n$ を大きくしていくと、標本平均は母平均に近づいていくという法則です。\nサイコロで確かめてみましょう。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# サイコロを振る回数を変えて、平均値の推移を見る {.unnumbered}\nset.seed(123)\nn <- 1000\ndice_rolls <- sample(1:6, n, replace = TRUE)\ncumulative_mean <- cumsum(dice_rolls) / (1:n)\n\n# データフレーム作成 {.unnumbered}\ndf <- data.frame(n = 1:n, mean = cumulative_mean)\n\n# プロット {.unnumbered}\nggplot(df, aes(x = n, y = mean)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line() +\n  geom_hline(yintercept = 3.5, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"大数の法則のシミュレーション\", y = \"標本平均\")\n```\n\n::: {.cell-output-display}\n![](07_sampling_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n回数が増えるにつれて、理論的な期待値 3.5 に近づいていく様子がわかります。\n\n## 中心極限定理 (Central Limit Theorem)\n\n母集団がどんな分布であっても、サンプルサイズ $n$ が十分に大きければ、標本平均の分布は **正規分布** に近づくという強力な定理です。\n\n一様分布（0から1の乱数）から、サイズ $n=30$ の標本を取り出し、その平均を計算する作業を1000回繰り返してみましょう。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# シミュレーション {.unnumbered}\nn_samples <- 1000\nsample_size <- 30\nmeans <- numeric(n_samples)\n\nfor (i in 1:n_samples) {\n  means[i] <- mean(runif(sample_size, min = 0, max = 1))\n}\n\n# ヒストグラム {.unnumbered}\nggplot(data.frame(means), aes(x = means)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_histogram(bins = 30, fill = \"orange\", color = \"white\") +\n  labs(title = \"標本平均の分布 (n=30)\", x = \"標本平均\")\n```\n\n::: {.cell-output-display}\n![](07_sampling_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n元の分布は平坦（一様分布）ですが、平均値の分布は釣鐘型（正規分布）になっていることが確認できます。\n\n### サンプルサイズによる変化\n\nサンプルサイズを変えて、中心極限定理の効果を確認してみましょう。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 異なるサンプルサイズでのシミュレーション\nsample_sizes <- c(5, 30, 100)\nn_samples <- 1000\n\nresults <- list()\nfor (n in sample_sizes) {\n  means <- replicate(n_samples, mean(runif(n)))\n  results[[paste0(\"n=\", n)]] <- means\n}\n\n# データフレームにまとめる\ndf_clt <- data.frame(\n  means = unlist(results),\n  sample_size = rep(paste0(\"n=\", sample_sizes), each = n_samples)\n)\n\n# サンプルサイズの順序を明示的に設定\ndf_clt$sample_size <- factor(df_clt$sample_size, levels = paste0(\"n=\", sample_sizes))\n\n# プロット\nggplot(df_clt, aes(x = means)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  facet_wrap(~sample_size, scales = \"free_y\") +\n  labs(title = \"中心極限定理: サンプルサイズによる変化\", x = \"標本平均\")\n```\n\n::: {.cell-output-display}\n![](07_sampling_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nサンプルサイズが大きくなるほど、分布が正規分布に近づき、ばらつきも小さくなることがわかります。\n\n## 標本平均の分散\n\n標本平均の分散は、母分散をサンプルサイズで割ったものになります。\n\n$$V[\\bar{X}] = \\frac{\\sigma^2}{n}$$\n\nこれは、サンプルサイズが大きいほど、標本平均のばらつきが小さくなることを示しています。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 理論値と実際の値を比較\ncat(\"母分散（一様分布）:\", 1/12, \"\\n\")\n#> 母分散（一様分布）: 0.08333333\ncat(\"標本平均の理論分散 (n=30):\", (1/12) / 30, \"\\n\")\n#> 標本平均の理論分散 (n=30): 0.002777778\ncat(\"シミュレーションでの分散:\", var(results[[\"n=30\"]]), \"\\n\")\n#> シミュレーションでの分散: 0.00278787\n```\n:::\n\n\n## 標準誤差 (Standard Error)\n\n標本平均の標準偏差を**標準誤差**といいます。\n\n$$SE = \\frac{\\sigma}{\\sqrt{n}}$$\n\n標準誤差は、推定の精度を表す重要な指標です。\n\n## 課題\n\n1.  中心極限定理のシミュレーションで、`sample_size` を 5 に減らして実行してみてください。ヒストグラムの形はどう変わりますか？\n\n## 練習問題\n\n### 練習1: 大数の法則\nコインを投げるシミュレーションを行い、大数の法則を確認してください：\n1. `sample(c(0, 1), 1000, replace = TRUE)` でコイン投げをシミュレート\n2. 累積の表の割合を計算し、グラフにプロット\n3. 回数が増えると0.5に近づくことを確認\n\n### 練習2: 中心極限定理の応用\n指数分布（右に歪んだ分布）を使って中心極限定理を確認してください：\n1. `rexp(n, rate = 1)` で指数分布から乱数を生成\n2. サンプルサイズ30で1000回のシミュレーションを行い、標本平均の分布を描画\n3. 正規分布に近づいているか確認\n\n### 練習3: 標準誤差の計算\n母平均50、母標準偏差10の正規分布から：\n1. サンプルサイズ25のときの標準誤差を計算\n2. サンプルサイズ100のときの標準誤差を計算\n3. 標準誤差を半分にするには、サンプルサイズを何倍にする必要がありますか？\n\n## まとめ\n\n| 定理 | 内容 | 実務的な意味 |\n|------|------|-------------|\n| 大数の法則 | $n \\to \\infty$ で $\\bar{X} \\to \\mu$ | サンプルが多いほど推定が正確 |\n| 中心極限定理 | $\\bar{X}$ の分布は正規分布に近づく | 正規分布を前提とした推測が可能 |\n",
    "supporting": [
      "07_sampling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}