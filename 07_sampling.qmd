# 第7回 標本分布 {.unnumbered}

![標本分布](figure/07_sampling/infographic.png)

## 今回の目標

-   母集団と標本の関係を理解する。
-   **大数の法則** と **中心極限定理** をシミュレーションで体感する。
-   標本分布の概念を理解する。

## 母集団と標本

### 基本的な定義

-   **母集団 (Population)**: 調査対象全体の集まり。知りたい情報を持つ全ての対象を指します（例：日本人全員の身長、ある企業の全製品）。
-   **標本 (Sample)**: 母集団から一部を取り出したもの（例：ランダムに選んだ1000人、工場から抜き取った100個の製品）。

**重要な事実**: 私たちが実際に手にするデータの多くは**標本**です。母集団全体のデータを得ることは、コストや時間の制約から現実的ではありません。

### ランダム標本 (Random Sample)

標本が母集団から**無作為に抽出**されたとき、これを**ランダム標本**と呼びます。

ランダム標本の特徴：
- 母集団のどの要素も等しい確率で選ばれる
- 各抽出が互いに独立である
- 母集団を偏りなく代表する

**横断面データ**（ある時点での複数の個体のデータ）は、通常ランダム標本と考えます。
例：2024年1月に実施した1000人の消費者調査データ

### 推測統計学 (Inferential Statistics)

**標本から母集団の特徴を推測すること**を推測統計学といいます。

- **記述統計学**：手元のデータを要約・記述する（これまで学んできたこと）
- **推測統計学**：標本データから母集団について結論を導く（これから学ぶこと）

### 確率変数としての母集団

推測統計学では、母集団を**確率変数**と仮定します。

なぜ確率変数として扱うのか：

- 母集団から標本を抽出する行為は「ランダムな試行」
- 同じ母集団から何度も標本を取れば、毎回異なる値が得られる
- この不確実性を数学的に扱うために、確率変数の枠組みを使う

### ランダム標本の数学的性質

サイズ $N$ のランダム標本 $X_1, X_2, \ldots, X_N$ は：

1. **N個の母集団のコピー**と考えることができる
2. それぞれが**独立同一分布 (i.i.d.: independent and identically distributed)** に従う確率変数

**独立同一分布とは**：
- **同一分布 (identically distributed)**: 全ての $X_i$ が同じ母集団分布に従う
- **独立 (independent)**: 各 $X_i$ の値は互いに影響を与えない

数学的には：
$$X_1, X_2, \ldots, X_N \sim \text{i.i.d.} \quad F(\cdot)$$

ここで $F(\cdot)$ は母集団の分布を表します。

**具体例**：

- 母集団：ある会社の全従業員の年収（平均500万円、標準偏差100万円の正規分布に従うと仮定）
- ランダム標本（N=100）：無作為に選んだ100人の年収データ $X_1, \ldots, X_{100}$
- 各 $X_i$ は独立に $N(500, 100^2)$ から抽出された確率変数

### なぜ標本を使うのか

- 母集団全体を調べるのはコストがかかる（全数調査）
- 時間的・物理的に不可能な場合もある
- 少数のサンプルから全体の傾向を推測できる

### 母数と統計量

| 用語 | 説明 | 記号 |
|------|------|------|
| 母平均 | 母集団の平均 | $\mu$ |
| 母分散 | 母集団の分散 | $\sigma^2$ |
| 標本平均 | 標本の平均 | $\bar{x}$ |
| 標本分散 | 標本の分散 | $s^2$ |

### 母集団と標本のイメージ

```{r}
library(tidyverse)
set.seed(1)

# 母集団（例：正規分布） {.unnumbered}
population <- rnorm(10000, mean = 50, sd = 10)

# 標本（そこから100個ランダムに抽出） {.unnumbered}
sample_data <- sample(population, 100)

# データフレーム化 {.unnumbered}
df_pop <- data.frame(value = population, type = "Population")
df_samp <- data.frame(value = sample_data, type = "Sample")
df_all <- bind_rows(df_pop, df_samp)

# ヒストグラムで比較（密度表示） {.unnumbered}
ggplot(df_all, aes(x = value, fill = type)) +
  theme_gray(base_family = "HiraKakuProN-W3") +
  geom_density(alpha = 0.5) +
  labs(title = "母集団と標本の分布比較", x = "値", y = "密度")
```

## 大数の法則 (Law of Large Numbers)

サンプルサイズ（標本の大きさ）$n$ を大きくしていくと、標本平均は母平均に近づいていくという法則です。
サイコロで確かめてみましょう。

```{r}
library(tidyverse)

# サイコロを振る回数を変えて、平均値の推移を見る {.unnumbered}
set.seed(123)
n <- 1000
dice_rolls <- sample(1:6, n, replace = TRUE)
cumulative_mean <- cumsum(dice_rolls) / (1:n)

# データフレーム作成 {.unnumbered}
df <- data.frame(n = 1:n, mean = cumulative_mean)

# プロット {.unnumbered}
ggplot(df, aes(x = n, y = mean)) +
  theme_gray(base_family = "HiraKakuProN-W3") +
  geom_line() +
  geom_hline(yintercept = 3.5, color = "red", linetype = "dashed") +
  labs(title = "大数の法則のシミュレーション", y = "標本平均")
```

回数が増えるにつれて、理論的な期待値 3.5 に近づいていく様子がわかります。

## 中心極限定理 (Central Limit Theorem)

母集団がどんな分布であっても、サンプルサイズ $n$ が十分に大きければ、標本平均の分布は **正規分布** に近づくという強力な定理です。

一様分布（0から1の乱数）から、サイズ $n=30$ の標本を取り出し、その平均を計算する作業を1000回繰り返してみましょう。

```{r}
# シミュレーション {.unnumbered}
n_samples <- 1000
sample_size <- 30
means <- numeric(n_samples)

for (i in 1:n_samples) {
  means[i] <- mean(runif(sample_size, min = 0, max = 1))
}

# ヒストグラム {.unnumbered}
ggplot(data.frame(means), aes(x = means)) +
  theme_gray(base_family = "HiraKakuProN-W3") +
  geom_histogram(bins = 30, fill = "orange", color = "white") +
  labs(title = "標本平均の分布 (n=30)", x = "標本平均")
```

元の分布は平坦（一様分布）ですが、平均値の分布は釣鐘型（正規分布）になっていることが確認できます。

### サンプルサイズによる変化

サンプルサイズを変えて、中心極限定理の効果を確認してみましょう。

```{r}
# 異なるサンプルサイズでのシミュレーション
sample_sizes <- c(5, 30, 100)
n_samples <- 1000

results <- list()
for (n in sample_sizes) {
  means <- replicate(n_samples, mean(runif(n)))
  results[[paste0("n=", n)]] <- means
}

# データフレームにまとめる
df_clt <- data.frame(
  means = unlist(results),
  sample_size = rep(paste0("n=", sample_sizes), each = n_samples)
)

# サンプルサイズの順序を明示的に設定
df_clt$sample_size <- factor(df_clt$sample_size, levels = paste0("n=", sample_sizes))

# プロット
ggplot(df_clt, aes(x = means)) +
  theme_gray(base_family = "HiraKakuProN-W3") +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  facet_wrap(~sample_size, scales = "free_y") +
  labs(title = "中心極限定理: サンプルサイズによる変化", x = "標本平均")
```

サンプルサイズが大きくなるほど、分布が正規分布に近づき、ばらつきも小さくなることがわかります。

## 標本平均の分散

標本平均の分散は、母分散をサンプルサイズで割ったものになります。

$$V[\bar{X}] = \frac{\sigma^2}{n}$$

これは、サンプルサイズが大きいほど、標本平均のばらつきが小さくなることを示しています。

```{r}
# 理論値と実際の値を比較
cat("母分散（一様分布）:", 1/12, "\n")
cat("標本平均の理論分散 (n=30):", (1/12) / 30, "\n")
cat("シミュレーションでの分散:", var(results[["n=30"]]), "\n")
```

## 標準誤差 (Standard Error)

標本平均の標準偏差を**標準誤差**といいます。

$$SE = \frac{\sigma}{\sqrt{n}}$$

標準誤差は、推定の精度を表す重要な指標です。

## 課題

1.  中心極限定理のシミュレーションで、`sample_size` を 5 に減らして実行してみてください。ヒストグラムの形はどう変わりますか？

## 練習問題

### 練習1: 大数の法則
コインを投げるシミュレーションを行い、大数の法則を確認してください：

1. `sample(c(0, 1), 1000, replace = TRUE)` でコイン投げをシミュレート
2. 累積の表の割合を計算し、グラフにプロット
3. 回数が増えると0.5に近づくことを確認

### 練習2: 中心極限定理の応用
指数分布（右に歪んだ分布）を使って中心極限定理を確認してください：

1. `rexp(n, rate = 1)` で指数分布から乱数を生成
2. サンプルサイズ30で1000回のシミュレーションを行い、標本平均の分布を描画
3. 正規分布に近づいているか確認

### 練習3: 標準誤差の計算
母平均50、母標準偏差10の正規分布から：

1. サンプルサイズ25のときの標準誤差を計算
2. サンプルサイズ100のときの標準誤差を計算
3. 標準誤差を半分にするには、サンプルサイズを何倍にする必要がありますか？

## まとめ

| 定理 | 内容 | 実務的な意味 |
|------|------|-------------|
| 大数の法則 | $n \to \infty$ で $\bar{X} \to \mu$ | サンプルが多いほど推定が正確 |
| 中心極限定理 | $\bar{X}$ の分布は正規分布に近づく | 正規分布を前提とした推測が可能 |
