[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "経済学のためのデータ分析入門 (R編)",
    "section": "",
    "text": "はじめに\nこの講義ノートは、経済学部の1年生を対象とした「Rによる統計学入門」の資料です。 プログラミング未経験者を想定し、データの読み込みから基礎的な統計分析、そして回帰分析までを半期（全12回）で学びます。\n本講義では、現代的なRの記法である Tidyverse を中心に解説します。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#シラバス",
    "href": "index.html#シラバス",
    "title": "経済学のためのデータ分析入門 (R編)",
    "section": "シラバス",
    "text": "シラバス\n\nRとRStudioの基礎: インストール、基本操作、計算\nデータの構造と扱い: ベクトル、データフレーム、データの読み込み\n記述統計 (1) 数値要約: 平均、分散、標準偏差、四分位数\n記述統計 (2) データの可視化: ggplot2によるグラフ作成\n確率論の基礎: 確率変数、期待値、分散\n主要な確率分布: 正規分布、二項分布\n標本分布: 母集団と標本、中心極限定理\n統計的推定: 点推定、区間推定\n仮説検定 (1): 検定の考え方、1標本のt検定\n仮説検定 (2): 2標本の平均の差の検定\n相関と単回帰分析: 散布図、相関係数、最小二乗法\n重回帰分析と因果推論: 複数の説明変数、因果関係と相関関係",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#準備",
    "href": "index.html#準備",
    "title": "経済学のためのデータ分析入門 (R編)",
    "section": "準備",
    "text": "準備\nこの講義では以下のソフトウェアを使用します。\n\nR\nRStudio Desktop\n\nまた、以下のパッケージを主に使用します。\ninstall.packages(\"tidyverse\")",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "第1回 RとRStudioの基礎",
    "section": "",
    "text": "なぜ今、Rを学ぶのか\n統計解析ソフトは山ほどあります。Excelで事足りることもあれば、Pythonがハマる場面もあるでしょう。それでも、多くの研究者が R を選び続けるのには理由があります。\n「科学的な正しさ」への執着。これに尽きます。\n本講義の狙いは、単なるツールの操作説明ではありません。R という言語の根底にある「再現性（Reproducibility）」の思想を理解し、RStudio を通じてそれを実践する力を養うことです。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#rとrstudioとは",
    "href": "01_intro.html#rとrstudioとは",
    "title": "第1回 RとRStudioの基礎",
    "section": "RとRStudioとは",
    "text": "RとRStudioとは\n\nR: 統計解析やデータ分析に特化したプログラミング言語である。オープンソース（GPLライセンス）で提供されており、学術機関や企業のデータ分析部門で広く利用されている。\nRStudio: Rを操作するための統合開発環境（IDE）である。コードの記述、実行、グラフの確認、変数の管理を一つのウィンドウ内で完結できる仕組みを持つ。\n\n\nなぜRを学ぶのか（筆者が推奨する理由）\n\nOSSとコスト: オープンソースであるため、個人・組織を問わず無料で導入可能である。\n統計機能の充実: 統計学者のコミュニティによって開発されているため、検定、確率分布、回帰分析などの機能が標準ライブラリとして組み込まれている（Python等は追加ライブラリが必要な場合が多い）。\n拡張性: CRAN（The Comprehensive R Archive Network）には22,000以上（2025年時点）のパッケージが公開されており、最新の統計手法も即座に利用可能となる。\n再現性の確保: すべての操作をコードとして保存するため、第三者が同じ手順で同じ結果を再現できる。これは科学的検証において必須の条件である。\nキャリアへの影響: データサイエンティストや定量的研究者の職務記述書（Job Description）において、Rスキルは統計分析能力を示す指標として重要視されている。\n\n一方で、Webアプリ開発やシステムへの組み込み用途ではPythonやC++に分があることは留意されたい（適材適所）。\n\n\nRとExcelの比較\n筆者は以下の観点から、用途に応じて使い分けることを推奨する。\n\n\n\n\n\n\n\n\n項目\nR\nExcel\n\n\n\n\nコスト\n無料\n有料（Microsoft 365等）\n\n\n再現性\n◎（コードが手順書となる）\n△（手作業の履歴が残りにくい）\n\n\nデータ規模\n◎（メモリに依存するが、数百万〜数億行も処理可能）\n×（仕様上、約100万行が上限）\n\n\n学習コスト\n高い（コマンドの習得が必要）\n低い（GUIで直感的に操作可能）\n\n\n統計機能\n◎（最新かつ高度な分析が可能）\n△（基本統計量は算出可能だが専門手法は限定的）",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#rstudioの画面構成",
    "href": "01_intro.html#rstudioの画面構成",
    "title": "第1回 RとRStudioの基礎",
    "section": "RStudioの画面構成",
    "text": "RStudioの画面構成\nRStudioを起動すると、画面は4つの領域（ペイン）に分割されている。各ペインの役割は以下の通りである。\n\n1. Source Editor (左上)\n分析手順書となる「スクリプト」を記述・編集する場所である。\n\nここに記述したコードはファイルとして保存可能であり、再現性の担保となる。\nCtrl + Enter (Macは Cmd + Enter) を押下することで、カーソル行のコードを実行できる。\n\n\n\n2. Console (左下)\nRに対して直接命令を送り、計算結果が出力される場所である。\n\n単発の計算や、変数の値を確認する際に使用する。\n注意: ここに入力したコードは実行履歴（History）には残るが、スクリプトファイルとしては保存されない。重要な処理は必ずSource Editorに記述すること。\nプロンプト &gt; が表示されている時は、Rが命令を受け付け可能な状態であることを示す。\n\n\n\n3. Environment / History (右上)\n\nEnvironment (環境): 現在のセッションで定義されている変数や読み込んだデータセットの一覧である。\nHistory (履歴): 過去にConsoleで実行したコマンドのリストである。\n\n\n\n4. Files / Plots / Packages / Help (右下)\n\nFiles: 作業ディレクトリ内のファイル操作を行う。\nPlots: 描画命令によって生成されたグラフが表示される。\nPackages: 機能拡張用パッケージのインストールや管理を行う。\nHelp: 関数の仕様書（ドキュメント）を閲覧する。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#計算してみよう",
    "href": "01_intro.html#計算してみよう",
    "title": "第1回 RとRStudioの基礎",
    "section": "計算してみよう",
    "text": "計算してみよう\nConsoleを用いた基本的な演算を行う。\n\n1 + 1\n#&gt; [1] 2\n\n\n10 * 5\n#&gt; [1] 50\n\n演算の優先順位は数学の定義に従う。\n\n(100 - 20) / 4\n#&gt; [1] 20",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#グラフを描いてみよう",
    "href": "01_intro.html#グラフを描いてみよう",
    "title": "第1回 RとRStudioの基礎",
    "section": "グラフを描いてみよう",
    "text": "グラフを描いてみよう\nRはグラフを描く機能も強力です。 試しに、Rに最初から入っている cars というデータの散布図を描いてみましょう。\n\nlibrary(tidyverse)\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\"))\nggplot(cars, aes(x = speed, y = dist)) +\n  geom_point() +\n  labs(title = \"車の速度と停止距離\")\n\n\n\n\n\n\n\n\nggsave(\"figure/01_intro/cars.png\")",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#変数オブジェクト",
    "href": "01_intro.html#変数オブジェクト",
    "title": "第1回 RとRStudioの基礎",
    "section": "変数（オブジェクト）",
    "text": "変数（オブジェクト）\n計算結果やデータを一時的に保持するための「箱」を 変数（またはオブジェクト）と呼ぶ。 Rでは代入演算子 &lt;- を用いて定義する。\n\nx &lt;- 10\ny &lt;- 5\n\n定義した変数は、その名前を評価（実行）することで内容を確認できる。\n\nx\n#&gt; [1] 10\n\n変数を用いた演算も可能である。\n\nx + y\n#&gt; [1] 15",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#関数",
    "href": "01_intro.html#関数",
    "title": "第1回 RとRStudioの基礎",
    "section": "関数",
    "text": "関数\n特定の処理をひとまとめにした機能を 関数 と呼ぶ。\n例：平方根の計算 sqrt()\n\nsqrt(16)\n#&gt; [1] 4\n\n例：ベクトル（数値の列）の作成 c()\n\nscores &lt;- c(80, 90, 75, 60, 95)\nscores\n#&gt; [1] 80 90 75 60 95\n\n例：平均値の算出 mean()\n\nmean(scores)\n#&gt; [1] 80\n\n\n関数の構造\n関数は原則として 関数名(引数) の形式をとる。引数（ひきすう）とは、関数に渡す具体的なデータや設定値のことである。\n\n# 複数の引数を持つ関数の例\n# digits引数で丸める桁数を指定\nround(3.14159, digits = 2)\n#&gt; [1] 3.14\n\n\n\n主要な関数一覧\n\n\n\n関数\n機能概要\n使用例\n\n\n\n\nmean()\n算術平均の算出\nmean(c(1,2,3)) → 2\n\n\nmedian()\n中央値の算出\nmedian(c(1,2,10)) → 2\n\n\nsum()\n総和の算出\nsum(c(1,2,3)) → 6\n\n\nmax()\n最大値の取得\nmax(c(1,2,3)) → 3\n\n\nmin()\n最小値の取得\nmin(c(1,2,3)) → 1\n\n\nsqrt()\n平方根の算出\nsqrt(16) → 4\n\n\nabs()\n絶対値の算出\nabs(-5) → 5\n\n\nround()\n四捨五入（丸め）\nround(3.7) → 4\n\n\nlength()\n要素数（長さ）の取得\nlength(c(1,2,3)) → 3",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#よく使う演算子と関数",
    "href": "01_intro.html#よく使う演算子と関数",
    "title": "第1回 RとRStudioの基礎",
    "section": "よく使う演算子と関数",
    "text": "よく使う演算子と関数\nRでのデータ分析では、以下の演算子と関数をよく使います。\n\n算術演算子\n\n# 足し算\n2 + 3\n#&gt; [1] 5\n\n# 引き算\n10 - 4\n#&gt; [1] 6\n\n# 掛け算\n5 * 6\n#&gt; [1] 30\n\n# 割り算\n20 / 4\n#&gt; [1] 5\n\n# べき乗\n2^3  # 2の3乗\n#&gt; [1] 8\n\n# 割り算の余り\n10 %% 3\n#&gt; [1] 1\n\n\n\nベクトルの操作\n\n# ベクトルの作成\nx &lt;- c(1, 2, 3, 4, 5)\n\n# ベクトル全体に同じ操作を適用\nx * 2  # すべての要素を2倍\n#&gt; [1]  2  4  6  8 10\n\n# ベクトルの要素数\nlength(x)\n#&gt; [1] 5\n\n# ベクトルの合計\nsum(x)\n#&gt; [1] 15\n\n# ベクトルの最大値・最小値\nmax(x)\n#&gt; [1] 5\nmin(x)\n#&gt; [1] 1",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#実践のヒント",
    "href": "01_intro.html#実践のヒント",
    "title": "第1回 RとRStudioの基礎",
    "section": "実践のヒント",
    "text": "実践のヒント\n\nヒント1: コメントを活用しよう\nコードの前に # をつけると、その行はコメント（メモ）になります。 後で見返したときに、何をしているコードなのか分かりやすくなります。\n\n# これはコメントです。実行されません。\nx &lt;- 10  # 変数xに10を代入\n\n\n\nヒント2: エラーを恐れない\nプログラミングではエラーが出るのは当たり前です。 エラーメッセージをよく読んで、何が問題なのか考えてみましょう。 よくあるエラー:\n\ncould not find function: 関数名が間違っているか、パッケージを読み込んでいない。\nobject not found: 変数名が間違っているか、まだ定義していない。\nカッコの閉じ忘れ: ( や { を開いたら、必ず ) や } で閉じる。\n\n\n\nヒント3: ヘルプの使い方\n関数の使い方が分からないときは、? をつけて実行してみましょう。\n\n?mean  # mean関数のヘルプを表示",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#スクリプトの保存",
    "href": "01_intro.html#スクリプトの保存",
    "title": "第1回 RとRStudioの基礎",
    "section": "スクリプトの保存",
    "text": "スクリプトの保存\nConsoleでの作業は一時的なものである。再現性を担保するため、全ての工程をスクリプトファイルとして保存する。\n\nメニューバーより File -&gt; New File -&gt; R Script を選択する。\nSource Editorにコードを記述する。\nCtrl + S (Macは Cmd + S) で保存する。拡張子は .R となる。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#課題",
    "href": "01_intro.html#課題",
    "title": "第1回 RとRStudioの基礎",
    "section": "課題",
    "text": "課題\n\n自身の年齢を変数 age に代入してください。\n変数 age を使って、10年後の年齢を計算してください。\n任意の数値を3つ格納したベクトルを作成し、その平均値を求めてください。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#練習問題",
    "href": "01_intro.html#練習問題",
    "title": "第1回 RとRStudioの基礎",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 基本計算\n以下の数式をRのコードで表現し、計算せよ。\n\n\\(25 \\times 4 + 100\\)\n\\(\\sqrt{144}\\)\n\\(2^{10}\\)\n\n\n\n練習2: 変数の操作\n\n変数 price に数値 1500 を定義する。\n変数 quantity に数値 3 を定義する。\nprice * quantity を実行し、総額を算出する。\n\n\n\n練習3: ベクトルの操作\n\n1から10までの整数を含むベクトルを作成する（ヒント: 1:10 という記法が利用可能）。\n当該ベクトルの総和を sum() 関数で算出する。\n当該ベクトルの平均値を mean() 関数で算出する。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "02_data.html",
    "href": "02_data.html",
    "title": "第2回 データの構造と扱い",
    "section": "",
    "text": "データを「整える」思想\nデータ分析において、一番時間を食う作業は何でしょうか。複雑な統計モデルの構築ではありません。「データの掃除（Data Wrangling）」です。 形式の揃っていないデータ、謎の空白、表記の揺れ。これらを人間が扱える形に整えるだけで、プロジェクトの時間の8割が消えることすらあります。\n本節では、この泥臭い作業をエレガントに片付ける武器、Tidyverse を導入します。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#今回の目標",
    "href": "02_data.html#今回の目標",
    "title": "第2回 データの構造と扱い",
    "section": "",
    "text": "Rでのデータの持ち方（データフレーム）を理解する。\n外部データ（CSVファイルなど）を読み込む方法を学ぶ。\nTidyverse パッケージを使った基本的なデータ操作を学ぶ。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#パッケージの準備",
    "href": "02_data.html#パッケージの準備",
    "title": "第2回 データの構造と扱い",
    "section": "パッケージの準備",
    "text": "パッケージの準備\nRには便利な機能を追加する パッケージ という仕組みがあります。 この講義では、データ分析に必須のパッケージ群 Tidyverse を使います。\n\nTidyverseとは\nTidyverseは、データサイエンスのために設計されたパッケージの集合体です。主に以下のパッケージが含まれています：\n\n\n\nパッケージ\n主な用途\n\n\n\n\nggplot2\nデータの可視化（グラフ作成）\n\n\ndplyr\nデータの操作・加工\n\n\ntidyr\nデータの整形\n\n\nreadr\nデータの読み込み\n\n\nstringr\n文字列の操作\n\n\nforcats\nカテゴリ変数（因子）の操作\n\n\n\n初回のみインストールが必要です（前回の課題で実施済みなら不要）。\n\n# install.packages(\"tidyverse\") {.unnumbered}\n\n使うときは毎回 library() 関数で読み込みます。\n\nlibrary(tidyverse)",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データフレーム",
    "href": "02_data.html#データフレーム",
    "title": "第2回 データの構造と扱い",
    "section": "データフレーム",
    "text": "データフレーム\n統計分析では、Excelのような表形式のデータを扱います。Rではこれを データフレーム と呼びます。 Rには練習用のデータセットがいくつか入っています。iris（アヤメのデータ）を見てみましょう。\n\nhead(iris) # 最初の6行を表示\n\n\n  \n\n\n\n\nデータフレームの構造を確認する\n\n# データの次元（行数 × 列数）\ndim(iris)\n#&gt; [1] 150   5\n\n# 列名の確認\nnames(iris)\n#&gt; [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"\n\n# データの構造を確認\nstr(iris)\n#&gt; 'data.frame':    150 obs. of  5 variables:\n#&gt;  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n#&gt;  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n#&gt;  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n#&gt;  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n#&gt;  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\nデータ型について\nRには主に以下のデータ型があります：\n\n\n\nデータ型\n説明\n例\n\n\n\n\nnumeric\n数値\n1.5, 100, -3.14\n\n\ninteger\n整数\n1L, 2L, 100L\n\n\ncharacter\n文字列\n“東京”, “hello”\n\n\nlogical\n論理値\nTRUE, FALSE\n\n\nfactor\nカテゴリ\n男性/女性, 大/中/小",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データの読み込み",
    "href": "02_data.html#データの読み込み",
    "title": "第2回 データの構造と扱い",
    "section": "データの読み込み",
    "text": "データの読み込み\n自分のデータを分析するには、CSVファイルなどを読み込む必要があります。 read_csv() 関数を使います。\n\n# data.csv というファイルがある場合の例 {.unnumbered}\n# df &lt;- read_csv(\"data.csv\") {.unnumbered}\n\n\nよく使うデータ読み込み関数\n\n\n\n関数\nファイル形式\nパッケージ\n\n\n\n\nread_csv()\nCSV（カンマ区切り）\nreadr (tidyverse)\n\n\nread_tsv()\nTSV（タブ区切り）\nreadr (tidyverse)\n\n\nread_excel()\nExcel (.xlsx)\nreadxl\n\n\nread.csv()\nCSV\nbase R\n\n\n\n今回は、Web上のCSVデータを読み込んでみましょう。\n\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\nデータの概要を確認します。\n\nglimpse(tips)\n#&gt; Rows: 244\n#&gt; Columns: 7\n#&gt; $ total_bill &lt;dbl&gt; 16.99, 10.34, 21.01, 23.68, 24.59, 25.29, 8.77, 26.88, 15.0…\n#&gt; $ tip        &lt;dbl&gt; 1.01, 1.66, 3.50, 3.31, 3.61, 4.71, 2.00, 3.12, 1.96, 3.23,…\n#&gt; $ sex        &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\",…\n#&gt; $ smoker     &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n#&gt; $ day        &lt;chr&gt; \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Su…\n#&gt; $ time       &lt;chr&gt; \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\",…\n#&gt; $ size       &lt;dbl&gt; 2, 3, 3, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 3, 3, 3, 3,…\n\n\n\ntipsデータの説明\nこのデータはレストランでのチップに関するデータです。\n\n\n\n変数名\n説明\n\n\n\n\ntotal_bill\n支払総額（ドル）\n\n\ntip\nチップの額（ドル）\n\n\nsex\n支払者の性別\n\n\nsmoker\n喫煙者かどうか\n\n\nday\n曜日\n\n\ntime\n時間帯（ランチ/ディナー）\n\n\nsize\nグループの人数",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データの操作-dplyr",
    "href": "02_data.html#データの操作-dplyr",
    "title": "第2回 データの構造と扱い",
    "section": "データの操作 (dplyr)",
    "text": "データの操作 (dplyr)\nTidyverseに含まれる dplyr パッケージを使うと、データの加工が直感的に行えます。\n\n1. 列を選ぶ: select()\n特定の列だけを取り出します。\n\ntips %&gt;% \n  select(total_bill, tip) %&gt;% \n  head()\n\n\n  \n\n\n\n%&gt;% は パイプ演算子 といい、「左の結果を右の関数に渡す」という意味です。 「tipsデータ を selectする」と読みます。\n\n\n2. 行を選ぶ: filter()\n条件に合う行だけを取り出します。 例えば、time が “Dinner” のデータだけ抽出します。\n\ntips %&gt;% \n  filter(time == \"Dinner\") %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n3. 新しい列を作る: mutate()\n計算結果などを新しい列として追加します。 チップの割合（チップ / 総額）を計算してみましょう。\n\ntips %&gt;% \n  mutate(tip_rate = tip / total_bill) %&gt;% \n  select(total_bill, tip, tip_rate) %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n5. データの並び替え: arrange()\nデータを特定の列の値で並び替えます。\n\n# 支払総額の小さい順に並べる\ntips %&gt;% \n  arrange(total_bill) %&gt;% \n  head()\n\n\n  \n\n\n\n# 降順（大きい順）にする場合は desc() を使う\ntips %&gt;% \n  arrange(desc(total_bill)) %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n6. 要約統計量を計算: summarize()\nデータの要約統計量（平均、合計など）を計算します。\n\ntips %&gt;% \n  summarize(\n    平均支払額 = mean(total_bill),\n    平均チップ = mean(tip),\n    データ数 = n()\n  )\n\n\n  \n\n\n\nグループごとに集計する場合は、group_by() と組み合わせます。\n\n# 曜日ごとの平均支払額を計算\ntips %&gt;% \n  group_by(day) %&gt;% \n  summarize(\n    平均支払額 = mean(total_bill),\n    データ数 = n()\n  )",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#パイプ演算子-の活用",
    "href": "02_data.html#パイプ演算子-の活用",
    "title": "第2回 データの構造と扱い",
    "section": "パイプ演算子 %>% の活用",
    "text": "パイプ演算子 %&gt;% の活用\nパイプ演算子を使うと、複数の操作を順番につなげられます。 「データを読み込んで、フィルタして、新しい列を作って、並び替える」といった一連の操作を、読みやすく書けます。\n\n# 例: ディナーのデータだけを抽出し、チップ率を計算し、支払額の大きい順に並べる\ntips %&gt;% \n  filter(time == \"Dinner\") %&gt;% \n  mutate(tip_rate = tip / total_bill * 100) %&gt;%  # パーセントで表示\n  arrange(desc(total_bill)) %&gt;% \n  select(total_bill, tip, tip_rate, day) %&gt;% \n  head(10)  # 上位10件のみ表示",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データ操作のヒント",
    "href": "02_data.html#データ操作のヒント",
    "title": "第2回 データの構造と扱い",
    "section": "データ操作のヒント",
    "text": "データ操作のヒント\n\nヒント1: 列名の指定方法\n列を指定する方法は2つあります。\n\n# 方法1: $ を使う\ntips$total_bill\n\n# 方法2: dplyrで直接列名を書く（パイプと相性が良い）\ntips %&gt;% select(total_bill)\n\n\n\nヒント2: 複数の条件を組み合わせる\nfilter() では、&（かつ）や |（または）を使って複数の条件を組み合わせられます。\n\n# 支払額が20ドル以上、かつディナーのデータ\ntips %&gt;% \n  filter(total_bill &gt;= 20 & time == \"Dinner\") %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n4. データの可視化（チラ見せ）\nggplot2 を使うと、データの分布を簡単に可視化できます。 例えば、男女 (sex) の人数を棒グラフにしてみましょう。\n\nggplot(tips, aes(x = sex)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_bar()",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#課題",
    "href": "02_data.html#課題",
    "title": "第2回 データの構造と扱い",
    "section": "課題",
    "text": "課題\n自分でストーリーを作ってみましょう。\n\nday が “Sun”（日曜日）である行のみを抽出する（filter）。\n抽出したデータから、total_bill と size の2列のみを選択して表示する（select）。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#練習問題",
    "href": "02_data.html#練習問題",
    "title": "第2回 データの構造と扱い",
    "section": "練習問題",
    "text": "練習問題\n正解かどうかより、「コードが思考の流れを表しているか」を意識してください。\n\n練習1: 基礎確認\nglimpse() や dim() を使い、このデータセットが「何行何列」で、「変数の型は何か」を言葉で説明してください。\n\n\n練習2: 仮説の検証\n「女性客の方がチップ率が高いのではないか？」という仮説を検証するコードを書いてください。（ヒント：filterで女性を抽出し、mutateで率を計算し、summarizeで平均を出す、など方法は幾通りもあります）\n\n\n練習3: パイプラインの構築\n以下の処理をひとつのパイプラインで書いてみてください。\n\n土曜日 (Sat) のデータを抽出。\nチップ率を計算し、新しい列として追加。\nそのチップ率が高い順（降順）に並べ替え。\n上位5件を表示。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#dplyr関数のまとめ",
    "href": "02_data.html#dplyr関数のまとめ",
    "title": "第2回 データの構造と扱い",
    "section": "dplyr関数のまとめ",
    "text": "dplyr関数のまとめ\n\n\n\n関数\n用途\n例\n\n\n\n\nselect()\n列を選択\nselect(data, col1, col2)\n\n\nfilter()\n行を抽出\nfilter(data, x &gt; 10)\n\n\nmutate()\n新しい列を作成\nmutate(data, new = x + y)\n\n\narrange()\n並び替え\narrange(data, x)\n\n\nsummarize()\n要約統計量\nsummarize(data, mean(x))\n\n\ngroup_by()\nグループ化\ngroup_by(data, category)",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html",
    "href": "03_desc_stat_1.html",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "",
    "text": "情報を「縮約」する\n手元に1万人の顧客データがあるとします。上司に「客層はどうだい？」と聞かれたら、どう答えますか。 1万人全員の年齢を読み上げるわけにはいきません。「だいたい30代です」と答えるはずです。\n記述統計（Descriptive Statistics）の本質は、ここにあります。 膨大な生のデータを、たった1つの数字（要約統計量）にまで圧縮する。多くの情報は捨てられますが、代わりに人間が理解できる「特徴」が浮かび上がります。\n本節では、この「情報の圧縮技術」を学びます。キーとなるのは次の2点です。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#今回の目標",
    "href": "03_desc_stat_1.html#今回の目標",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "",
    "text": "データの中心を表す指標（代表値）を理解する。\nデータのばらつきを表す指標（散布度）を理解する。\nRを使ってこれらの指標を計算する。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#記述統計とは",
    "href": "03_desc_stat_1.html#記述統計とは",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "記述統計とは",
    "text": "記述統計とは\n記述統計（Descriptive Statistics）とは、データの特徴を数値やグラフで要約・記述する方法です。主に以下の2つの側面からデータを把握します：\n\n中心的傾向（代表値）: データの「中心」がどこにあるか\n散布度（ばらつき）: データがどれくらい広がっているか",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#準備",
    "href": "03_desc_stat_1.html#準備",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "準備",
    "text": "準備\n前回に引き続き、tidyverse パッケージと、tips データセット（Bryant & Smith, 1995）を使います。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#代表値データの中心",
    "href": "03_desc_stat_1.html#代表値データの中心",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "代表値：データの中心",
    "text": "代表値：データの中心\nデータの中心的位置を示す指標です。\n\n平均値 (Mean)\n観測されたすべての値の総和を、データの個数（サンプルサイズ）で割った値です。統計学では一般に算術平均を指します。\n\\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\]\n\nmean(tips$total_bill)\n#&gt; [1] 19.78594\n\nこの指標は、全てのデータの影響を受けるため、極端な値（外れ値）の存在によって大きく変動するという性質があります。\n\n\n中央値 (Median)\nデータを大きさの順（昇順または降順）に並べた際、順位が中央に位置する値です。データ数が偶数の場合は、中央にある2つの値の平均をとります。 外れ値の影響を受けにくい（頑健性がある）という特徴を持ちます。\n\nmedian(tips$total_bill)\n#&gt; [1] 17.795\n\n\n\n最頻値 (Mode)\nデータセット内で最も頻繁に出現する値です。 RのBaseパッケージには統計的な最頻値を算出する関数が標準では含まれていないため、集計処理によって算出します。\n\n# カテゴリ変数の最頻値を確認\ntips %&gt;% \n  count(day) %&gt;% \n  arrange(desc(n))\n\n\n  \n\n\n\n\n\n平均値と中央値の使い分け\n分析対象の分布形状に応じて、適切な代表値を選択する必要があります。\n\n\n\n\n\n\n\n\n分布の形状\n特徴\n推奨される代表値\n\n\n\n\n左右対称な分布\n平均値と中央値がほぼ一致する\n平均値（数学的な扱いやすさから推奨されることが多い）\n\n\n歪んだ分布\n裾が長い方へ平均値が引っ張られる\n中央値（実感を反映しやすいため）\n\n\n所得分布（右に歪む）\n少数の高所得者が平均を引き上げる\n中央値\n\n\nテストの点数\n一般に正規分布（左右対称）を仮定する\n平均値",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#散布度データのばらつき",
    "href": "03_desc_stat_1.html#散布度データのばらつき",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "散布度：データのばらつき",
    "text": "散布度：データのばらつき\nデータの散らばり具合を数値化した指標です。\n\n範囲 (Range)\nデータの最大値と最小値の差です。\n\nrange(tips$total_bill)  # 最小値と最大値を返す関数\n#&gt; [1]  3.07 50.81\n\nmax(tips$total_bill) - min(tips$total_bill)  # 範囲（数値）の算出\n#&gt; [1] 47.74\n\n\n\n分散 (Variance)\n各データが平均値からどれくらい離れているか（偏差）を二乗し、平均したものです。 Rの var() 関数は、母集団の分散ではなく、不偏分散（分母が \\(n-1\\)）を計算することに注意してください。\n\\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2\\]\n\nvar(tips$total_bill)\n#&gt; [1] 79.25294\n\n\n\n標準偏差 (Standard Deviation)\n分散の正の平方根です。単位が元のデータと一致するため、解釈が容易であるという利点があります。\n\\[s = \\sqrt{s^2}\\]\n\nsd(tips$total_bill)\n#&gt; [1] 8.902412\n\n\n\n変動係数 (Coefficient of Variation)\n標準偏差を平均値で除した値です。単位の異なるデータ間や、平均値が大きく異なるデータ間でばらつきを比較する際に使用します。\n\\[CV = \\frac{s}{\\bar{x}} \\times 100\\%\\]\n\n# チップと支払総額の相対的なばらつきを比較\ncv_tip &lt;- sd(tips$tip) / mean(tips$tip) * 100\ncv_bill &lt;- sd(tips$total_bill) / mean(tips$total_bill) * 100\n\ncat(\"チップの変動係数:\", cv_tip, \"%\\n\")\n#&gt; チップの変動係数: 46.14775 %\ncat(\"支払総額の変動係数:\", cv_bill, \"%\\n\")\n#&gt; 支払総額の変動係数: 44.99362 %\n\n\n\n四分位数 (Quartiles)\nデータを小さい順に並べ、個数が等しくなるように4分割する3つの点（第1、第2、第3四分位数）です。 summary() 関数は、これらの記述統計量を一括して出力します。\n\nsummary(tips$total_bill)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;    3.07   13.35   17.80   19.79   24.13   50.81\n\n出力項目の定義:\n\nMin: 最小値\n1st Qu: 第1四分位数（25パーセンタイル）\nMedian: 中央値（50パーセンタイル＝第2四分位数）\nMean: 平均値\n3rd Qu: 第3四分位数（75パーセンタイル）\nMax: 最大値\n\n\n\n四分位範囲 (IQR: Interquartile Range)\n第3四分位数から第1四分位数を引いた値です。 データの中央50%が含まれる範囲を示し、分散と同様にばらつきの指標となりますが、外れ値に対して頑健であるという特徴があります。\n\nIQR(tips$total_bill)\n#&gt; [1] 10.78",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#外れ値の検出",
    "href": "03_desc_stat_1.html#外れ値の検出",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "外れ値の検出",
    "text": "外れ値の検出\n統計分析では、極端に大きい・小さい値（外れ値）がデータに含まれていることがあります。 外れ値の基準として、以下がよく使われます。\n\n第1四分位数 - 1.5 × IQR より小さい値\n第3四分位数 + 1.5 × IQR より大きい値\n\n\nQ1 &lt;- quantile(tips$total_bill, 0.25)\nQ3 &lt;- quantile(tips$total_bill, 0.75)\nIQR_val &lt;- IQR(tips$total_bill)\n\n# 外れ値の境界\nlower_bound &lt;- Q1 - 1.5 * IQR_val\nupper_bound &lt;- Q3 + 1.5 * IQR_val\n\ncat(\"外れ値の下限:\", lower_bound, \"\\n\")\n#&gt; 外れ値の下限: -2.8225\ncat(\"外れ値の上限:\", upper_bound, \"\\n\")\n#&gt; 外れ値の上限: 40.2975\n\n# 外れ値を持つデータを抽出\ntips %&gt;% \n  filter(total_bill &lt; lower_bound | total_bill &gt; upper_bound) %&gt;% \n  select(total_bill, tip, day, time)",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#平均値と中央値の違いを可視化",
    "href": "03_desc_stat_1.html#平均値と中央値の違いを可視化",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "平均値と中央値の違いを可視化",
    "text": "平均値と中央値の違いを可視化\n分布が歪んでいる場合、平均値と中央値はずれます。 ヒストグラムに直線を引いて確認してみましょう。\n\n# 平均と中央値を計算 {.unnumbered}\nmean_val &lt;- mean(tips$total_bill)\nmed_val &lt;- median(tips$total_bill)\n\n# プロット {.unnumbered}\nggplot(tips, aes(x = total_bill)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_histogram(bins = 30, fill = \"lightgray\", color = \"white\") +\n  geom_vline(xintercept = mean_val, color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = med_val, color = \"blue\", linetype = \"solid\", size = 1) +\n  annotate(\"text\", x = mean_val + 5, y = 30, label = \"Mean (Red)\", color = \"red\") +\n  annotate(\"text\", x = med_val - 5, y = 30, label = \"Median (Blue)\", color = \"blue\") +\n  labs(title = \"平均値（赤破線）と中央値（青実線）\")",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#グループごとの集計",
    "href": "03_desc_stat_1.html#グループごとの集計",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "グループごとの集計",
    "text": "グループごとの集計\ndplyr の group_by() と summarize() を組み合わせると、グループごとの統計量を簡単に計算できます。 例えば、男女別 (sex) の支払総額 (total_bill) の平均と標準偏差を求めてみましょう。\n\ntips %&gt;% \n  group_by(sex) %&gt;% \n  summarize(\n    avg_bill = mean(total_bill),\n    sd_bill = sd(total_bill),\n    count = n() # データの個数\n  )",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#課題",
    "href": "03_desc_stat_1.html#課題",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "課題",
    "text": "課題\n自分の手でデータを縮約してみましょう。\n\ntips データを使用し、時間帯 (time) ごとのチップ (tip) の平均値を算出してください。\nsummary() 関数を使用し、チップ (tip) の分布の要約統計量を確認してください。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#練習問題",
    "href": "03_desc_stat_1.html#練習問題",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 基本的な記述統計の算出\ntips データの size（グループの人数）について、以下の4つの統計量を算出してください。\n\n平均値\n中央値\n標準偏差\n範囲（最小値と最大値）\n\n\n\n練習2: グループ別の比較検証\n喫煙者 (smoker == \"Yes\") と非喫煙者 (smoker == \"No\") の2群において、支払総額 (total_bill) の平均値と標準偏差を比較してください。\n\n\n練習3: 外れ値の影響を体感する\n\ntips データに極端な外れ値（例: total_bill = 100）を持つ行を追加した新しいデータを作成してください。\n元のデータと新しいデータで、平均値と中央値がそれぞれどれくらい変化したかを確認してください。どちらが「頑健」でしたか？\n\n ※本節で用いた記述統計の指標一覧は、練習問題の振り返りとして自身のノートにまとめておくことを推奨します。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#記述統計量のまとめ",
    "href": "03_desc_stat_1.html#記述統計量のまとめ",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "記述統計量のまとめ",
    "text": "記述統計量のまとめ\n\n\n\n\n\n\n\n\n\n分類\n指標\nR関数\n主な特徴\n\n\n\n\n代表値\n平均値\nmean()\n全データを使用するため情報量が多いが、外れ値に弱い\n\n\n代表値\n中央値\nmedian()\n順位に基づくため、外れ値に対して頑健\n\n\n散布度\n分散\nvar()\n偏差の二乗平均（不偏分散）。単位は元の二乗になる\n\n\n散布度\n標準偏差\nsd()\n分散の平方根。単位は元データと一致し解釈しやすい\n\n\n散布度\n四分位範囲\nIQR()\n中央50%の範囲。外れ値の影響を受けにくい\n\n\n位置\n四分位数\nquantile()\nデータの分布上の位置（パーセンタイル）を示す",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html",
    "href": "04_desc_stat_2.html",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "",
    "text": "要約の限界と「アンスコムの警鐘」\n前節では、膨大なデータを「平均値」や「分散」などの数値に縮約し、全体の特徴を掴みました。 しかし、縮約には副作用があります。「形の消失」です。\nAnscombe (1973) の有名な例、アンスコムのカルテットを見てみましょう。 一見、平均値も分散も相関係数もしっかり一致している4つのデータセットです。\nlibrary(tidyverse)\n# Rに標準で入っている anscombe データを整形\nanscombe_long &lt;- anscombe %&gt;%\n  pivot_longer(everything(),\n               names_to = c(\".value\", \"set\"),\n               names_pattern = \"(.)(.)\")\n\n# 統計量を確認：どれもほぼ同じ\nanscombe_long %&gt;%\n  group_by(set) %&gt;%\n  summarize(\n    mean_x = mean(x), mean_y = mean(y),\n    sd_x = sd(x), sd_y = sd(y),\n    cor = cor(x, y)\n  )\n数値だけなら「これらは同じ性質のデータだ」と結論づけてしまうでしょう。でも、グラフにして可視化した瞬間、景色は一変します。 [対象注意: 日本語フォント設定は環境依存あり]\nggplot(anscombe_long, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~set) +\n  labs(title = \"数値は嘘をつかないが、真実を語るとは限らない\")\nきれいな直線、曲線、外れ値の影響…。数値要約で捨て去られた情報が、可視化ではっきりと浮かび上がりました。 データ分析において、可視化は分析の「後」の飾りではありません。分析の「最初」に行うべき、欠かせない診断です。",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#今回の目標",
    "href": "04_desc_stat_2.html#今回の目標",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "",
    "text": "データの分布をグラフで確認する重要性を理解する。\nggplot2 を使って基本的なグラフ（ヒストグラム、箱ひげ図、散布図）を作成する。\nグラフの種類と使い分けを学ぶ。",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#なぜ可視化が重要か",
    "href": "04_desc_stat_2.html#なぜ可視化が重要か",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "なぜ可視化が重要か",
    "text": "なぜ可視化が重要か\n数値だけではデータの特徴を見落とすことがあります。有名な「アンスコムのカルテット」という例があります。\n\nlibrary(tidyverse)\n\n# アンスコムのカルテット（Rに組み込み済み）\nanscombe_long &lt;- anscombe %&gt;%\n  pivot_longer(everything(),\n               names_to = c(\".value\", \"set\"),\n               names_pattern = \"(.)(.)\")\n\n# 各セットの統計量\nanscombe_long %&gt;%\n  group_by(set) %&gt;%\n  summarize(\n    mean_x = mean(x),\n    mean_y = mean(y),\n    sd_x = sd(x),\n    sd_y = sd(y),\n    cor = cor(x, y)\n  )\n\n\n  \n\n\n\n統計量はほぼ同じですが、グラフにすると全く異なるパターンが見えます。\n\nggplot(anscombe_long, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~set) +\n  labs(title = \"アンスコムのカルテット: 統計量は同じでもパターンは異なる\")",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#準備",
    "href": "04_desc_stat_2.html#準備",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "準備",
    "text": "準備\n本節でも tips データセット（Bryant & Smith, 1995）を使います。\n\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#ggplot2の基本",
    "href": "04_desc_stat_2.html#ggplot2の基本",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "ggplot2の基本",
    "text": "ggplot2の基本\nggplot2 は、「キャンバスを用意」→「グラフの種類を指定」→「装飾を追加」という層（レイヤー）を重ねる考え方でグラフを作ります。\n基本形:\n\nggplot(data = データフレーム, mapping = aes(x = x軸の変数, y = y軸の変数)) +\n  グラフの種類()",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#変数の可視化",
    "href": "04_desc_stat_2.html#変数の可視化",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "1変数の可視化",
    "text": "1変数の可視化\n\nヒストグラム (Histogram)\n連続変数の分布を見るのによく使います。geom_histogram() を使います。\n\nggplot(tips, aes(x = total_bill)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"white\") +\n  labs(title = \"支払総額のヒストグラム\", x = \"支払総額 ($)\", y = \"度数\")\n\n\n\n\n\n\n\n\n\n\n箱ひげ図 (Boxplot)\nデータのばらつきや外れ値を確認するのに便利です。geom_boxplot() を使います。 1変数だけでなく、カテゴリごとの分布比較にもよく使われます。\n\nggplot(tips, aes(x = day, y = total_bill, fill = day)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_boxplot() +\n  labs(title = \"曜日別の支払総額\", x = \"曜日\", y = \"支払総額\")\n\n\n\n\n\n\n\n\n\n\n箱ひげ図の読み方\n箱ひげ図の各部分は以下を表しています：\n\n箱の下端: 第1四分位数（Q1、下位25%）\n箱の中の線: 中央値（Q2、下位50%）\n箱の上端: 第3四分位数（Q3、下位75%）\nひげ: Q1 - 1.5×IQR から Q3 + 1.5×IQR の範囲\n点: 外れ値\n\n\n\nバイオリンプロット\n箱ひげ図の代替として、分布の形状をより詳しく見られるバイオリンプロットがあります。\n\nggplot(tips, aes(x = day, y = total_bill, fill = day)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_violin() +\n  geom_boxplot(width = 0.1, fill = \"white\") +\n  labs(title = \"曜日別の支払総額（バイオリンプロット）\", x = \"曜日\", y = \"支払総額\")\n\n\n\n\n\n\n\n\n\n\n棒グラフ (Bar Plot)\nカテゴリ変数（離散変数）の度数（カウント）を見るのに使います。geom_bar() を使います。 曜日ごとのデータ数を見てみましょう。\n\nggplot(tips, aes(x = day)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"曜日ごとのデータ数\", x = \"曜日\", y = \"件数\")",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#変数の可視化-1",
    "href": "04_desc_stat_2.html#変数の可視化-1",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "2変数の可視化",
    "text": "2変数の可視化\n\n散布図 (Scatter Plot)\n2つの連続変数の関係を見るのに使います。geom_point() を使います。 支払総額とチップの関係を見てみましょう。\n\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_point(color = \"blue\", alpha = 0.5) +\n  labs(title = \"支払総額とチップの関係\", x = \"支払総額\", y = \"チップ\")\n\n\n\n\n\n\n\n\nさらに、性別で色分けしてみましょう。aes() の中に color = sex を追加します。\n\nggplot(tips, aes(x = total_bill, y = tip, color = sex)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_point()",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#グラフのカスタマイズ",
    "href": "04_desc_stat_2.html#グラフのカスタマイズ",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "グラフのカスタマイズ",
    "text": "グラフのカスタマイズ\n\n色とテーマの変更\n\n# 色を変更する\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_point(color = \"darkblue\", alpha = 0.6, size = 2) +\n  labs(title = \"支払総額とチップの関係\", x = \"支払総額\", y = \"チップ\")\n\n\n\n\n\n\n\n\n\n\nファセット（グラフを分割）\nfacet_wrap() や facet_grid() を使うと、カテゴリごとにグラフを分けて表示できます。\n\n# 時間帯ごとにグラフを分ける\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\")+\n  geom_point(aes(color = smoker)) +\n  facet_wrap(~ time) +\n  labs(title = \"時間帯別の支払総額とチップ\", x = \"支払総額\", y = \"チップ\")",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#統計量を重ねる",
    "href": "04_desc_stat_2.html#統計量を重ねる",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "統計量を重ねる",
    "text": "統計量を重ねる\nグラフに平均線や回帰直線を追加すると、データの傾向がより分かりやすくなります。\n\n# 平均線を追加\nggplot(tips, aes(x = day, y = total_bill)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_boxplot(fill = \"lightblue\") +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\", aes(group = 1), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"曜日別の支払総額（赤点は平均値）\", x = \"曜日\", y = \"支払総額\")",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#データ可視化のベストプラクティス",
    "href": "04_desc_stat_2.html#データ可視化のベストプラクティス",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "データ可視化のベストプラクティス",
    "text": "データ可視化のベストプラクティス\n\n1. グラフの目的を明確に\n\n分布を見たい → ヒストグラム、箱ひげ図\n関係を見たい → 散布図\nカテゴリ別の比較 → 棒グラフ、箱ひげ図\n\n\n\n2. 軸ラベルとタイトルを必ず付ける\n他人に見せる資料では、何のデータか一目で分かるようにlabs()で設定しましょう。\n\n\n3. 色の使い方に注意\n\n色覚多様性（色覚異常）に配慮した配色を使いましょう\n明度の違いも利用すると見やすくなります",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#課題",
    "href": "04_desc_stat_2.html#課題",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "課題",
    "text": "課題\n自分の手で可視化を行い、データからの発見を言語化してください。\n\ntip（チップ）の分布をヒストグラムで確認してください。何か気づく特徴はありますか？（キリの良い数字が多い、など）\ntotal_bill と tip の散布図を描き、time（ランチ/ディナー）で色分けして、時間帯による傾向の違いを議論してください。",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#練習問題",
    "href": "04_desc_stat_2.html#練習問題",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: ヒストグラムの最適化\n\ntip のヒストグラムを作成してください。\nビンの数（bins）を10, 30, 50と変えてみてください。分布の印象がどう変わるか観察してください。\n\n\n\n練習2: 多変量の可視化\n\n性別 (sex) ごとの tip の分布を箱ひげ図で比較してください。女性の方がばらつきが大きいですか？\n喫煙者 (smoker) ごとの total_bill の分布を、facet_wrap() を使って左右に並べて比較してください。\n\n\n\n練習3: 散布図への情報付加\n\ntotal_bill と tip の散布図を作成してください。\n点の大きさを size（人数）にマッピングしてください（aes(size = size)）。大人数のグループは右上に集まっていますか？\n全体の傾向を示す回帰直線を geom_smooth() で追加してください。",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#グラフ選択のガイド",
    "href": "04_desc_stat_2.html#グラフ選択のガイド",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "グラフ選択のガイド",
    "text": "グラフ選択のガイド\n\n\n\n目的\nグラフの種類\nggplot2の関数\n\n\n\n\n1変数の分布（連続）\nヒストグラム\ngeom_histogram()\n\n\n1変数の分布（連続）\n密度プロット\ngeom_density()\n\n\n1変数の分布（カテゴリ）\n棒グラフ\ngeom_bar()\n\n\n2変数の関係（連続×連続）\n散布図\ngeom_point()\n\n\nグループ比較（連続×カテゴリ）\n箱ひげ図\ngeom_boxplot()\n\n\nグループ比較（連続×カテゴリ）\nバイオリンプロット\ngeom_violin()\n\n\n時系列データ\n折れ線グラフ\ngeom_line()",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "05_probability.html",
    "href": "05_probability.html",
    "title": "第5回 確率論の基礎",
    "section": "",
    "text": "不確実性を飼いならす言語\nデータ分析のゴールは、手元のデータ（標本）から背後の世界（母集団）を推測すること。 でも、そこには必ず「ズレ」があります。今日のデータと明日のデータは、違うから。\nこの「ズレ」や「不確実性」を、「なんとなく」ではなく数学的に扱うための言語。それが確率論です。 統計学を学ぶ私たちにとって、避けては通れない共通言語です。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#今回の目標",
    "href": "05_probability.html#今回の目標",
    "title": "第5回 確率論の基礎",
    "section": "",
    "text": "確率変数、確率分布の意味を理解する。\n期待値と分散の定義と意味を理解する。\nRを使って期待値を計算してみる。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#なぜ確率を学ぶのか",
    "href": "05_probability.html#なぜ確率を学ぶのか",
    "title": "第5回 確率論の基礎",
    "section": "なぜ確率を学ぶのか",
    "text": "なぜ確率を学ぶのか\n統計学は「不確実性」を扱う学問です。サンプルから母集団を推測するとき、そこには常に不確実性があります。この不確実性を数学的に扱うために、確率論の知識が必要です。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#確率の基本",
    "href": "05_probability.html#確率の基本",
    "title": "第5回 確率論の基礎",
    "section": "確率の基本",
    "text": "確率の基本\n\n確率の定義\n確率とは、ある事象が起こる可能性を0から1の間の数値で表したものです。\n\n確率 = 0: 絶対に起こらない\n確率 = 1: 必ず起こる\n確率 = 0.5: 半々の可能性\n\n\n\n確率の計算\n公正なサイコロを1回振ったとき、特定の目が出る確率：\n\n# 1の目が出る確率\n1 / 6\n#&gt; [1] 0.1666667\n\n# 偶数の目が出る確率\n3 / 6\n#&gt; [1] 0.5",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#確率変数と確率分布",
    "href": "05_probability.html#確率変数と確率分布",
    "title": "第5回 確率論の基礎",
    "section": "確率変数と確率分布",
    "text": "確率変数と確率分布\n\n確率変数 (Random Variable, \\(X\\)): 試行の結果によって、とる値が確率的に定まる変数。\n\n表記: 通常、変数を大文字（\\(X, Y\\)）、実現値を小文字（\\(x, y\\)）で表します。\n\n確率分布 (Probability Distribution): 確率変数がとりうる値と、その確率（または確率密度）の対応関係。\n\n\n離散型と連続型\n\n\n\n\n\n\n\n\n種類\n定義\n例\n\n\n\n\n離散型 (Discrete)\nとりうる値が飛び飛び（可算個）\nサイコロの目、コインの裏表、不良品の数\n\n\n連続型 (Continuous)\nとりうる値が連続的（実数区間）\n身長、時間、温度\n\n\n\n\n\n離散型の例：サイコロ\n確率変数 \\(X\\) を「サイコロの目」とします。\\(X \\in \\{1, 2, 3, 4, 5, 6\\}\\) であり、それぞれの確率は \\(1/6\\) です。\nRでこの分布を表現します。\n\nx &lt;- 1:6\nprob &lt;- rep(1/6, 6) # 全ての確率が等しく 1/6\n\ndata.frame(x, prob)\n\n\n  \n\n\n\n分布の可視化： [対象注意: 日本語フォント設定は環境依存あり]\n\nlibrary(tidyverse)\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\"))\n\ndf &lt;- data.frame(x = factor(x), prob = prob)\n\nggplot(df, aes(x = x, y = prob)) +\n  geom_col(fill = \"orange\") +\n  ylim(0, 0.5) +\n  labs(title = \"サイコロの確率分布\", x = \"出る目\", y = \"確率\")",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#期待値-expected-value",
    "href": "05_probability.html#期待値-expected-value",
    "title": "第5回 確率論の基礎",
    "section": "期待値 (Expected Value)",
    "text": "期待値 (Expected Value)\n確率変数の「平均的な値」であり、分布の重心を表します。記号 \\(E[X]\\) または \\(\\mu\\) で表されます。 離散型の場合、とりうる値にその確率を掛けて総和をとることで定義されます。\n\\[ E[X] = \\sum_{i} x_i P(X=x_i) \\]\nサイコロの期待値の計算：\n\\[ 1 \\times \\frac{1}{6} + 2 \\times \\frac{1}{6} + \\cdots + 6 \\times \\frac{1}{6} = 3.5 \\]\nRでの計算：\n\n# 期待値の定義通りの計算\nE_X &lt;- sum(x * prob)\nE_X\n#&gt; [1] 3.5\n\n\n期待値の性質（線形性）\n期待値には以下の重要な性質（線形性）があります。\\(a, b\\) は定数とします。\n\n\\(E[X + b] = E[X] + b\\) （平行移動）\n\\(E[aX] = a E[X]\\) （定数倍）\n\\(E[aX + bY] = aE[X] + bE[Y]\\) （和の期待値は期待値の和）",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#分散-variance",
    "href": "05_probability.html#分散-variance",
    "title": "第5回 確率論の基礎",
    "section": "分散 (Variance)",
    "text": "分散 (Variance)\n確率変数の「ばらつき」の大きさ、つまり期待値からの散らばり具合を表す指標です。記号 \\(V[X]\\) または \\(\\sigma^2\\) で表されます。 定義は「平均（期待値）からの偏差の二乗の期待値」です。\n\\[ V[X] = E[(X - E[X])^2] = \\sum_{i} (x_i - E[X])^2 P(X=x_i) \\]\nサイコロの分散の計算：\n\n# 分散の定義通りの計算\nV_X &lt;- sum((x - E_X)^2 * prob)\nV_X\n#&gt; [1] 2.916667\n\n# 標準偏差 (Standard Deviation)\nsqrt(V_X)\n#&gt; [1] 1.707825\n\n\n分散の性質\n\n\\(V[X + b] = V[X]\\) （平行移動してもばらつきは変わらない）\n\\(V[aX] = a^2 V[X]\\) （定数倍すると分散は2乗倍になる）\n計算公式: \\(V[X] = E[X^2] - (E[X])^2\\)\n\n\n# 公式を用いた検算\nE_X2 &lt;- sum(x^2 * prob)  # E[X^2]: 二乗の期待値\nE_X2 - E_X^2             # V[X]\n#&gt; [1] 2.916667",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#同時確率と条件付き確率",
    "href": "05_probability.html#同時確率と条件付き確率",
    "title": "第5回 確率論の基礎",
    "section": "同時確率と条件付き確率",
    "text": "同時確率と条件付き確率\n\n同時確率\n2つの事象が同時に起こる確率を同時確率といいます。\n例：2つのサイコロを振って、両方とも6が出る確率\n\n# 両方6が出る確率\n(1/6) * (1/6)\n#&gt; [1] 0.02777778\n\n\n\n条件付き確率\nある事象が起こったという条件のもとで、別の事象が起こる確率を条件付き確率といいます。\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\n\n独立性\n事象 \\(A\\) と \\(B\\) が独立であるとは：\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\nが成り立つことをいいます。サイコロを2回振る場合、1回目の結果と2回目の結果は独立です。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#課題",
    "href": "05_probability.html#課題",
    "title": "第5回 確率論の基礎",
    "section": "課題",
    "text": "課題\n\nコインの期待値: 表が出る確率 \\(0.5\\)、裏が出る確率 \\(0.5\\) のコインがあります。表なら100円、裏なら0円を得るときの賞金の期待値を計算してください。\n確率の変化: もし表が出る確率が \\(0.1\\)（裏は \\(0.9\\)）の歪んだコインを使用した場合、期待値はどう変化するか計算してください。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#練習問題",
    "href": "05_probability.html#練習問題",
    "title": "第5回 確率論の基礎",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: サイコロの和\n\n2つのサイコロを振ったとき、目の合計が「7」になる組み合わせを列挙し、その確率を計算してください。\n目の合計の期待値を、期待値の線形性 \\(E[X+Y] = E[X] + E[Y]\\) を用いて計算してください。\n\n\n\n練習2: 宝くじの期待値評価\n以下の条件の宝くじの期待値を算出してください。 - 1等（100万円）：確率 \\(1/10000\\) - 2等（10万円）：確率 \\(1/1000\\) - ハズレ（0円）：上記以外\n\n\n練習3: 二項分布の実験\nコインを3回投げて、表が出た回数 \\(X\\) (\\(X \\in \\{0, 1, 2, 3\\}\\)) に応じて \\(100X\\) 円がもらえるゲームを考えます。 1. \\(X\\) がとる各値の確率を計算してください（樹形図などを想像してください）。 2. このゲームの賞金の期待値を計算してください。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#確率の公式まとめ",
    "href": "05_probability.html#確率の公式まとめ",
    "title": "第5回 確率論の基礎",
    "section": "確率の公式まとめ",
    "text": "確率の公式まとめ\n\n\n\n公式\n説明\n\n\n\n\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n加法定理\n\n\n\\(P(A \\cap B) = P(A) \\times P(B\\|A)\\)\n乗法定理\n\n\n\\(P(A\\|B) = \\frac{P(A \\cap B)}{P(B)}\\)\n条件付き確率\n\n\n\\(E[X] = \\sum x_i P(X=x_i)\\)\n期待値\n\n\n\\(V[X] = E[(X-E[X])^2]\\)\n分散",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "06_distributions.html",
    "href": "06_distributions.html",
    "title": "第6回 主要な確率分布",
    "section": "",
    "text": "世界を支配する「釣り鐘」\n身長、テストの点数、工場の部品サイズ、株価の変動…。 まったく異なるこれらすべての現象に、どこにでも現れる不思議な曲線があります。 正規分布（Normal Distribution）。またの名を、ガウス分布。\nなぜ世界は、ことあるごとに正規分布したがるのか？ その秘密は、統計学で最強の定理（中心極限定理）にあります。まずはこの「王様」の振る舞いを知ることから始めましょう。\n本節では、統計解析の主役である正規分布と、その親戚たち（二項分布、t分布など）を、Rを使って自在に操れるようになります。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#今回の目標",
    "href": "06_distributions.html#今回の目標",
    "title": "第6回 主要な確率分布",
    "section": "",
    "text": "統計学で最も重要な 正規分布 を理解する。\n二項分布 を理解する。\nRを使って確率分布の計算やグラフ描画を行う。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#rにおける確率分布関数",
    "href": "06_distributions.html#rにおける確率分布関数",
    "title": "第6回 主要な確率分布",
    "section": "Rにおける確率分布関数",
    "text": "Rにおける確率分布関数\nRでは、主要な確率分布に対して以下4種類の関数が標準実装されています。関数名は [接頭辞] + [分布の略称] の形式で統一されています。\n\n\n\n接頭辞\n機能\n確率論的定義\n例（正規分布 norm）\n\n\n\n\nd\n確率密度/質量 (Density)\n\\(f(x)\\) または \\(P(X=x)\\)\ndnorm()\n\n\np\n累積分布 (Probability)\n\\(F(q) = P(X \\le q)\\)\npnorm()\n\n\nq\n分位点 (Quantile)\n\\(F^{-1}(p)\\)\nqnorm()\n\n\nr\n乱数生成 (Random)\n-\nrnorm()",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#正規分布-normal-distribution",
    "href": "06_distributions.html#正規分布-normal-distribution",
    "title": "第6回 主要な確率分布",
    "section": "正規分布 (Normal Distribution)",
    "text": "正規分布 (Normal Distribution)\n正規分布（ガウス分布）は、統計学において最も基本的かつ重要な連続型確率分布です。 平均 \\(\\mu\\) と標準偏差 \\(\\sigma\\)（または分散 \\(\\sigma^2\\)）の2つのパラメータによって一意に定まります。\n確率密度関数: \\[f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]\n\n正規分布の可視化\n平均0、分散1の「標準正規分布」を描画します。 [対象注意: 日本語フォント設定は環境依存あり]\n\nlibrary(tidyverse)\n\n# x軸の範囲定義\nx &lt;- seq(-4, 4, length.out = 100)\n# 確率密度の計算\ny &lt;- dnorm(x, mean = 0, sd = 1)\n\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  labs(title = \"標準正規分布 (Mean=0, SD=1)\")\n\n\n\n\n\n\n\n\n\n\nパラメータによる変化\n平均 \\(\\mu\\) は分布の中心位置を、標準偏差 \\(\\sigma\\) は分布の広がり（幅）を決定します。\n\nx &lt;- seq(-10, 15, length.out = 200)\ndf_compare &lt;- data.frame(\n  x = rep(x, 3),\n  y = c(dnorm(x, mean = 0, sd = 1),\n        dnorm(x, mean = 5, sd = 1),\n        dnorm(x, mean = 0, sd = 2)),\n  type = rep(c(\"μ=0, σ=1\", \"μ=5, σ=1\", \"μ=0, σ=2\"), each = length(x))\n)\n\nggplot(df_compare, aes(x = x, y = y, color = type)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line(size = 1) +\n  labs(title = \"パラメータによる正規分布の変化\", color = \"設定\")",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#確率の計算",
    "href": "06_distributions.html#確率の計算",
    "title": "第6回 主要な確率分布",
    "section": "確率の計算",
    "text": "確率の計算\n例題：「平均50、標準偏差10の正規分布に従う集団において、値が60以上となる確率はいくらか？」\nRの pnorm(q) は累積確率（\\(-\\infty\\) から \\(q\\) までの面積）を返すため、右側の面積を求める場合は全体（1）から引きます。\n\n# P(X &lt;= 60)\np_lower &lt;- pnorm(60, mean = 50, sd = 10)\n\n# P(X &gt;= 60) = 1 - P(X &lt;= 60)\n1 - p_lower\n#&gt; [1] 0.1586553\n\n計算結果は約15.9%となります。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#二項分布-binomial-distribution",
    "href": "06_distributions.html#二項分布-binomial-distribution",
    "title": "第6回 主要な確率分布",
    "section": "二項分布 (Binomial Distribution)",
    "text": "二項分布 (Binomial Distribution)\n二項分布は、結果が2通り（成功/失敗）の試行を固定回数繰り返すモデルです。\n\n前提：ベルヌーイ試行\n「コイン投げ」のように、結果が \\(\\{0, 1\\}\\) のいずれかである試行をベルヌーイ試行と呼びます。 確率変数 \\(X\\) が成功確率 \\(p\\) のベルヌーイ分布に従うとき：\n\\[P(X=1) = p, \\quad P(X=0) = 1-p\\]\n期待値は \\(E[X]=p\\)、分散は \\(V[X]=p(1-p)\\) となります。\n\n\n二項分布の定義\n以下の条件（ベルヌーイ試行の反復）を満たす確率変数を考えます。\n\n試行回数 \\(n\\) が固定されている。\n各試行は独立である。\n成功確率 \\(p\\) は常に一定である。\n\nこのとき、総成功回数 \\(X\\) はパラメータ \\((n, p)\\) の二項分布に従います。 \\[X \\sim \\text{Binomial}(n, p)\\]\n確率質量関数: \\[P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\]\n\n\nRでの計算と可視化\n例：公正なコインを10回投げたとき、表がちょうど5回出る確率。\n\ndbinom(5, size = 10, prob = 0.5)\n#&gt; [1] 0.2460938\n\n分布全体（\\(k=0 \\sim 10\\)）の可視化：\n\nx &lt;- 0:10\nprob &lt;- dbinom(x, size = 10, prob = 0.5)\ndf_binom &lt;- data.frame(x = factor(x), prob = prob)\n\nggplot(df_binom, aes(x = x, y = prob)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_col(fill = \"lightgreen\") +\n  labs(title = \"二項分布 (n=10, p=0.5)\", x = \"成功回数\", y = \"確率\")\n\n\n\n\n\n\n\n\n\n\n二項分布の期待値と分散\n\n期待値: \\(E[X] = np\\)\n分散: \\(V[X] = np(1-p)\\)\n\n\n\n二項分布の正規近似\n試行回数 \\(n\\) が十分に大きい場合、二項分布は正規分布 \\(N(np, np(1-p))\\) で近似可能です（ド・モアブル＝ラプラスの定理）。 これは中心極限定理の一例です。\n\n# 試行回数 n を変化させた場合の分布形状\nn_values &lt;- c(30, 10, 100)\np &lt;- 0.3\n\ndf_binom_approx &lt;- data.frame()\nfor(n in n_values) {\n  x &lt;- 0:n\n  prob &lt;- dbinom(x, size = n, prob = p)\n  df_binom_approx &lt;- rbind(df_binom_approx, data.frame(x=x, prob=prob, n=paste0(\"n=\", n)))\n}\n\nggplot(df_binom_approx, aes(x = x, y = prob)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_col(fill = \"steelblue\") +\n  facet_wrap(~ fct_relevel(n, \"n=10\", \"n=30\", \"n=100\"), scales = \"free_x\") +\n  labs(title = \"nの増加に伴う二項分布の正規近似\", x = \"成功回数\", y = \"確率\")",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#ポアソン分布-poisson-distribution",
    "href": "06_distributions.html#ポアソン分布-poisson-distribution",
    "title": "第6回 主要な確率分布",
    "section": "ポアソン分布 (Poisson Distribution)",
    "text": "ポアソン分布 (Poisson Distribution)\n一定期間・一定空間内でまれに起こる事象の回数を表す分布です。\n例：1時間あたりに店に来る客の数、1ページあたりの誤字の数\n\\[P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\]\n\n# 平均5回の事象が起こるとき\nx &lt;- 0:15\nprob &lt;- dpois(x, lambda = 5)\ndf_pois &lt;- data.frame(x = factor(x), prob = prob)\n\nggplot(df_pois, aes(x = x, y = prob)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_col(fill = \"coral\") +\n  labs(title = \"ポアソン分布 (λ=5)\", x = \"事象の発生回数\", y = \"確率\")",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#正規分布の重要性",
    "href": "06_distributions.html#正規分布の重要性",
    "title": "第6回 主要な確率分布",
    "section": "正規分布の重要性",
    "text": "正規分布の重要性\n正規分布が統計学で特別視される主な理由は以下の通りです。\n\n中心極限定理 (CLT): 元の分布がどのような形であっても、標本サイズが十分に大きければ、標本平均の分布は正規分布に近似します。これにより、多種多様なデータの統計的推測が可能になります（第7回詳述）。\n誤差のモデル化: 多数の微小な独立した要因が積み重なって生じる誤差（測定誤差など）は、理論的に正規分布に従うことが示されます。\n\n\n経験則（68-95-99.7ルール）\n正規分布には以下の確率的性質があります。\n\n\\(\\mu \\pm 1\\sigma\\) の範囲: 約68.3%\n\\(\\mu \\pm 2\\sigma\\) の範囲: 約95.4%\n\\(\\mu \\pm 3\\sigma\\) の範囲: 約99.7%\n\n\nx &lt;- seq(-4, 4, length.out = 100)\ny &lt;- dnorm(x)\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  geom_area(data = filter(df, x &gt;= -1 & x &lt;= 1), fill = \"blue\", alpha = 0.3) +\n  geom_area(data = filter(df, x &gt;= -2 & x &lt;= 2), fill = \"green\", alpha = 0.2) +\n  geom_area(data = filter(df, x &gt;= -3 & x &lt;= 3), fill = \"red\", alpha = 0.1) +\n  labs(title = \"正規分布の区間確率 (1SD, 2SD, 3SD)\", x = \"標準偏差 (z)\", y = \"確率密度\")",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#課題",
    "href": "06_distributions.html#課題",
    "title": "第6回 主要な確率分布",
    "section": "課題",
    "text": "課題\n自らの手で確率を計算し、モデルの感覚を掴んでください。\n\n正規分布の計算: 日本人成人男性の身長が平均171cm、標準偏差6cmの正規分布に従うと仮定します。 身長が180cm以上の人は、上位何パーセントに含まれますか？\n二項分布の計算: サイコロを10回振ったとき、1の目が「ちょうど2回」出る確率は？（ヒント：\\(n=10, p=1/6\\)）",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#練習問題",
    "href": "06_distributions.html#練習問題",
    "title": "第6回 主要な確率分布",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: テストの点数分布\n平均50点、標準偏差10点の正規分布に従うテストについて：\n\n40点以下となる確率は？\n40点から60点の間に入る確率は？\n上位10%に入るには何点以上必要ですか？ (qnormを使って逆算してください)\n\n\n\n練習2: 不良品の発生確率\n不良品率が10% (\\(p=0.1\\)) の製造ラインで製品を20個 (\\(n=20\\)) 作る場合： 1. 不良品が1個も出ない確率 2. 不良品が3個以上出る確率（sum(dbinom(3:20, ...))）\n\n\n練習3: 乱数シミュレーション\n標準正規分布から乱数を100個生成しヒストグラムを描画してください。 その後、サンプルサイズを1,000個、10,000個と増やしたとき、ヒストグラムの形状がどのように理論分布（釣鐘型）に近づくか確認してください。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#主要な確率分布のまとめ",
    "href": "06_distributions.html#主要な確率分布のまとめ",
    "title": "第6回 主要な確率分布",
    "section": "主要な確率分布のまとめ",
    "text": "主要な確率分布のまとめ\n\n\n\n分布\n用途\nR関数\nパラメータ\n\n\n\n\n正規分布\n連続データの分布\nnorm\nmean, sd\n\n\n二項分布\n成功/失敗の回数\nbinom\nsize, prob\n\n\nt分布\n小標本の推定・検定\nt\ndf\n\n\nカイ二乗分布\n分散の検定\nchisq\ndf\n\n\nF分布\n分散比の検定\nf\ndf1, df2",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "07_sampling.html",
    "href": "07_sampling.html",
    "title": "第7回 標本分布",
    "section": "",
    "text": "一滴の血液で、全身を知る\nたった数mlの血液を検査するだけで、全身の健康状態がわかってしまう。 選挙の出口調査では、数千人の回答から全国民の意思を予測できる。\nなぜ、そんなことができるのか？ なぜ、「一部」を見るだけで「全体」が見えるのか？\n今回は、統計的推測の根幹を支える標本分布という考え方と、そこに働く数学的な魔法（大数の法則・中心極限定理）について学びます。これで、記述統計から推測統計への架け橋がかかる。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#今回の目標",
    "href": "07_sampling.html#今回の目標",
    "title": "第7回 標本分布",
    "section": "",
    "text": "母集団と標本の関係を理解する。\n大数の法則 と 中心極限定理 をシミュレーションで体感する。\n標本分布の概念を理解する。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#母集団と標本",
    "href": "07_sampling.html#母集団と標本",
    "title": "第7回 標本分布",
    "section": "母集団と標本",
    "text": "母集団と標本\n推測統計学（Inferential Statistics）の目的は、「手元のデータ（標本）」から「背後の世界（母集団）」の性質を明らかにすることです。\n\n概念の定義\n\n母集団 (Population): 分析の対象となる関心領域の全体。例えば「日本人全ての身長」や「製造ラインで作られる全ての製品」など。推測統計では、母集団を無限の要素を持つ確率分布とみなしてモデル化することが一般的です（無限母集団）。\n標本 (Sample): 母集団から抽出された一部の観測データ。現実の分析対象は常にこの標本です。\n\n\n\n全数調査と標本調査\n母集団全体を調べる「全数調査（Census）」は、国勢調査などを除き、コストや時間の制約から現実的に不可能です。したがって、一部のデータから全体を推測する「標本調査」が必要となります。\n\n\n単純無作為抽出 (Simple Random Sampling)\n母集団のすべての要素が等しい確率で選ばれるような抽出方法です。 統計学的なモデルとして扱う場合、サイズ \\(n\\) の標本 \\(X_1, X_2, \\ldots, X_n\\) は、以下の条件を満たす確率変数として定式化されます。\n\n独立かつ同一の分布 (i.i.d.: independent and identically distributed):\n\n独立: データの抽出が他のデータに影響を与えない。\n同一分布: すべてのデータが同じ母集団分布から得られている。\n\n\n\\[X_1, X_2, \\ldots, X_n \\sim \\text{i.i.d.} \\quad F(\\mu, \\sigma^2)\\]",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#大数の法則-law-of-large-numbers",
    "href": "07_sampling.html#大数の法則-law-of-large-numbers",
    "title": "第7回 標本分布",
    "section": "大数の法則 (Law of Large Numbers)",
    "text": "大数の法則 (Law of Large Numbers)\nサンプルサイズ \\(n\\) を大きくすると、標本平均 \\(\\bar{X}\\) は母平均 \\(\\mu\\) に確率的に収束するという法則です。 これは「データが多ければ多いほど、その平均値は真の値に近づく」という直感を数学的に保証するものです。\n\nサイコロによる実験\nサイコロの目の期待値（母平均）は \\(3.5\\) です。投げる回数を増やしたときの標本平均の推移を確認します。\n\nn &lt;- 1000\ndice_rolls &lt;- sample(1:6, n, replace = TRUE)\ncumulative_mean &lt;- cumsum(dice_rolls) / (1:n)\n\ndf &lt;- data.frame(n = 1:n, mean = cumulative_mean)\n\nggplot(df, aes(x = n, y = mean)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  geom_hline(yintercept = 3.5, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"大数の法則: 試行回数と標本平均の収束\", y = \"標本平均\")\n\n\n\n\n\n\n\n\n\\(n\\) が増えるにつれて、標本平均が真の値 \\(3.5\\) に収束していく様子が確認できます。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#中心極限定理-central-limit-theorem",
    "href": "07_sampling.html#中心極限定理-central-limit-theorem",
    "title": "第7回 標本分布",
    "section": "中心極限定理 (Central Limit Theorem)",
    "text": "中心極限定理 (Central Limit Theorem)\n母集団がどんな分布であっても、サンプルサイズ \\(n\\) が十分に大きければ、標本平均の分布は 正規分布 に近づくという強力な定理です。\n一様分布（0から1の乱数）から、サイズ \\(n=30\\) の標本を取り出し、その平均を計算する作業を1000回繰り返してみましょう。\n\n# シミュレーション {.unnumbered}\nn_samples &lt;- 1000\nsample_size &lt;- 30\nmeans &lt;- numeric(n_samples)\n\nfor (i in 1:n_samples) {\n  means[i] &lt;- mean(runif(sample_size, min = 0, max = 1))\n}\n\n# ヒストグラム {.unnumbered}\nggplot(data.frame(means), aes(x = means)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_histogram(bins = 30, fill = \"orange\", color = \"white\") +\n  labs(title = \"標本平均の分布 (n=30)\", x = \"標本平均\")\n\n\n\n\n\n\n\n\n元の分布は平坦（一様分布）ですが、平均値の分布は釣鐘型（正規分布）になっていることが確認できます。\n\nサンプルサイズによる変化\nサンプルサイズを変えて、中心極限定理の効果を確認してみましょう。\n\n# 異なるサンプルサイズでのシミュレーション\nsample_sizes &lt;- c(5, 30, 100)\nn_samples &lt;- 1000\n\nresults &lt;- list()\nfor (n in sample_sizes) {\n  means &lt;- replicate(n_samples, mean(runif(n)))\n  results[[paste0(\"n=\", n)]] &lt;- means\n}\n\n# データフレームにまとめる\ndf_clt &lt;- data.frame(\n  means = unlist(results),\n  sample_size = rep(paste0(\"n=\", sample_sizes), each = n_samples)\n)\n\n# サンプルサイズの順序を明示的に設定\ndf_clt$sample_size &lt;- factor(df_clt$sample_size, levels = paste0(\"n=\", sample_sizes))\n\n# プロット\nggplot(df_clt, aes(x = means)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  facet_wrap(~sample_size, scales = \"free_y\") +\n  labs(title = \"中心極限定理: サンプルサイズによる変化\", x = \"標本平均\")\n\n\n\n\n\n\n\n\nサンプルサイズが大きくなるほど、分布が正規分布に近づき、ばらつきも小さくなることがわかります。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#標本平均の分散",
    "href": "07_sampling.html#標本平均の分散",
    "title": "第7回 標本分布",
    "section": "標本平均の分散",
    "text": "標本平均の分散\n標本平均の分散は、母分散をサンプルサイズで割ったものになります。\n\\[V[\\bar{X}] = \\frac{\\sigma^2}{n}\\]\nこれは、サンプルサイズが大きいほど、標本平均のばらつきが小さくなることを示しています。\n\n# 理論値と実際の値を比較\ncat(\"母分散（一様分布）:\", 1/12, \"\\n\")\n#&gt; 母分散（一様分布）: 0.08333333\ncat(\"標本平均の理論分散 (n=30):\", (1/12) / 30, \"\\n\")\n#&gt; 標本平均の理論分散 (n=30): 0.002777778\ncat(\"シミュレーションでの分散:\", var(results[[\"n=30\"]]), \"\\n\")\n#&gt; シミュレーションでの分散: 0.00278787",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#標準誤差-standard-error",
    "href": "07_sampling.html#標準誤差-standard-error",
    "title": "第7回 標本分布",
    "section": "標準誤差 (Standard Error)",
    "text": "標準誤差 (Standard Error)\n\n標準偏差と標準誤差の違い\n非常に混同しやすい概念ですが、以下の区別が重要です。\n\n標準偏差 (Standard Deviation, SD): データのばらつきを表す指標。個々のデータが平均からどれくらい離れているか。\n標準誤差 (Standard Error, SE): 標本平均のばらつきを表す指標。標本平均の分布（標本分布）の標準偏差。\n\n\n\n標準誤差の公式\n母分散を \\(\\sigma^2\\)、サンプルサイズを \\(n\\) とすると、標本平均 \\(\\bar{X}\\) の分散 \\(V[\\bar{X}]\\) は： \\[V[\\bar{X}] = \\frac{\\sigma^2}{n}\\]\nしたがって、標本平均の標準偏差である標準誤差 (SE) は以下のようになります： \\[SE(\\bar{X}) = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nこの式は、「データを \\(n\\) 個集めると、平均値の推定精度（ばらつきの小ささ）は \\(\\sqrt{n}\\) 分の1 になる」ことを意味しています。精度を2倍にする（誤差を半分にする）には、データを4倍集める必要があります。\n\n\nシミュレーションによる確認\n一様分布（0~1）の理論分散は \\(\\sigma^2 = 1/12\\) です。 \\(n=30\\) の場合の標準誤差を比較します。\n\n# 理論上のSE\ntrue_se &lt;- sqrt(1/12 / 30)\n\n# シミュレーションのSE（標本平均の標準偏差）\nsim_se &lt;- sd(results %&gt;% filter(size == \"n=30\") %&gt;% pull(means))\n\ncat(\"理論的SE:\", true_se, \"\\n\")\n#&gt; 理論的SE: 0.05270463\ncat(\"シミュレーションSE:\", sim_se, \"\\n\")\n#&gt; シミュレーションSE: 0.05283213",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#課題",
    "href": "07_sampling.html#課題",
    "title": "第7回 標本分布",
    "section": "課題",
    "text": "課題\n\n大数の法則: コイン投げ（表=1, 裏=0）のシミュレーションを行い、試行回数 \\(n\\) を \\(10\\) から \\(10000\\) まで増やしたとき、標本平均が理論値 \\(0.5\\) に収束する様子をグラフで描画してください。\n標準誤差の性質: 母標準偏差 \\(\\sigma=10\\) の正規分布において、標準誤差を \\(1\\) 以下にするためには、最低何個のサンプルサイズが必要か計算してください。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#練習問題",
    "href": "07_sampling.html#練習問題",
    "title": "第7回 標本分布",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 指数分布のCLT\n指数分布（rexp）は右に裾が長い歪んだ分布です。この分布からサンプルを抽出しても、標本平均の分布は正規分布に近づくか、シミュレーションで確認してください。\n\n\n練習2: サンプルサイズと精度\n標準誤差の式 \\(SE = \\sigma / \\sqrt{n}\\) に基づき、以下の問いに答えてください。\n\nサンプルサイズを100から400に増やすと、標準誤差はどう変化しますか？\n標準誤差を \\(1/10\\) にするためには、サンプルサイズを何倍にする必要がありますか？\n\n\n\n練習3: 記述統計と推測統計\n手元に \\(n=100\\) のデータがあります。 - このデータの平均値と標準偏差を計算すること（記述統計）と、 - このデータの平均値から標準誤差を計算して信頼区間を求めること（推測統計） の違いを、自分の言葉で説明してください。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#まとめ",
    "href": "07_sampling.html#まとめ",
    "title": "第7回 標本分布",
    "section": "まとめ",
    "text": "まとめ\n\n\n\n\n\n\n\n\n概念\n記号/式\n意味\n\n\n\n\n標本分布\n-\n統計量（平均など）のパラレルワールドでの分布\n\n\n大数の法則\n\\(n \\to \\infty\\) で \\(\\bar{X} \\to \\mu\\)\nデータが増えれば平均は真の値に近づく\n\n\n中心極限定理\n\\(n\\) 大なら \\(\\bar{X} \\sim N(\\mu, \\sigma^2/n)\\)\n平均値の分布は（元が何であれ）正規分布になる\n\n\n標準誤差\n\\(\\sigma / \\sqrt{n}\\)\n推定の精度。「平均値のブレ幅」",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "08_estimation.html",
    "href": "08_estimation.html",
    "title": "第8回 統計的推定",
    "section": "",
    "text": "「だいたい」を科学する\n「有権者の支持率は45%」 「新薬の効果は従来より20%高い」\nニュースでよく聞く、これらの数字。もちろん、有権者全員に聞いたわけでも、世界中の患者に試したわけでもありません。 一部のデータ（標本）から、全体（母集団）の真実を推測したもの。\nしかし、なぜ「45%」と言い切れるのか？ もし本当は「40%」だったら？ あるいは「50%」だったら？ その「ズレ」のリスクを、私たちはどう見積もればいいのか？\n今回は、統計学の核心部分である推定（Estimation）について学びます。 一点張りで予想する「点推定」と、幅を持たせて安全策をとる「区間推定」。この2つの武器を使いこなしましょう。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#今回の目標",
    "href": "08_estimation.html#今回の目標",
    "title": "第8回 統計的推定",
    "section": "",
    "text": "点推定と区間推定の違いを理解する。\n信頼区間の意味を正しく理解する。\nRで信頼区間を計算する。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#推定とは",
    "href": "08_estimation.html#推定とは",
    "title": "第8回 統計的推定",
    "section": "推定とは",
    "text": "推定とは\n推定とは、標本のデータから母集団のパラメータ（母数）を推測することです。\n\n良い推定量の性質\n\n不偏性: 推定量の期待値が真の値に等しい（\\(E[\\hat{\\theta}] = \\theta\\)）\n一致性: サンプルサイズが大きくなると真の値に近づく\n効率性: 分散が小さい（ばらつきが少ない）",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#点推定-point-estimation",
    "href": "08_estimation.html#点推定-point-estimation",
    "title": "第8回 統計的推定",
    "section": "点推定 (Point Estimation)",
    "text": "点推定 (Point Estimation)\n母数（母平均など）を一つの値でピンポイントに推定することです。 例えば、標本平均 \\(\\bar{x}\\) は母平均 \\(\\mu\\) の点推定値として使われます。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# 点推定\nmean(tips$total_bill)  # 母平均の点推定\n#&gt; [1] 19.78594\n\n\n点推定の限界\n点推定だけでは、その推定がどれくらい信頼できるか分かりません。そこで区間推定が必要になります。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#区間推定-interval-estimation",
    "href": "08_estimation.html#区間推定-interval-estimation",
    "title": "第8回 統計的推定",
    "section": "区間推定 (Interval Estimation)",
    "text": "区間推定 (Interval Estimation)\n母数が含まれるであろう「範囲」を、ある確率（信頼係数）をもって推定することです。 一般的に 95%信頼区間 がよく使われます。\n\n信頼区間の意味\n「95%の確率で母数がこの区間に入る」というのは少し不正確です。 正しくは、「同じ手順で標本抽出と区間推定を100回繰り返したら、そのうち約95回の区間には母数が含まれる」という意味です。\nこれをシミュレーションで可視化してみましょう。\n\nlibrary(tidyverse)\nset.seed(123)\n\n# シミュレーション設定 {.unnumbered}\nn_sim &lt;- 100\nn_sample &lt;- 30\nmu &lt;- 50\nsigma &lt;- 10\n\n# 結果を格納するデータフレーム {.unnumbered}\nresults &lt;- data.frame(id = 1:n_sim, lower = NA, upper = NA, hit = NA)\n\nfor (i in 1:n_sim) {\n  # 標本抽出\n  x &lt;- rnorm(n_sample, mean = mu, sd = sigma)\n  # t検定で信頼区間を計算\n  test &lt;- t.test(x)\n  results$lower[i] &lt;- test$conf.int[1]\n  results$upper[i] &lt;- test$conf.int[2]\n  # 母平均が含まれているか判定\n  results$hit[i] &lt;- (mu &gt;= results$lower[i] & mu &lt;= results$upper[i])\n}\n\n# プロット {.unnumbered}\nggplot(results, aes(x = id, ymin = lower, ymax = upper, color = hit)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_errorbar(width = 0.5) +\n  geom_hline(yintercept = mu, linetype = \"dashed\") +\n  labs(title = \"95%信頼区間のシミュレーション (100回)\", x = \"試行回数\", y = \"推定された区間\") +\n  scale_color_manual(values = c(\"TRUE\" = \"gray\", \"FALSE\" = \"red\"))",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#母平均の信頼区間母分散が未知の場合",
    "href": "08_estimation.html#母平均の信頼区間母分散が未知の場合",
    "title": "第8回 統計的推定",
    "section": "母平均の信頼区間（母分散が未知の場合）",
    "text": "母平均の信頼区間（母分散が未知の場合）\nt分布を使って計算します。Rでは t.test() 関数を使うと簡単に計算できます。 tips データの total_bill の平均値の95%信頼区間を求めてみましょう。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\nt.test(tips$total_bill)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  tips$total_bill\n#&gt; t = 34.717, df = 243, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  18.66333 20.90855\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;  19.78594\n\n出力結果の 95 percent confidence interval: の部分を見ます。\n95 percent confidence interval:\n 18.66333 20.90855\nこれは、「支払総額の母平均は、約18.66ドルから20.91ドルの間にあると考えられる」ことを示しています。\n\n信頼区間の幅に影響する要因\n\n信頼係数: 信頼係数を上げる（95%→99%）と、区間は広くなる\nサンプルサイズ: サンプルサイズが大きいほど、区間は狭くなる\nデータのばらつき: 標準偏差が大きいほど、区間は広くなる\n\n\n# 信頼係数を変えた比較\nci_90 &lt;- t.test(tips$total_bill, conf.level = 0.90)$conf.int\nci_95 &lt;- t.test(tips$total_bill, conf.level = 0.95)$conf.int\nci_99 &lt;- t.test(tips$total_bill, conf.level = 0.99)$conf.int\n\ndata.frame(\n  信頼係数 = c(\"90%\", \"95%\", \"99%\"),\n  下限 = c(ci_90[1], ci_95[1], ci_99[1]),\n  上限 = c(ci_90[2], ci_95[2], ci_99[2]),\n  幅 = c(ci_90[2] - ci_90[1], ci_95[2] - ci_95[1], ci_99[2] - ci_99[1])\n)",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#t分布",
    "href": "08_estimation.html#t分布",
    "title": "第8回 統計的推定",
    "section": "t分布",
    "text": "t分布\n母分散が未知の場合（通常はこのケース）、正規分布ではなくt分布を使います。\nt分布は正規分布に似ていますが、裾が厚い（外れ値が出やすい）特徴があります。 サンプルサイズが大きくなると、正規分布に近づきます。\n\n# t分布と正規分布の比較\nx &lt;- seq(-4, 4, length.out = 100)\ndf_dist &lt;- data.frame(\n  x = rep(x, 3),\n  y = c(dnorm(x), dt(x, df = 3), dt(x, df = 30)),\n  分布 = rep(c(\"正規分布\", \"t分布 (df=3)\", \"t分布 (df=30)\"), each = length(x))\n)\n\nggplot(df_dist, aes(x = x, y = y, color = 分布)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line(size = 1) +\n  labs(title = \"t分布と正規分布の比較\")",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#母比率の信頼区間",
    "href": "08_estimation.html#母比率の信頼区間",
    "title": "第8回 統計的推定",
    "section": "母比率の信頼区間",
    "text": "母比率の信頼区間\n「支持率」や「喫煙率」などの割合（比率）の推定には prop.test() を使います。 例：100人中60人が賛成した場合の、母集団での賛成率の95%信頼区間。\n\nprop.test(x = 60, n = 100)\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  60 out of 100, null probability 0.5\n#&gt; X-squared = 3.61, df = 1, p-value = 0.05743\n#&gt; alternative hypothesis: true p is not equal to 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.4970036 0.6952199\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#課題",
    "href": "08_estimation.html#課題",
    "title": "第8回 統計的推定",
    "section": "課題",
    "text": "課題\n\nTipsデータの分析: tips データの tip（チップ額）について、平均値の99%信頼区間を求めてください。\n解釈の確認: 算出された区間について、「チップの母平均が99%の確率でこの値になる」という説明がなぜ誤りなのか、論じてください。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#練習問題",
    "href": "08_estimation.html#練習問題",
    "title": "第8回 統計的推定",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 信頼区間の幅とサンプルサイズ\n記述統計的に同じ平均と分散を持つデータでも、サンプルサイズが異なると信頼区間はどう変わるか確認してください。 （rnorm で \\(n=10\\) と \\(n=100\\) のデータを生成し、t.test で比較）\n\n\n練習2: 母比率のシミュレーション\n真の支持率が50%のとき、100人の世論調査を100回繰り返したと仮定し、95%信頼区間が0.5を含まない回数が何回あるかシミュレーションしてください。\n\n\n練習3: 記述統計と推測統計\n手元に \\(n=100\\) のデータがあります。\n\n「データの平均」と「母平均の点推定値」は値としては同じですが、概念としてどう異なりますか？",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#推定のまとめ",
    "href": "08_estimation.html#推定のまとめ",
    "title": "第8回 統計的推定",
    "section": "推定のまとめ",
    "text": "推定のまとめ\n\n\n\n推定の種類\n説明\n例\n\n\n\n\n点推定\n1つの値で推定\n\\(\\bar{x} = 19.8\\)\n\n\n区間推定\n範囲で推定\n\\([18.7, 20.9]\\)\n\n\n\n\n\n\n信頼区間の種類\nR関数\n用途\n\n\n\n\n母平均の信頼区間\nt.test()\n連続変数の平均\n\n\n母比率の信頼区間\nprop.test()\n割合・比率",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html",
    "href": "09_hypothesis_1.html",
    "title": "第9回 仮説検定 (1)",
    "section": "",
    "text": "裁判官になるための統計学\n「この新薬は効く！」 「私の予知能力は本物だ！」\n世の中には、様々な主張が溢れている。しかし、科学の世界では「言った者勝ち」は通用しない。 その主張が、たまたまの偶然なのか、それとも確かな証拠に基づいているのか。 それを厳格にジャッジする手続きが仮説検定 (Hypothesis Testing) 。\n仮説検定の仕組みは、刑事裁判にそっくりです。 今回は、あなたが裁判官となって、「偶然かどうか」という難事件に判決を下す方法を学ぼう。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#今回の目標",
    "href": "09_hypothesis_1.html#今回の目標",
    "title": "第9回 仮説検定 (1)",
    "section": "",
    "text": "仮説検定の論理（帰無仮説、対立仮説、p値）を理解する。\nRを使って1標本のt検定を行う。\n検定の結果を正しく解釈する。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#仮説検定とは",
    "href": "09_hypothesis_1.html#仮説検定とは",
    "title": "第9回 仮説検定 (1)",
    "section": "仮説検定とは",
    "text": "仮説検定とは\n仮説検定は、データに基づいて仮説の真偽を判断する統計的手法です。\n例えば「新しい薬には効果がある」という主張を検証したいとき： 1. まず「効果がない」という仮説を立てる 2. データを集める 3. 「効果がない」という仮説のもとで、このデータが得られる確率を計算 4. その確率が十分に小さければ、「効果がない」は間違いと判断",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#仮説検定の考え方",
    "href": "09_hypothesis_1.html#仮説検定の考え方",
    "title": "第9回 仮説検定 (1)",
    "section": "仮説検定の考え方",
    "text": "仮説検定の考え方\n「コインが歪んでいないか？」を確かめたいとします。 「歪んでいない（表が出る確率は0.5）」と仮定したときに、実際に起きたこと（例：10回中9回表）が「めったに起きないこと」かどうかを確率で評価します。\n\n帰無仮説 (\\(H_0\\)): 否定したい仮説（例：差はない、効果はない）。\n対立仮説 (\\(H_1\\)): 主張したい仮説（例：差がある、効果がある）。\np値 (p-value): 帰無仮説が正しいとしたときに、今のデータ（またはそれ以上に極端なデータ）が得られる確率。\n有意水準 (\\(\\alpha\\)): 帰無仮説を棄却する基準。通常 0.05 (5%) を使います。\n\n判定ルール: - p値 &lt; 有意水準 \\(\\Rightarrow\\) 帰無仮説を棄却する（統計的に有意である）。 - p値 \\(\\ge\\) 有意水準 \\(\\Rightarrow\\) 帰無仮説を棄却できない（差があるとは言えない）。\n\n検定の手順\n\n帰無仮説と対立仮説を設定\n有意水準を決める（通常5%）\n検定統計量を計算\np値を求める\n結論を出す\n\n\n\n棄却域のイメージ\nt分布において、どの範囲に入ったら「極端」とみなされるか（棄却域）を可視化します。\n\nlibrary(tidyverse)\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\"))\n\n# t分布 (自由度9) {.unnumbered}\nx &lt;- seq(-4, 4, length.out = 100)\ny &lt;- dt(x, df = 9)\ndf_t &lt;- data.frame(x, y)\n\n# 棄却域 (両側5%) {.unnumbered}\ncritical_val &lt;- qt(0.975, df = 9)\n\nggplot(df_t, aes(x = x, y = y)) +\n  geom_line() +\n  geom_area(data = filter(df_t, x &gt; critical_val), fill = \"red\", alpha = 0.5) +\n  geom_area(data = filter(df_t, x &lt; -critical_val), fill = \"red\", alpha = 0.5) +\n  geom_vline(xintercept = c(critical_val, -critical_val), linetype = \"dashed\") +\n  labs(title = \"t分布と棄却域 (両側5%)\", x = \"t値\", y = \"確率密度\")",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#標本のt検定",
    "href": "09_hypothesis_1.html#標本のt検定",
    "title": "第9回 仮説検定 (1)",
    "section": "1標本のt検定",
    "text": "1標本のt検定\nあるデータの平均値が、特定の値 \\(\\mu_0\\) と異なるかどうかを検定します。\n例：あるクラスのテストの平均点が、全国平均の50点と異なるか？\n\n# サンプルデータ作成 {.unnumbered}\nscores &lt;- c(55, 60, 45, 70, 58, 62, 48, 52, 65, 50)\n\n# t検定 (mu = 50 と比較) {.unnumbered}\nt.test(scores, mu = 50)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  scores\n#&gt; t = 2.5862, df = 9, p-value = 0.02939\n#&gt; alternative hypothesis: true mean is not equal to 50\n#&gt; 95 percent confidence interval:\n#&gt;  50.81453 62.18547\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;      56.5\n\n結果の見方:\n\np値 (p-value): 0.02939 となりました。\n\nこれは、「もし本当にクラスの平均点が50点だとしたら、今回のような（あるいはもっと極端な）データが得られる確率は約2.9%しかない」という意味です。\nこの確率は、一般的な基準である有意水準 5% (0.05) よりも小さいです。\n\n結論: 帰無仮説（平均点は50点である）を棄却します。\n\nつまり、「偶然で片付けるには確率が低すぎる」と判断し、「このクラスの平均点は50点とは統計的に有意に異なる」と結論づけます。\n95%信頼区間 (50.8 〜 62.2) を見ても、50点が含まれていないことがわかります。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#両側検定と片側検定",
    "href": "09_hypothesis_1.html#両側検定と片側検定",
    "title": "第9回 仮説検定 (1)",
    "section": "両側検定と片側検定",
    "text": "両側検定と片側検定\n\n両側検定（デフォルト）\n「等しくない」ことを検定します。\n\\(H_0: \\mu = \\mu_0\\) vs \\(H_1: \\mu \\neq \\mu_0\\)\n\n\n片側検定\n「大きい」または「小さい」ことを検定します。\n\n# 「50点より大きい」ことを検定（片側検定）\nt.test(scores, mu = 50, alternative = \"greater\")\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  scores\n#&gt; t = 2.5862, df = 9, p-value = 0.0147\n#&gt; alternative hypothesis: true mean is greater than 50\n#&gt; 95 percent confidence interval:\n#&gt;  51.89284      Inf\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;      56.5",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#検定の誤り",
    "href": "09_hypothesis_1.html#検定の誤り",
    "title": "第9回 仮説検定 (1)",
    "section": "検定の誤り",
    "text": "検定の誤り\n仮説検定では2種類の誤りがありえます。\n\n\n\n\n帰無仮説が真\n帰無仮説が偽\n\n\n\n\n帰無仮説を棄却\n第1種の誤り（α）\n正しい判断\n\n\n帰無仮説を棄却しない\n正しい判断\n第2種の誤り（β）\n\n\n\n\n第1種の誤り（偽陽性）: 実際には差がないのに「差がある」と判断してしまう\n第2種の誤り（偽陰性）: 実際には差があるのに「差がない」と判断してしまう\n検出力 (Power): \\(1 - \\beta\\)。真の差を検出できる確率\n\n\n有意水準と検出力のトレードオフ\n有意水準を厳しくすると（5%→1%）： - 第1種の誤りは減る - 第2種の誤りは増える（検出力が下がる）",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#課題",
    "href": "09_hypothesis_1.html#課題",
    "title": "第9回 仮説検定 (1)",
    "section": "課題",
    "text": "課題\n\nTipsデータの分析: tips データの total_bill の平均値が 20ドル と異なるかどうかを検定してください。 帰無仮説 \\(H_0\\) と対立仮説 \\(H_1\\) を数式で記述し、結果のp値に基づいて結論（棄却するか否か）を述べてください。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#練習問題",
    "href": "09_hypothesis_1.html#練習問題",
    "title": "第9回 仮説検定 (1)",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 結論の解釈\nある検定の結果、p値が 0.08 でした。有意水準5%の場合、以下の主張は正しいですか？ 「p値 &gt; 0.05 なので、帰無仮説は正しいと証明された。」\n\n\n練習2: サンプルサイズと有意差\n前回使用したシミュレーションコードを使い、\\(H_0: \\mu=50\\) が誤り（真の \\(\\mu=52\\)）であるデータを生成してください。サンプルサイズ \\(n\\) を変えたとき、p値がどう変化するか確認してください。\n\n\n練習3: 誤りの種類\n「ガンではない患者を、誤ってガンであると診断してしまう」のは、第1種の過誤ですか、第2種の過誤ですか？（帰無仮説：「ガンではない」とした場合）",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#仮説検定の注意点",
    "href": "09_hypothesis_1.html#仮説検定の注意点",
    "title": "第9回 仮説検定 (1)",
    "section": "仮説検定の注意点",
    "text": "仮説検定の注意点\n\n統計的有意 ≠ 実質的に重要: p値が小さくても、効果の大きさが小さい場合がある\n「棄却しない」≠「帰無仮説が正しい」: 差がないと証明したわけではない\np値は確率ではない: 「帰無仮説が正しい確率」ではない\n多重検定の問題: 何度も検定を繰り返すと、偶然有意になりやすい",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html",
    "href": "10_hypothesis_2.html",
    "title": "第10回 仮説検定 (2)",
    "section": "",
    "text": "A vs B：決着をつけよう\n「新薬Aは、プラセボBより効くのか？」 「新しい教育プログラムを受けた生徒は、受けていない生徒より成績が良いか？」 「ダイエット前後で、体重は本当に減ったのか？」\n私たちの世界は、比較で溢れている。 しかし、単に平均値を比べるだけでは不十分。偶然のバラつきかもしれないからだ。\n今回は、2つのグループの間に「意味のある差」があるかどうかを判定する、統計学の定番技 2標本のt検定 をマスターしよう。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#今回の目標",
    "href": "10_hypothesis_2.html#今回の目標",
    "title": "第10回 仮説検定 (2)",
    "section": "",
    "text": "2つのグループの平均値に差があるかどうかを検定する。\n対応のあるデータと対応のないデータの違いを理解する。\n効果量の概念を理解する。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#標本のt検定の種類",
    "href": "10_hypothesis_2.html#標本のt検定の種類",
    "title": "第10回 仮説検定 (2)",
    "section": "2標本のt検定の種類",
    "text": "2標本のt検定の種類\n\n\n\n種類\n状況\n例\n\n\n\n\n対応なし\n独立した2群を比較\n男性vs女性、薬vsプラセボ\n\n\n対応あり\n同じ対象の前後を比較\nダイエット前後、学習前後",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#標本のt検定対応なし",
    "href": "10_hypothesis_2.html#標本のt検定対応なし",
    "title": "第10回 仮説検定 (2)",
    "section": "2標本のt検定（対応なし）",
    "text": "2標本のt検定（対応なし）\n異なる2つのグループ（例：男性と女性、投薬群とプラセボ群）の平均値を比較します。\ntips データで、ランチ (Lunch) とディナー (Dinner) で支払総額 (total_bill) に差があるか検定してみましょう。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n\n\n# 箱ひげ図で確認 {.unnumbered}\nggplot(tips, aes(x = time, y = total_bill, fill = time)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_boxplot() +\n  labs(title = \"ランチとディナーの支払総額比較\")\n\n\n\n\n\n\n\n\n# 密度図でも確認 {.unnumbered}\nggplot(tips, aes(x = total_bill, fill = time)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_density(alpha = 0.5) +\n  labs(title = \"支払総額の分布比較 (密度図)\")\n\n\n\n\n\n\n\n\n# t検定 {.unnumbered}\n# total_bill ~ time は「total_bill を time で分ける」という意味 {.unnumbered}\nt.test(total_bill ~ time, data = tips)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  total_bill by time\n#&gt; t = 3.123, df = 143.29, p-value = 0.002167\n#&gt; alternative hypothesis: true difference in means between group Dinner and group Lunch is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  1.331877 5.925088\n#&gt; sample estimates:\n#&gt; mean in group Dinner  mean in group Lunch \n#&gt;             20.79716             17.16868\n\n結果の見方:\n\np値 (p-value): 0.002167 となりました。\n\nこれは 0.05 よりはるかに小さい値です。したがって、帰無仮説（ランチとディナーで支払総額に差はない）を棄却します。\n結論として、「ランチとディナーの支払総額には統計的に有意な差がある」と言えます。\n\n平均値の比較:\n\nmean in group Dinner: 約 20.8 ドル\nmean in group Lunch: 約 17.2 ドル\nディナーの方が平均して約 3.6 ドル高いことがわかります。95%信頼区間 (1.33 〜 5.93) も0を含んでおらず、差がプラス（ディナーが高い）であることを示しています。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#対応のあるt検定-paired-t-test",
    "href": "10_hypothesis_2.html#対応のあるt検定-paired-t-test",
    "title": "第10回 仮説検定 (2)",
    "section": "対応のあるt検定 (Paired t-test)",
    "text": "対応のあるt検定 (Paired t-test)\n同じ対象に対して2回測定した場合（例：ダイエット前後の体重、テストの事前事後）の比較です。 paired = TRUE オプションを使います。\n\n# サンプルデータ（ダイエット前後の体重） {.unnumbered}\nbefore &lt;- c(70, 80, 75, 60, 65)\nafter  &lt;- c(68, 78, 74, 58, 64)\n\nt.test(before, after, paired = TRUE)\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  before and after\n#&gt; t = 6.532, df = 4, p-value = 0.002838\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.9199126 2.2800874\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;             1.6\n\n結果の見方:\n\np値: 0.002838 となりました。\n\n0.05 より小さいため、帰無仮説（ダイエット前後で差はない）を棄却します。\n「ダイエット前後で体重には有意な変化があった」と言えます。\n\n平均差 (mean difference):\n\n1.6 となっています。これは before - after の平均値です。\nつまり、平均して 1.6kg 体重が減少したことを意味します（プラスの値なので、beforeの方が大きい）。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#等分散の仮定",
    "href": "10_hypothesis_2.html#等分散の仮定",
    "title": "第10回 仮説検定 (2)",
    "section": "等分散の仮定",
    "text": "等分散の仮定\n2標本t検定には、両群の分散が等しいという仮定があります。Rの t.test() はデフォルトでWelchのt検定（等分散を仮定しない）を使用します。\n\n# Welchのt検定（デフォルト）\nt.test(total_bill ~ time, data = tips)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  total_bill by time\n#&gt; t = 3.123, df = 143.29, p-value = 0.002167\n#&gt; alternative hypothesis: true difference in means between group Dinner and group Lunch is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  1.331877 5.925088\n#&gt; sample estimates:\n#&gt; mean in group Dinner  mean in group Lunch \n#&gt;             20.79716             17.16868\n\n# Studentのt検定（等分散を仮定）\nt.test(total_bill ~ time, data = tips, var.equal = TRUE)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  total_bill by time\n#&gt; t = 2.8976, df = 242, p-value = 0.004105\n#&gt; alternative hypothesis: true difference in means between group Dinner and group Lunch is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  1.161839 6.095127\n#&gt; sample estimates:\n#&gt; mean in group Dinner  mean in group Lunch \n#&gt;             20.79716             17.16868\n\n結果の比較:\n\nWelchのt検定 (等分散を仮定しない):\n\nt統計量: 3.123、自由度: 143.29、p値: 0.002167\n95%信頼区間: 1.33 〜 5.93\n自由度が小数になっているのは、Welch-Satterthwaiteの近似を使用しているためです。\n\nStudentのt検定 (等分散を仮定する):\n\nt統計量: 2.898、自由度: 242、p値: 0.004105\n95%信頼区間: 1.16 〜 6.10\n自由度は単純に n1 + n2 - 2 = 176 + 68 - 2 = 242 となります。\n\n両者の違い:\n\nWelchのt検定の方がp値が小さく（より有意）、信頼区間も狭くなっています。\nこれは、2群のサンプルサイズが異なる場合（ディナー176件 vs ランチ68件）、Welchの方がより正確だからです。\n実務上の推奨: 等分散性が確実でない限り、Welchのt検定を使用する方が安全 です。\n\n\n等分散かどうかは、F検定やLevene検定で確認できます。\n\n# F検定（等分散の検定）\nvar.test(total_bill ~ time, data = tips)\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  total_bill by time\n#&gt; F = 1.4046, num df = 175, denom df = 67, p-value = 0.1109\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.9237626 2.0595995\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;           1.404557\n\n結果の見方:\n\np値: 0.1109 となりました。\n\nこれは 0.05 より大きいため、帰無仮説（2群の分散が等しい）を棄却できません。\nつまり、ランチとディナーの支払総額の 分散に有意な差があるとは言えない という結論になります。\n\n分散比 (ratio of variances):\n\n1.4046 となっています。これはディナーの分散がランチの分散の約1.4倍であることを示します。\nしかし、95%信頼区間 (0.924 〜 2.060) が1を含んでいるため、この差は統計的に有意ではありません。\n\n実務的な意味:\n\n等分散性が棄却されなかったため、Studentのt検定を使用することもできますが、一般的には Welchのt検定（デフォルト）の方が安全 です。\nWelchのt検定は等分散を仮定しないため、分散が異なる場合でも適切に機能します。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#効果量-effect-size",
    "href": "10_hypothesis_2.html#効果量-effect-size",
    "title": "第10回 仮説検定 (2)",
    "section": "効果量 (Effect Size)",
    "text": "効果量 (Effect Size)\np値だけでは効果の大きさがわかりません。効果量を計算することで、実質的な差の大きさを評価できます。\n\nCohen’s d\n2群の平均値の差を標準偏差で割った指標です。\n\\[d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}\\]\n\n\\(|d| &lt; 0.2\\): 小さい効果\n\\(0.2 \\le |d| &lt; 0.8\\): 中程度の効果\n\\(|d| \\ge 0.8\\): 大きい効果\n\n\n# Cohen's d の計算\ndinner &lt;- tips$total_bill[tips$time == \"Dinner\"]\nlunch &lt;- tips$total_bill[tips$time == \"Lunch\"]\n\nmean_diff &lt;- mean(dinner) - mean(lunch)\npooled_sd &lt;- sqrt(((length(dinner)-1)*var(dinner) + (length(lunch)-1)*var(lunch)) / \n                   (length(dinner) + length(lunch) - 2))\n\ncohens_d &lt;- mean_diff / pooled_sd\ncat(\"Cohen's d:\", cohens_d, \"\\n\")\n#&gt; Cohen's d: 0.4137406\n\n結果の解釈:\n\n効果量の大きさ: Cohen’s d は 0.414 となりました。\n\nこれは 0.2 ≤ |d| &lt; 0.8 の範囲に入るため、中程度の効果 と判断されます。\nランチとディナーの支払総額の差は、実質的にも意味のある大きさであると言えます。\n\np値との関係:\n\nt検定でp値が 0.002167 と統計的に有意でした（統計的有意性）。\nCohen’s d が 0.414 で中程度の効果を示しています（実質的意義）。\nつまり、この差は統計的に有意であるだけでなく、実務的にも意味のある大きさだと結論できます。\n\n解釈のポイント:\n\nサンプルサイズが大きい場合、小さな差でもp値が有意になることがあります。\n効果量を確認することで、その差が実質的に意味があるかどうかを判断できます。\np値と効果量を併せて報告することが重要 です。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#課題",
    "href": "10_hypothesis_2.html#課題",
    "title": "第10回 仮説検定 (2)",
    "section": "課題",
    "text": "課題\n\n喫煙の有無とチップ: tips データを使って、喫煙者 (Smoker) と非喫煙者 (Non-Smoker) で、チップの額 (tip) に差があるかを検定してください（Welchのt検定）。 また、その差の効果量 (Cohen’s d) を計算し、統計的有意性と実質的意味について論じてください。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#練習問題",
    "href": "10_hypothesis_2.html#練習問題",
    "title": "第10回 仮説検定 (2)",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 検定の選択\n以下のシナリオにおいて、最も適切な検定手法（対応ありt検定 / 対応なし(Welch)t検定）を選んでください。 1. A組30人とB組30人のテストの平均点の比較。 2. 高血圧患者30人の、降圧剤投与前と投与後の血圧の比較。 3. 10組の双子における、兄と弟の身長の比較。\n\n\n練習2: サンプルサイズとp値\n効果量 \\(d=0.5\\) （中程度）の差がある2つの母集団から、 (a) \\(n=10\\) ずつ (b) \\(n=100\\) ずつ データを抽出し、t検定を行った場合のp値をシミュレーションで比較してください。サンプルサイズがp値に与える影響を確認します。\n\n\n練習3: 等分散性の確認はいらない？\n「まずF検定をしてからt検定の種類を選ぶ」という手順が、現在では推奨されない理由を自分の言葉で説明してください。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#検定のまとめ",
    "href": "10_hypothesis_2.html#検定のまとめ",
    "title": "第10回 仮説検定 (2)",
    "section": "検定のまとめ",
    "text": "検定のまとめ\n\n\n\n\n\n\n\n\n検定\n用途\nR関数\n\n\n\n\n1標本t検定\n1群の平均と特定の値の比較\nt.test(x, mu = value)\n\n\n2標本t検定（対応なし）\n独立した2群の平均の比較\nt.test(y ~ group, data)\n\n\n2標本t検定（対応あり）\n対応のある2群の平均の比較\nt.test(x, y, paired = TRUE)\n\n\nF検定\n2群の分散の比較\nvar.test(y ~ group, data)",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "11_regression_1.html",
    "href": "11_regression_1.html",
    "title": "第11回 相関と単回帰分析",
    "section": "",
    "text": "未来を予測する魔法\n「もっと勉強したら、成績はどれくらい上がる？」 「気温が1度上がったら、ビールは何本多く売れる？」\nもし、あるデータ (\\(X\\)) を知ることで、未知のデータ (\\(Y\\)) を予測できるとしたら？ それはビジネスでも科学でも、最強の武器になる。\n今回は、2つのデータの関係性を読み解き、未来を予測するための数理モデル 単回帰分析 を習得しよう。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#今回の目標",
    "href": "11_regression_1.html#今回の目標",
    "title": "第11回 相関と単回帰分析",
    "section": "",
    "text": "相関係数を計算し、2変数の関係の強さを理解する。\n単回帰分析を行い、結果（切片、傾き）を解釈する。\n回帰分析の仮定と診断を学ぶ。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#相関-correlation",
    "href": "11_regression_1.html#相関-correlation",
    "title": "第11回 相関と単回帰分析",
    "section": "相関 (Correlation)",
    "text": "相関 (Correlation)\n2つの変数の間に、直線的な関係があるかどうかを表す指標です。 相関係数 \\(r\\) は \\(-1 \\le r \\le 1\\) の値をとり、1に近いほど正の相関、-1に近いほど負の相関、0に近いほど無相関を表します。\n\n相関係数の計算\n\\[r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\sum_{i=1}^{n}(y_i - \\bar{y})^2}}\\]\ntips データの total_bill と tip の相関係数を計算してみましょう。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\ncor(tips$total_bill, tips$tip)\n#&gt; [1] 0.6757341\n\n\n\n相関係数の解釈\n\n\n\n相関係数の絶対値\n解釈\n\n\n\n\n0.0 - 0.2\nほぼ相関なし\n\n\n0.2 - 0.4\n弱い相関\n\n\n0.4 - 0.7\n中程度の相関\n\n\n0.7 - 1.0\n強い相関\n\n\n\n\n\n相関行列\n複数の変数間の相関を一度に確認できます。\n\n# 数値変数だけを選んで相関行列を作成\ntips %&gt;%\n  select(total_bill, tip, size) %&gt;%\n  cor()\n#&gt;            total_bill       tip      size\n#&gt; total_bill  1.0000000 0.6757341 0.5983151\n#&gt; tip         0.6757341 1.0000000 0.4892988\n#&gt; size        0.5983151 0.4892988 1.0000000\n\n\n\n相関係数の検定\n相関係数が0と有意に異なるかを検定できます。\n\ncor.test(tips$total_bill, tips$tip)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  tips$total_bill and tips$tip\n#&gt; t = 14.26, df = 242, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.6011647 0.7386372\n#&gt; sample estimates:\n#&gt;       cor \n#&gt; 0.6757341",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#単回帰分析-simple-linear-regression",
    "href": "11_regression_1.html#単回帰分析-simple-linear-regression",
    "title": "第11回 相関と単回帰分析",
    "section": "単回帰分析 (Simple Linear Regression)",
    "text": "単回帰分析 (Simple Linear Regression)\nある変数 \\(x\\)（説明変数）を使って、別の変数 \\(y\\)（被説明変数）を予測・説明するモデルを作ります。\n\\[ y = \\beta_0 + \\beta_1 x + \\epsilon \\]\n\n\\(\\beta_0\\): 切片 (Intercept)\n\\(\\beta_1\\): 傾き (Slope)\n\\(\\epsilon\\): 誤差項\n\nRでは lm() 関数（Linear Model）を使います。 「支払総額 (\\(x\\)) が増えると、チップ (\\(y\\)) はどれくらい増えるか？」を分析します。\n\nmodel &lt;- lm(tip ~ total_bill, data = tips)\nsummary(model)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.1982 -0.5652 -0.0974  0.4863  3.7434 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 0.920270   0.159735   5.761 2.53e-08 ***\n#&gt; total_bill  0.105025   0.007365  14.260  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.022 on 242 degrees of freedom\n#&gt; Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 \n#&gt; F-statistic: 203.4 on 1 and 242 DF,  p-value: &lt; 2.2e-16\n\n\n結果の解釈\nCoefficients: の部分を見ます。\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.920270   0.159735   5.761 2.53e-08 ***\ntotal_bill  0.105025   0.007365  14.260  &lt; 2e-16 ***\n\n(Intercept) の Estimate: 0.92\n\n切片です。\\(x\\)（支払総額）が0のときの \\(y\\)（チップ）の予測値です。\nただし、支払総額が0ドルということは現実にはあり得ないので、この値自体に深い意味はないことが多いです。\n\ntotal_bill の Estimate: 0.105\n\n傾きです。これが最も重要な数値です。\n「支払総額が1ドル増えると、チップは約0.105ドル（約10.5セント）増える傾向がある」 と解釈します。\n\nPr(&gt;|t|):\n\ntotal_bill の行を見ると &lt; 2e-16 となっています。これは \\(2 \\times 10^{-16}\\) 未満という非常に小さな値です。\n0.05よりはるかに小さいため、「傾きは0ではない（支払総額とチップには統計的に有意な関係がある）」と結論づけられます。\n\n\n\n\n散布図に回帰直線を引く\nggplot2 で geom_smooth(method = \"lm\") を使うと、簡単に回帰直線を追加できます。\n\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"red\")\n\n\n\n\n\n\n\n\n\n\n残差プロット\n回帰分析がうまくいっているか確認するために、予測値と残差（予測とのズレ）の関係を見ることがあります。\n\n# データフレームに予測値と残差を追加 {.unnumbered}\ntips_aug &lt;- tips %&gt;%\n  mutate(pred = predict(model), resid = residuals(model))\n\nggplot(tips_aug, aes(x = pred, y = resid)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"残差プロット\", x = \"予測値\", y = \"残差\")\n\n\n\n\n\n\n\n\n良い回帰モデルでは： - 残差が0の周りにランダムに散らばっている - 残差にパターンがない（扇形になっていない等）",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#決定係数-r-squared",
    "href": "11_regression_1.html#決定係数-r-squared",
    "title": "第11回 相関と単回帰分析",
    "section": "決定係数 (R-squared)",
    "text": "決定係数 (R-squared)\n回帰モデルがデータをどれくらい説明できているかを表す指標です。\n\\[R^2 = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}\\]\n\n\\(R^2 = 0\\): モデルは全く説明力がない\n\\(R^2 = 1\\): モデルはデータを完全に説明できる\n\n\n# summaryから決定係数を確認\nsummary(model)$r.squared\n#&gt; [1] 0.4566166\n\n今回のモデルでは約0.46、つまりチップの変動の約46%を支払総額で説明できています。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#回帰分析の仮定",
    "href": "11_regression_1.html#回帰分析の仮定",
    "title": "第11回 相関と単回帰分析",
    "section": "回帰分析の仮定",
    "text": "回帰分析の仮定\n回帰分析が正しく機能するためには、いくつかの仮定が必要です：\n\n線形性: \\(x\\) と \\(y\\) の関係が線形である\n独立性: 観測値が互いに独立\n等分散性: 残差の分散が一定\n正規性: 残差が正規分布に従う\n\n\n仮定の診断\n\n# 残差の正規性を確認（Q-Qプロット）\nggplot(tips_aug, aes(sample = resid)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"残差のQ-Qプロット\")",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#課題",
    "href": "11_regression_1.html#課題",
    "title": "第11回 相関と単回帰分析",
    "section": "課題",
    "text": "課題\n\n単回帰分析の実践: tips データを用いて、size（客数）を説明変数、\\(Y=\\) total_bill（支払総額）を被説明変数とする単回帰分析を行ってください。 得られた傾き \\(\\hat{\\beta}_1\\) の値を解釈し、その統計的有意性について述べてください。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#練習問題",
    "href": "11_regression_1.html#練習問題",
    "title": "第11回 相関と単回帰分析",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 相関の罠\n架空のデータにおいて、「アイスクリームの売上」と「水難事故の件数」に強い正の相関が見られました。 これは「アイスクリームを食べることが水難事故の原因である」ことを意味しますか？第三の要因（交絡因子）を挙げて説明してください。\n\n\n練習2: 決定係数の解釈\nある回帰モデルの決定係数が \\(R^2 = 0.05\\) でしたが、傾きの検定は \\(p &lt; 0.001\\) で有意でした。 この結果はどう解釈すべきですか？「モデルは無意味」ですか、それとも「関係はあるが予測精度は低い」ですか？\n\n\n練習3: 残差のパターン\n残差プロットにおいて、残差がU字型のパターンを描いていました。これはモデルの何の仮定に違反している可能性が高いですか？（ヒント：線形性）",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#回帰分析のまとめ",
    "href": "11_regression_1.html#回帰分析のまとめ",
    "title": "第11回 相関と単回帰分析",
    "section": "回帰分析のまとめ",
    "text": "回帰分析のまとめ\n\n\n\n用語\n説明\n\n\n\n\n被説明変数（目的変数）\n予測したい変数 \\(y\\)\n\n\n説明変数（予測変数）\n予測に使う変数 \\(x\\)\n\n\n切片\n\\(x = 0\\) のときの \\(y\\) の値\n\n\n傾き\n\\(x\\) が1単位増えたときの \\(y\\) の変化量\n\n\n残差\n実測値と予測値の差\n\n\n決定係数\nモデルの説明力（0〜1）",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "12_regression_2.html",
    "href": "12_regression_2.html",
    "title": "第12回 重回帰分析と因果推論",
    "section": "",
    "text": "複雑な現実を解き明かす\n「勉強すれば成績は上がる」と言うが、成績に影響するのは勉強時間だけだろうか？ 地頭の良さ、塾の有無、親の収入、睡眠時間……現実は無数の要因が絡み合っている。\nたった一つの原因で結果が決まることなど、世の中にはほとんどない。 だからこそ、複数の要因を同時に扱う 重回帰分析 が必要になる。\n今回は、絡み合った糸をほぐし、真の原因（因果関係）を見つけ出すための探偵技術を学ぼう。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#今回の目標",
    "href": "12_regression_2.html#今回の目標",
    "title": "第12回 重回帰分析と因果推論",
    "section": "",
    "text": "複数の説明変数を使う重回帰分析を理解する。\n回帰分析の結果を「因果関係」として解釈する際の注意点（交絡因子など）を学ぶ。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#重回帰分析-multiple-regression",
    "href": "12_regression_2.html#重回帰分析-multiple-regression",
    "title": "第12回 重回帰分析と因果推論",
    "section": "重回帰分析 (Multiple Regression)",
    "text": "重回帰分析 (Multiple Regression)\n\n重回帰分析とは\n説明変数が2つ以上ある回帰分析を重回帰分析といいます。\n\\[ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k + \\epsilon \\]\nここで：\n\n\\(y\\)：被説明変数（目的変数）\n\\(x_1, x_2, \\dots, x_k\\)：説明変数\n\\(\\beta_0\\)：切片\n\\(\\beta_1, \\beta_2, \\dots, \\beta_k\\)：偏回帰係数\n\\(\\epsilon\\)：誤差項\n\n重回帰分析の最大の強みは、「他の条件を一定としたとき（ceteris paribus）」の影響力を推定できることです。これは経済学において非常に重要な概念です。\n\n\n基本的な重回帰分析の例\ntips データで、チップの額 (tip) を、支払総額 (total_bill) と人数 (size) の両方で説明してみましょう。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\nmodel2 &lt;- lm(tip ~ total_bill + size, data = tips)\nsummary(model2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill + size, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.9279 -0.5547 -0.0852  0.5095  4.0425 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 0.668945   0.193609   3.455  0.00065 ***\n#&gt; total_bill  0.092713   0.009115  10.172  &lt; 2e-16 ***\n#&gt; size        0.192598   0.085315   2.258  0.02487 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.014 on 241 degrees of freedom\n#&gt; Multiple R-squared:  0.4679, Adjusted R-squared:  0.4635 \n#&gt; F-statistic: 105.9 on 2 and 241 DF,  p-value: &lt; 2.2e-16\n\n結果の解釈:\n\ntotal_bill の係数: 0.093\n\n「人数 (size) を固定したときに（同じ人数のグループ同士で比べたときに）」、支払総額が1ドル増えると、チップは約0.093ドル増えることを意味します。\n単回帰のとき（0.105）より少し値が小さくなりました。これは、人数という要因をコントロールしたためです。\n\nsize の係数: 0.193\n\n「支払総額 (total_bill) を固定したときに（同じ支払額のグループ同士で比べたときに）」、人数が1人増えると、チップは約0.193ドル増えることを意味します。\np値 (0.02487) は 0.05 より小さいので、統計的に有意です。つまり、支払額が同じでも、人数が多いほうがチップが多くなる傾向があると言えます。\n\n\n\n\n単回帰と重回帰の比較\n同じデータで単回帰と重回帰を比較してみましょう。\n\n# 単回帰モデル\nmodel_simple &lt;- lm(tip ~ total_bill, data = tips)\n\n# 結果の比較\ncat(\"【単回帰】tip ~ total_bill\\n\")\n#&gt; 【単回帰】tip ~ total_bill\ncoef(model_simple)\n#&gt; (Intercept)  total_bill \n#&gt;   0.9202696   0.1050245\n\ncat(\"\\n【重回帰】tip ~ total_bill + size\\n\")\n#&gt; \n#&gt; 【重回帰】tip ~ total_bill + size\ncoef(model2)\n#&gt; (Intercept)  total_bill        size \n#&gt;  0.66894474  0.09271334  0.19259779\n\ntotal_bill の係数が単回帰では約0.105、重回帰では約0.093となっています。この差は、人数（size）をコントロールすることで生じたものです。\n\n\n決定係数の比較\n\ncat(\"単回帰のR²:\", summary(model_simple)$r.squared, \"\\n\")\n#&gt; 単回帰のR²: 0.4566166\ncat(\"重回帰のR²:\", summary(model2)$r.squared, \"\\n\")\n#&gt; 重回帰のR²: 0.4678693\n\n説明変数を追加することで、モデルの説明力（\\(R^2\\)）が向上していることがわかります。\n\n\n係数の可視化 (Coefficient Plot)\n重回帰分析の結果（推定値と信頼区間）をグラフにすると、どの変数の影響が大きいか分かりやすくなります。\n\nlibrary(broom)\n\n# モデルの結果を整理されたデータフレームにする {.unnumbered}\ntidy_model &lt;- tidy(model2, conf.int = TRUE)\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\"))\n# 切片(Intercept)を除いてプロット {.unnumbered}\ntidy_model %&gt;%\n  filter(term != \"(Intercept)\") %&gt;%\n  ggplot(aes(x = estimate, y = term)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"重回帰分析の係数プロット (95%信頼区間)\", x = \"推定値\", y = \"説明変数\")",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#ダミー変数を使った回帰分析",
    "href": "12_regression_2.html#ダミー変数を使った回帰分析",
    "title": "第12回 重回帰分析と因果推論",
    "section": "ダミー変数を使った回帰分析",
    "text": "ダミー変数を使った回帰分析\n\nダミー変数とは\nカテゴリ変数（性別、曜日、地域など）を回帰分析に組み込むために使う0/1の変数です。Rでは、カテゴリ変数（factor型）を説明変数にすると、自動的にダミー変数を作成してくれます。\n\n# 喫煙者かどうかを追加したモデル\nmodel3 &lt;- lm(tip ~ total_bill + size + smoker, data = tips)\nsummary(model3)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill + size + smoker, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.8986 -0.5697 -0.0643  0.5115  4.0630 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.709016   0.204881   3.461 0.000638 ***\n#&gt; total_bill   0.093888   0.009331  10.062  &lt; 2e-16 ***\n#&gt; size         0.180332   0.087803   2.054 0.041077 *  \n#&gt; smokerYes   -0.083433   0.138000  -0.605 0.546028    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.015 on 240 degrees of freedom\n#&gt; Multiple R-squared:  0.4687, Adjusted R-squared:  0.462 \n#&gt; F-statistic: 70.57 on 3 and 240 DF,  p-value: &lt; 2.2e-16\n\nsmokerYes の係数は、非喫煙者（No）を基準としたときの喫煙者（Yes）の効果を表しています。\n\n\n複数のカテゴリ変数を使う\n曜日と時間帯も追加してみましょう。\n\nmodel4 &lt;- lm(tip ~ total_bill + size + smoker + day + time, data = tips)\nsummary(model4)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill + size + smoker + day + time, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.8551 -0.5733 -0.0863  0.4866  4.1034 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.789582   0.346487   2.279   0.0236 *  \n#&gt; total_bill   0.094277   0.009538   9.884   &lt;2e-16 ***\n#&gt; size         0.176374   0.089332   1.974   0.0495 *  \n#&gt; smokerYes   -0.086470   0.146292  -0.591   0.5550    \n#&gt; daySat      -0.125864   0.308524  -0.408   0.6837    \n#&gt; daySun      -0.032578   0.319158  -0.102   0.9188    \n#&gt; dayThur     -0.160946   0.392573  -0.410   0.6822    \n#&gt; timeLunch    0.068146   0.443723   0.154   0.8781    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.022 on 236 degrees of freedom\n#&gt; Multiple R-squared:   0.47,  Adjusted R-squared:  0.4542 \n#&gt; F-statistic: 29.89 on 7 and 236 DF,  p-value: &lt; 2.2e-16\n\n曜日については、Fri（金曜）が基準カテゴリとなり、他の曜日との差が表示されています。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#交互作用項-interaction-term",
    "href": "12_regression_2.html#交互作用項-interaction-term",
    "title": "第12回 重回帰分析と因果推論",
    "section": "交互作用項 (Interaction Term)",
    "text": "交互作用項 (Interaction Term)\n\n交互作用とは\nある説明変数の効果が、別の説明変数の値によって変わる場合があります。例えば、「支払総額がチップに与える影響が、喫煙者と非喫煙者で異なる」といった状況です。\nこれを分析するために、交互作用項を使います。\n\n# 交互作用を含むモデル\nmodel_interaction &lt;- lm(tip ~ total_bill * smoker, data = tips)\nsummary(model_interaction)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill * smoker, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.6789 -0.5238 -0.1205  0.4749  4.8999 \n#&gt; \n#&gt; Coefficients:\n#&gt;                       Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           0.360069   0.202058   1.782 0.076012 .  \n#&gt; total_bill            0.137156   0.009678  14.172  &lt; 2e-16 ***\n#&gt; smokerYes             1.204203   0.312263   3.856 0.000148 ***\n#&gt; total_bill:smokerYes -0.067566   0.014189  -4.762 3.32e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9785 on 240 degrees of freedom\n#&gt; Multiple R-squared:  0.506,  Adjusted R-squared:  0.4998 \n#&gt; F-statistic: 81.95 on 3 and 240 DF,  p-value: &lt; 2.2e-16\n\n結果の見方：\n\ntotal_bill：非喫煙者における支払総額の効果\nsmokerYes：支払総額が0のときの喫煙者と非喫煙者の差（実質的な意味は薄い）\ntotal_bill:smokerYes：交互作用項。喫煙者における支払総額の効果が、非喫煙者と比べてどれだけ異なるか\n\n\n\n交互作用の可視化\n\ntips %&gt;%\n  ggplot(aes(x = total_bill, y = tip, color = smoker)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"喫煙者・非喫煙者別の回帰直線\",\n    x = \"支払総額 (ドル)\",\n    y = \"チップ (ドル)\",\n    color = \"喫煙者\"\n  )",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#多重共線性-multicollinearity",
    "href": "12_regression_2.html#多重共線性-multicollinearity",
    "title": "第12回 重回帰分析と因果推論",
    "section": "多重共線性 (Multicollinearity)",
    "text": "多重共線性 (Multicollinearity)\n\n多重共線性とは\n説明変数同士が強く相関している場合、多重共線性の問題が生じます。これにより：\n\n係数の推定が不安定になる\n標準誤差が大きくなる\n係数の解釈が困難になる\n\n\n\nVIF（分散膨張因子）による診断\n多重共線性の程度は、VIF (Variance Inflation Factor) で確認できます。一般的に VIF &gt; 10 の場合、多重共線性が問題となっている可能性があります。\n\nlibrary(car)\nvif(model2)\n#&gt; total_bill       size \n#&gt;   1.557586   1.557586\n\nVIF が小さい値であれば、多重共線性の問題は深刻ではありません。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#相関と因果",
    "href": "12_regression_2.html#相関と因果",
    "title": "第12回 重回帰分析と因果推論",
    "section": "相関と因果",
    "text": "相関と因果\n\n相関関係と因果関係の違い\n「相関関係がある」ことと「因果関係がある」ことは別です。 例えば、「アイスクリームの売上」と「水難事故の件数」には正の相関がありますが、アイスクリームが事故を引き起こしているわけではありません。 「気温」という第3の変数（交絡因子）が両方に影響しているからです。\n\n\n交絡因子 (Confounding Variable)\n交絡因子とは、原因と結果の両方に影響を与える第3の変数のことです。\n        気温（交絡因子）\n       /    \\\n      ↓      ↓\nアイス売上 → 水難事故（見せかけの相関）\nこの場合、アイスクリームの売上と水難事故の間に直接の因果関係はありませんが、両方とも気温の影響を受けるため、データ上では相関が観察されます。\n\n\n交絡因子をコントロールする\n重回帰分析で交絡因子を説明変数として加えることで、その影響を取り除くことができます。\n例えば、「教育年数が賃金に与える影響」を分析する場合：\n\n# シミュレーションデータの作成\nset.seed(123)\nn &lt;- 200\n\n# 能力（交絡因子）\nability &lt;- rnorm(n, mean = 100, sd = 15)\n\n# 教育年数（能力の影響を受ける）\neducation &lt;- 12 + 0.05 * ability + rnorm(n, sd = 2)\n\n# 賃金（教育と能力の両方の影響を受ける）\nwage &lt;- 20 + 2 * education + 0.3 * ability + rnorm(n, sd = 5)\n\nsim_data &lt;- tibble(wage, education, ability)\n\n能力をコントロールしない場合としない場合を比較：\n\n# 能力をコントロールしない単回帰\nmodel_biased &lt;- lm(wage ~ education, data = sim_data)\n\n# 能力をコントロールした重回帰\nmodel_unbiased &lt;- lm(wage ~ education + ability, data = sim_data)\n\ncat(\"【能力をコントロールしない場合】\\n\")\n#&gt; 【能力をコントロールしない場合】\ncat(\"教育年数の係数:\", coef(model_biased)[\"education\"], \"\\n\\n\")\n#&gt; 教育年数の係数: 2.494524\n\ncat(\"【能力をコントロールした場合】\\n\")\n#&gt; 【能力をコントロールした場合】\ncat(\"教育年数の係数:\", coef(model_unbiased)[\"education\"], \"\\n\")\n#&gt; 教育年数の係数: 1.873354\n\n真の効果は2ですが、能力をコントロールしないと過大評価されることがわかります。\n\n\n因果推論の手法\n経済学の実証分析では、交絡因子の影響を取り除き、真の因果効果を明らかにするために様々な手法が使われます：\n\n重回帰分析：観測可能な交絡因子をコントロール\n操作変数法 (IV)：交絡因子が観測できない場合に使用\n差の差法 (DID)：政策介入の効果を推定\n回帰不連続デザイン (RDD)：閾値を利用した因果推論\n傾向スコアマッチング：処置群と対照群を比較可能にする\n\nこれらの手法は、計量経済学の上級コースで詳しく学ぶことになります。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#モデルの比較と選択",
    "href": "12_regression_2.html#モデルの比較と選択",
    "title": "第12回 重回帰分析と因果推論",
    "section": "モデルの比較と選択",
    "text": "モデルの比較と選択\n\n調整済み決定係数\n複数のモデルを比較する際、単純な \\(R^2\\) は説明変数を増やすほど大きくなるため、調整済み決定係数 (\\(\\bar{R}^2\\)) を使います。\n\\[ \\bar{R}^2 = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1} \\]\nここで \\(n\\) は標本サイズ、\\(k\\) は説明変数の数です。\n\n# 異なるモデルの調整済みR²を比較\nmodels &lt;- list(\n  \"model1: tip ~ total_bill\" = model_simple,\n  \"model2: tip ~ total_bill + size\" = model2,\n  \"model3: tip ~ total_bill + size + smoker\" = model3,\n  \"model4: tip ~ total_bill + size + smoker + day + time\" = model4\n)\n\nsapply(models, function(m) summary(m)$adj.r.squared)\n#&gt;                              model1: tip ~ total_bill \n#&gt;                                             0.4543712 \n#&gt;                       model2: tip ~ total_bill + size \n#&gt;                                             0.4634533 \n#&gt;              model3: tip ~ total_bill + size + smoker \n#&gt;                                             0.4620370 \n#&gt; model4: tip ~ total_bill + size + smoker + day + time \n#&gt;                                             0.4542383\n\n\n\nAIC と BIC\nAIC (赤池情報量規準) と BIC (ベイズ情報量規準) は、モデルの適合度と複雑さのバランスを評価する指標です。値が小さいほど良いモデルとされます。\n\n# AIC と BIC の比較\ntibble(\n  model = names(models),\n  AIC = sapply(models, AIC),\n  BIC = sapply(models, BIC)\n)",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#講義のまとめ",
    "href": "12_regression_2.html#講義のまとめ",
    "title": "第12回 重回帰分析と因果推論",
    "section": "講義のまとめ",
    "text": "講義のまとめ\n本講義では、データの読み込みから可視化、基本的な統計的推測、そして回帰分析による因果へのアプローチまでを学びました。 これらはデータサイエンスの基礎体力となるスキルです。 さらに深く学びたい方は、計量経済学や機械学習のコースへ進むことを推奨します。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#最終課題",
    "href": "12_regression_2.html#最終課題",
    "title": "第12回 重回帰分析と因果推論",
    "section": "最終課題",
    "text": "最終課題\n自分の興味のあるデータセット（Rの組み込みデータやWeb上のオープンデータ）を見つけ、以下の分析レポートを作成してください。\n\n問いの設定: 何を明らかにしたいか（例：燃費に影響するのは重量か馬力か？）\nデータの可視化: ヒストグラムや散布図による概観。\nモデリング: 適切な回帰モデルの構築。\n結果の解釈: 推定された係数の意味と、統計的な妥当性。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#練習問題",
    "href": "12_regression_2.html#練習問題",
    "title": "第12回 重回帰分析と因果推論",
    "section": "練習問題",
    "text": "練習問題\n\nモデル選択の実践: mtcars データセットにおいて、燃費 (mpg) を説明する最適な変数の組み合わせを、調整済み \\(R^2\\) や AIC を用いて探してください。\n交互作用の解釈: 先ほどの喫煙者と支払額の交互作用モデルについて、具体的な数値を用いて、「喫煙者なら10ドル増えるごとにチップはどう変わるか」を説明してください。\n交絡の発見: あなたの身の回りで「相関はあるが因果ではない（共通の原因がある）」と思われる例を挙げ、因果図を描いて説明してください。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "05_probability.html#連続確率変数",
    "href": "05_probability.html#連続確率変数",
    "title": "第5回 確率論の基礎",
    "section": "連続確率変数",
    "text": "連続確率変数\nこれまで見てきたサイコロやコインのような離散型確率変数とは異なり、連続型確率変数は連続的な値をとる確率変数です。 例えば、身長、体重、気温、株価などがこれにあたります。\n\n離散型と連続型の違い\n離散型確率変数: - とりうる値が飛び飛び（例：サイコロの目 1, 2, 3, 4, 5, 6） - 確率は \\(P(X = x)\\) で表される - 確率の合計は1: \\(\\sum P(X=x_i) = 1\\)\n連続型確率変数: - とりうる値が連続的（例：身長 170.5cm, 170.51cm, …） - 特定の値をとる確率は0: \\(P(X = x) = 0\\) - 代わりに、ある範囲に入る確率を考える: \\(P(a \\leq X \\leq b)\\)\n\n\n確率密度関数 (Probability Density Function)\n連続型確率変数の分布は、確率密度関数 \\(f(x)\\) で表されます。 確率密度関数には以下の性質があります：\n\n\\(f(x) \\geq 0\\) （常に0以上）\n\\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\) （全体の面積が1）\n\\(P(a \\leq X \\leq b) = \\int_a^b f(x) dx\\) （範囲 \\([a, b]\\) に入る確率は、その区間の面積）\n\n\n\n連続型確率変数の期待値と分散\n期待値（離散型の \\(\\sum\\) が \\(\\int\\) に変わる）: \\[E[X] = \\int_{-\\infty}^{\\infty} x f(x) dx\\]\n分散: \\[V[X] = E[(X - E[X])^2] = \\int_{-\\infty}^{\\infty} (x - E[X])^2 f(x) dx\\]\nまたは: \\[V[X] = E[X^2] - (E[X])^2\\]\n\n\n離散型との比較\n\n\n\n\n\n\n\n\n性質\n離散型確率変数\n連続型確率変数\n\n\n\n\n確率の表し方\n\\(P(X = x)\\)\n確率密度 \\(f(x)\\)\n\n\n期待値\n\\(E[X] = \\sum x_i P(X=x_i)\\)\n\\(E[X] = \\int x f(x) dx\\)\n\n\n分散\n\\(V[X] = \\sum (x_i - E[X])^2 P(X=x_i)\\)\n\\(V[X] = \\int (x - E[X])^2 f(x) dx\\)\n\n\n確率の計算\n足し算 \\(\\sum\\)\n積分 \\(\\int\\)\n\n\n全確率\n\\(\\sum P(X=x_i) = 1\\)\n\\(\\int f(x) dx = 1\\)\n\n\n\n\n\n連続型確率変数の例：一様分布\n最も単純な連続型確率分布は一様分布です。 0から1の間で、どの値も等しい確率（密度）で現れる分布です。\n\n# 一様分布の確率密度関数を可視化\nx &lt;- seq(0, 1, length.out = 100)\nf_x &lt;- dunif(x, min = 0, max = 1)  # 一様分布の密度関数\n\ndf &lt;- data.frame(x, f_x)\n\nggplot(df, aes(x = x, y = f_x)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line(color = \"blue\", size = 1.5) +\n  ylim(0, 1.5) +\n  labs(title = \"一様分布 U(0,1) の確率密度関数\", \n       x = \"x\", y = \"確率密度 f(x)\")\n\n\n\n\n\n\n\n\n一様分布 \\(U(0, 1)\\) の期待値と分散：\n\n# 一様分布の期待値（理論値は 0.5）\n# E[X] = ∫ x*f(x)dx = ∫₀¹ x*1 dx = 0.5\n\n# 一様分布の分散（理論値は 1/12 ≈ 0.0833）\n# V[X] = E[X²] - (E[X])² = 1/3 - 1/4 = 1/12\n\n# 乱数を発生させて確認\nset.seed(123)\nsamples &lt;- runif(10000)  # 10000個の乱数を生成\n\ncat(\"サンプル平均（期待値の推定）:\", mean(samples), \"\\n\")\n#&gt; サンプル平均（期待値の推定）: 0.4975494\ncat(\"理論的な期待値:\", 0.5, \"\\n\\n\")\n#&gt; 理論的な期待値: 0.5\n\ncat(\"サンプル分散（分散の推定）:\", var(samples), \"\\n\")\n#&gt; サンプル分散（分散の推定）: 0.08219329\ncat(\"理論的な分散:\", 1/12, \"\\n\")\n#&gt; 理論的な分散: 0.08333333\n\n\n\n重要：離散型と連続型で共通する性質\n期待値の性質（どちらも同じ）: 1. \\(E[X + c] = E[X] + c\\) 2. \\(E[cX] = c \\cdot E[X]\\) 3. \\(E[aX + bY] = aE[X] + bE[Y]\\)\n分散の性質（どちらも同じ）: 1. \\(V[X + c] = V[X]\\) 2. \\(V[cX] = c^2 \\cdot V[X]\\) 3. \\(V[X] = E[X^2] - (E[X])^2\\)\nこれらの性質は、離散型でも連続型でも成り立つ普遍的な性質です。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "06_distributions.html#ベルヌーイ分布-bernoulli-distribution",
    "href": "06_distributions.html#ベルヌーイ分布-bernoulli-distribution",
    "title": "第6回 主要な確率分布",
    "section": "ベルヌーイ分布 (Bernoulli Distribution)",
    "text": "ベルヌーイ分布 (Bernoulli Distribution)\nベルヌーイ分布は、最も基本的な離散型確率分布で、1回だけの試行で成功か失敗かのどちらかの結果が出る確率変数を表します。\n\n定義\n結果が2通り（成功/失敗、表/裏、1/0など）しかない1回の試行を考えます。 - 成功する確率を \\(p\\) - 失敗する確率を \\(1-p\\)\nとすると、確率変数 \\(X\\) は以下の値をとります：\n\\[X = \\begin{cases}\n1 & \\text{成功の場合（確率 } p \\text{）} \\\\\n0 & \\text{失敗の場合（確率 } 1-p \\text{）}\n\\end{cases}\\]\n確率質量関数は： \\[P(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0, 1\\}\\]\n\n\n期待値と分散\nベルヌーイ分布の期待値と分散は： - 期待値: \\(E[X] = p\\) - 分散: \\(V[X] = p(1-p)\\)\n\n\nRでの実装例\nコインを1回投げて表が出る（成功）確率が0.5の場合：\n\n# ベルヌーイ試行のシミュレーション（表が出る確率 p = 0.5）\nset.seed(123)\np &lt;- 0.5\n\n# 1回の試行\nrbinom(1, size = 1, prob = p)  # size=1 でベルヌーイ分布\n#&gt; [1] 0\n\n# 10回のベルヌーイ試行を実施\ntrials &lt;- rbinom(10, size = 1, prob = p)\ncat(\"10回の試行結果:\", trials, \"\\n\")\n#&gt; 10回の試行結果: 1 0 1 1 0 1 1 1 0 1\ncat(\"成功回数:\", sum(trials), \"\\n\")\n#&gt; 成功回数: 7\n\n\n\nベルヌーイ分布の確率分布\n\n# ベルヌーイ分布（p = 0.3）の確率分布\np &lt;- 0.3\nx &lt;- c(0, 1)\nprob_bern &lt;- c(1-p, p)\n\ndf_bern &lt;- data.frame(\n  x = factor(x, labels = c(\"失敗 (0)\", \"成功 (1)\")),\n  prob = prob_bern\n)\n\nggplot(df_bern, aes(x = x, y = prob)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_col(fill = \"steelblue\", width = 0.5) +\n  ylim(0, 1) +\n  labs(title = \"ベルヌーイ分布 (p = 0.3)\", \n       x = \"結果\", y = \"確率\") +\n  geom_text(aes(label = round(prob, 2)), vjust = -0.5)",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#カイ二乗分布t分布f分布",
    "href": "06_distributions.html#カイ二乗分布t分布f分布",
    "title": "第6回 主要な確率分布",
    "section": "カイ二乗分布・t分布・F分布",
    "text": "カイ二乗分布・t分布・F分布\nここまで、正規分布と二項分布（離散型確率分布）を学びました。 正規分布が中心極限定理により統計的推測の基礎となることを見てきましたが、実際の統計的推測（推定や検定）では、正規分布から派生した以下の3つの分布も頻繁に使われます。\n次回以降の講義で詳しく使い方を学びますが、ここではその概要を紹介します。\n\nカイ二乗分布 (Chi-square Distribution)\n標準正規分布に従う独立な確率変数を2乗して足し合わせた分布です。\n定義: \\(Z_1, Z_2, \\ldots, Z_k\\) が独立に標準正規分布 \\(N(0,1)\\) に従うとき、 \\[\\chi^2 = Z_1^2 + Z_2^2 + \\cdots + Z_k^2\\] は自由度 \\(k\\) のカイ二乗分布に従います。記号では \\(\\chi^2(k)\\) と書きます。\n性質: - パラメータは自由度 \\(k\\) のみ - 期待値: \\(E[\\chi^2] = k\\) - 分散: \\(V[\\chi^2] = 2k\\) - 常に正の値をとる（右に偏った分布）\n用途: 分散の推定、適合度検定、独立性の検定など\n\n# カイ二乗分布の可視化（自由度による違い）\nx &lt;- seq(0, 20, length.out = 200)\ndf_chi &lt;- data.frame(\n  x = rep(x, 3),\n  y = c(dchisq(x, df = 2),\n        dchisq(x, df = 5),\n        dchisq(x, df = 10)),\n  df = rep(c(\"自由度=2\", \"自由度=5\", \"自由度=10\"), each = length(x))\n)\n\nggplot(df_chi, aes(x = x, y = y, color = df)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line(size = 1) +\n  labs(title = \"カイ二乗分布（自由度による変化）\", \n       x = \"値\", y = \"確率密度\", color = \"自由度\")\n\n\n\n\n\n\n\n\n\n\nt分布 (Student’s t-distribution)\n正規分布に似ているが、裾が厚い（外れ値が出やすい）分布です。 標本サイズが小さいときの検定や信頼区間の構築に使われます。\n定義: \\(Z \\sim N(0,1)\\) と \\(V \\sim \\chi^2(k)\\) が独立のとき、 \\[t = \\frac{Z}{\\sqrt{V/k}}\\] は自由度 \\(k\\) のt分布に従います。記号では \\(t(k)\\) と書きます。\n性質: - パラメータは自由度 \\(k\\) のみ - 平均0を中心とした対称な分布 - 自由度が大きくなると正規分布に近づく - 自由度が小さいほど裾が厚い\n用途: t検定、回帰係数の検定、平均値の信頼区間など\n\n# t分布と正規分布の比較\nx &lt;- seq(-4, 4, length.out = 200)\ndf_t &lt;- data.frame(\n  x = rep(x, 4),\n  y = c(dt(x, df = 1),\n        dt(x, df = 3),\n        dt(x, df = 10),\n        dnorm(x)),\n  type = rep(c(\"t分布 (df=1)\", \"t分布 (df=3)\", \n               \"t分布 (df=10)\", \"標準正規分布\"), each = length(x))\n)\n\nggplot(df_t, aes(x = x, y = y, color = type)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line(size = 1) +\n  labs(title = \"t分布と標準正規分布の比較\", \n       x = \"値\", y = \"確率密度\", color = \"分布\")\n\n\n\n\n\n\n\n\n\n\nF分布 (F-distribution)\n2つのカイ二乗分布の比として定義される分布です。 分散の比の検定や分散分析（ANOVA）で使われます。\n定義: \\(V_1 \\sim \\chi^2(k_1)\\) と \\(V_2 \\sim \\chi^2(k_2)\\) が独立のとき、 \\[F = \\frac{V_1/k_1}{V_2/k_2}\\] は自由度 \\((k_1, k_2)\\) のF分布に従います。記号では \\(F(k_1, k_2)\\) と書きます。\n性質: - パラメータは2つの自由度 \\(k_1\\)（分子の自由度）と \\(k_2\\)（分母の自由度） - 常に正の値をとる - 右に偏った分布\n用途: 分散の比の検定、分散分析（ANOVA）、回帰分析のF検定など\n\n# F分布の可視化\nx &lt;- seq(0, 5, length.out = 200)\ndf_f &lt;- data.frame(\n  x = rep(x, 3),\n  y = c(df(x, df1 = 5, df2 = 10),\n        df(x, df1 = 10, df2 = 10),\n        df(x, df1 = 20, df2 = 10)),\n  df = rep(c(\"F(5,10)\", \"F(10,10)\", \"F(20,10)\"), each = length(x))\n)\n\nggplot(df_f, aes(x = x, y = y, color = df)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line(size = 1) +\n  labs(title = \"F分布（自由度による変化）\", \n       x = \"値\", y = \"確率密度\", color = \"自由度\")\n\n\n\n\n\n\n\n\n\n\n3つの分布の関係\nこれらの分布は互いに関連しています：\n\nカイ二乗分布: 標準正規分布の2乗和\nt分布: 標準正規分布 ÷ √(カイ二乗分布/自由度)\nF分布: (カイ二乗分布/自由度) ÷ (カイ二乗分布/自由度)\n\nこれらは全て正規分布から導かれる分布で、統計的推測の基礎となります。 次回以降の講義（推定、検定、回帰分析）で実際に使用していきます。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "02_data.html#本節の目的",
    "href": "02_data.html#本節の目的",
    "title": "第2回 データの構造と扱い",
    "section": "",
    "text": "Rにおけるデータの保持形式（データフレーム）の構造を理解する。\n外部ファイル（CSV形式）をR環境に読み込む手順を確立する。\nTidyverse パッケージ群を用いた、データの抽出・加工・集計手法を習得する。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#パッケージの導入",
    "href": "02_data.html#パッケージの導入",
    "title": "第2回 データの構造と扱い",
    "section": "パッケージの導入",
    "text": "パッケージの導入\nRには、標準機能（Base R）に加え、特定の目的のために機能を拡張する パッケージ という仕組みが存在します。 本講義では、データサイエンスにおける事実上の標準ツールセットである Tidyverse を採用します。\n\nTidyverseの概要\nTidyverseは、一貫した設計思想（Tidy Data principles）に基づいて設計されたRパッケージの集合体です。本講義では主に以下のパッケージを使用します。\n\n\n\nパッケージ\n主な機能\n\n\n\n\nggplot2\nデータの可視化（文法に基づく作図）\n\n\ndplyr\nデータの操作（抽出、加工、集計）\n\n\ntidyr\nデータの整形（整然データへの変換）\n\n\nreadr\nデータの読み込み（高速かつ安全なインポート）\n\n\nstringr\n文字列データの処理\n\n\nforcats\nカテゴリ変数（因子型）の操作\n\n\n\nパッケージを使用するには、環境ごとに一度だけの「インストール」と、Rを起動するたびに行う「ロード」の2段階の手順が必要です。\n1. インストール（初回のみ）\n講義環境（Posit Cloud等）で初めて実施する場合のみ、以下のコードを実行してください。\n\n# install.packages(\"tidyverse\") {.unnumbered}\n\n2. ロード（起動ごと）\nRセッションを開始するたびに、以下のコマンドで機能を有効化（ロード）します。\n\nlibrary(tidyverse)",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データフレームの構造",
    "href": "02_data.html#データフレームの構造",
    "title": "第2回 データの構造と扱い",
    "section": "データフレームの構造",
    "text": "データフレームの構造\n統計分析において、データは一般に「行（観測対象）」と「列（変数）」を持つ表形式で扱われます。Rではこの形式を データフレーム （またはtibble）と定義します。 Rには学習用データセットが標準で同梱されています。ここでは iris（アヤメの計測データ）[要出典] を例に構造を確認します。\n\nhead(iris) # 先頭の6行を表示\n\n\n  \n\n\n\n\n構造の確認手法\n未知のデータを扱う際は、まずその形式的特徴を把握する必要があります。\n\n# データの次元数（行数 × 列数）を確認\ndim(iris)\n#&gt; [1] 150   5\n\n# 変数名（列名）の一覧を取得\nnames(iris)\n#&gt; [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"\n\n# データ型を含む内部構造の要約を表示\nstr(iris)\n#&gt; 'data.frame':    150 obs. of  5 variables:\n#&gt;  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n#&gt;  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n#&gt;  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n#&gt;  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n#&gt;  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\nRにおける主なデータ型\nデータフレーム内の各列は、特定の「データ型」を持ちます。分析の前提として、以下の型区分を理解する必要があります。\n\n\n\nデータ型\n定義\n表記例\n\n\n\n\nnumeric\n実数値（倍精度浮動小数点数）\n1.5, 100, -3.14\n\n\ninteger\n整数値\n1L, 2L, 100L\n\n\ncharacter\n文字列（テキスト情報）\n“東京”, “hello”\n\n\nlogical\n論理値（真偽判定の結果）\nTRUE, FALSE\n\n\nfactor\nカテゴリ（順序や水準を持つ名義尺度）\n男性/女性, 大/中/小",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#外部データの読み込み",
    "href": "02_data.html#外部データの読み込み",
    "title": "第2回 データの構造と扱い",
    "section": "外部データの読み込み",
    "text": "外部データの読み込み\n独自の分析を行うには、外部ファイルとして保存されたデータをR環境に取り込む（インポートする）必要があります。 本講義では、テキスト形式のデータ保存における標準規格であるCSV（Comma-Separated Values）ファイルの読み込みに、readr パッケージの read_csv() 関数を使用します。\n\n# ローカル環境に data.csv が存在する場合のコード例\n# df &lt;- read_csv(\"data.csv\")\n\n\n読み込み関数の比較と選択\n\n\n\n\n\n\n\n\n\n関数\n対象フォーマット\n提供パッケージ\n特徴\n\n\n\n\nread_csv()\nCSV（カンマ区切り）\nreadr (tidyverse)\n高速、文字化けに強い、tibble形式で出力\n\n\nread_tsv()\nTSV（タブ区切り）\nreadr (tidyverse)\nタブ区切りデータ用\n\n\nread_excel()\nExcel (.xlsx)\nreadxl\nExcelファイルを直接読み込む場合に必要\n\n\nread.csv()\nCSV\nbase R\n標準機能だが、文字列をfactor型に自動変換するなど[対象注意]の挙動がある\n\n\n\n\n\nインターネット上のデータの読み込み\n本節では演習用データとして、Bryant & Smith (1995) に基づくレストランのチップ支払いデータ (tips) を使用します。このデータはPythonの可視化ライブラリ seaborn のリポジトリで公開されているものを参照します。\n\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n読み込み直後に、データの概要を確認します。glimpse() は str() のtidyverse版であり、画面幅に合わせた見やすい一覧表示を提供します。\n\nglimpse(tips)\n#&gt; Rows: 244\n#&gt; Columns: 7\n#&gt; $ total_bill &lt;dbl&gt; 16.99, 10.34, 21.01, 23.68, 24.59, 25.29, 8.77, 26.88, 15.0…\n#&gt; $ tip        &lt;dbl&gt; 1.01, 1.66, 3.50, 3.31, 3.61, 4.71, 2.00, 3.12, 1.96, 3.23,…\n#&gt; $ sex        &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\",…\n#&gt; $ smoker     &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n#&gt; $ day        &lt;chr&gt; \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Su…\n#&gt; $ time       &lt;chr&gt; \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\",…\n#&gt; $ size       &lt;dbl&gt; 2, 3, 3, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 3, 3, 3, 3,…\n\n\n\ntipsデータセットの変数の定義\n各変数の定義は以下の通りです。[要一次情報: データセットの詳細な定義書の所在]\n\n\n\n変数名\n定義\n単位/形式\n\n\n\n\ntotal_bill\n請求総額\n米ドル\n\n\ntip\nチップ支払額\n米ドル\n\n\nsex\n支払者の性別\nFemale / Male\n\n\nsmoker\n喫煙席の使用有無\nYes / No\n\n\nday\n来店曜日\nSun, Sat, Thur, Fri\n\n\ntime\n時間帯\nDinner / Lunch\n\n\nsize\n同伴者を含むグループ人数\n人数（整数）",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データ操作-dplyr",
    "href": "02_data.html#データ操作-dplyr",
    "title": "第2回 データの構造と扱い",
    "section": "データ操作 (dplyr)",
    "text": "データ操作 (dplyr)\ndplyr パッケージは、データ操作のための「動詞（Verbs）」となる関数群を提供します。\n\n1. 列の選択: select()\n分析に必要な変数（列）のみを保持した新しいデータフレーム作成します。\n\ntips %&gt;% \n  select(total_bill, tip) %&gt;% \n  head()\n\n\n  \n\n\n\nパイプ演算子 %&gt;% について コード内の %&gt;% は「パイプ演算子」と呼ばれ、前段の処理結果（左側のデータ）を次段の関数（右側）の第一引数として渡す役割を持ちます。これにより、「tipsデータ に対し、selectを実行する」という論理的な記述が可能になります。\n\n\n2. 行の抽出: filter()\n指定した条件に合致する観測（行）のみを抽出します。 以下は、time 変数が “Dinner” と一致する行のみを抽出する例です。\n\ntips %&gt;% \n  filter(time == \"Dinner\") %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n3. 変数の作成・更新: mutate()\n既存の列を用いた計算や変換を行い、その結果を新しい列として追加（または上書き）します。 ここでは、チップの対総額比率を計算します。\n\ntips %&gt;% \n  mutate(tip_rate = tip / total_bill) %&gt;% \n  select(total_bill, tip, tip_rate) %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n4. データの並び替え: arrange()\n指定した列の値を基準に、行を並び替えます。デフォルトは昇順（小さい順）です。\n\n# 支払総額の昇順（小さい順）\ntips %&gt;% \n  arrange(total_bill) %&gt;% \n  head()\n\n\n  \n\n\n\n# 降順（大きい順）にする場合は desc() 関数で指定\ntips %&gt;% \n  arrange(desc(total_bill)) %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n5. 要約統計量の算出: summarize()\nデータの集計を行い、平均値や合計値などの要約統計量を算出します。この操作を行うと、元のデータフレームは集計結果の行数（グループ化していなければ1行）に縮約されます。\n\ntips %&gt;% \n  summarize(\n    平均支払額 = mean(total_bill),\n    平均チップ = mean(tip),\n    データ数 = n() # 行数をカウントする関数\n  )\n\n\n  \n\n\n\nこれを group_by() 関数と組み合わせることで、「グループごとの集計」が可能になります。\n\n# 曜日ごとの平均支払額を計算\ntips %&gt;% \n  group_by(day) %&gt;% \n  summarize(\n    平均支払額 = mean(total_bill),\n    データ数 = n()\n  )",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#パイプ演算子-を用いた処理の連結",
    "href": "02_data.html#パイプ演算子-を用いた処理の連結",
    "title": "第2回 データの構造と扱い",
    "section": "パイプ演算子 %>% を用いた処理の連結",
    "text": "パイプ演算子 %&gt;% を用いた処理の連結\nパイプ演算子を用いる最大の利点は、中間変教を作成することなく、思考の流れ通りに処理を記述できる点にあります。 以下に、「抽出」「加工」「並び替え」「選択」を一連のフローとして記述する例を示します。\n\n# 目的: ディナーのデータを対象に、チップ率（%）を算出し、支払額が高い順に上位10件を表示する\ntips %&gt;% \n  filter(time == \"Dinner\") %&gt;% \n  mutate(tip_rate = tip / total_bill * 100) %&gt;% \n  arrange(desc(total_bill)) %&gt;% \n  select(total_bill, tip, tip_rate, day) %&gt;% \n  head(10)",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データ操作の補足事項",
    "href": "02_data.html#データ操作の補足事項",
    "title": "第2回 データの構造と扱い",
    "section": "データ操作の補足事項",
    "text": "データ操作の補足事項\n\n列の選び方\nRには方言があります。\n\ntips$total_bill：ベクトルとして取り出す（Base R）。計算式の内部で使うことが多い。\ntips %&gt;% select(total_bill)：データフレームとして取り出す（Tidyverse）。データを加工し続ける時に使う。 使い分けですが、パイプラインの中では select でOKです。\n\n\n\nデータのチラ見（可視化）\n数字だけだと見逃します。ggplot2 でサッと可視化する癖をつけてください。\n\nggplot(tips, aes(x = total_bill, y = tip, color = time)) +\n  geom_point()",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#演習課題",
    "href": "02_data.html#演習課題",
    "title": "第2回 データの構造と扱い",
    "section": "演習課題",
    "text": "演習課題\n読み込んだ tips データを使用し、以下の要件を満たすコードを作成・実行してください。\n\nday が “Sun”（日曜日）である行のみを filter() で抽出してください。\n上記で抽出したデータから、total_bill（支払総額）と size（人数）の2列のみを select() で選択し、結果を表示してください。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#dplyr-主要関数一覧",
    "href": "02_data.html#dplyr-主要関数一覧",
    "title": "第2回 データの構造と扱い",
    "section": "dplyr 主要関数一覧",
    "text": "dplyr 主要関数一覧\n本節で扱った主要関数の機能と構文をまとめます。\n\n\n\n関数\n役割\n構文例\n\n\n\n\nselect()\n列（変数）の選択\nselect(data, col1, col2)\n\n\nfilter()\n行（観測）の抽出\nfilter(data, x &gt; 10)\n\n\nmutate()\n列の作成・更新\nmutate(data, new = x + y)\n\n\narrange()\n行の並び替え\narrange(data, x)\n\n\nsummarize()\n集計・要約\nsummarize(data, mean(x))\n\n\ngroup_by()\nグループ化\ngroup_by(data, category)",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "01_intro.html#グラフの描画",
    "href": "01_intro.html#グラフの描画",
    "title": "第1回 RとRStudioの基礎",
    "section": "グラフの描画",
    "text": "グラフの描画\nRの強力な機能の一つである可視化を体験する。ここではRに標準で同梱されているデータセット cars（1920年代の自動車の速度と停止距離のデータ）を使用する。\n\nlibrary(tidyverse)\n# 日本語フォント設定（Macの場合はHiraKakuProN-W3、Windowsの場合はMeiryo等を指定）\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\"))\n\nggplot(cars, aes(x = speed, y = dist)) +\n  geom_point() +\n  labs(title = \"車の速度と停止距離\")\n\n\n\n\n\n\n\n\nggsave(\"figure/01_intro/cars.png\")",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#一般的な演算子と関数",
    "href": "01_intro.html#一般的な演算子と関数",
    "title": "第1回 RとRStudioの基礎",
    "section": "一般的な演算子と関数",
    "text": "一般的な演算子と関数\nデータ分析の実務において頻出する演算子を挙げる。\n\n算術演算子\n\n# 加算\n2 + 3\n#&gt; [1] 5\n\n# 減算\n10 - 4\n#&gt; [1] 6\n\n# 乗算\n5 * 6\n#&gt; [1] 30\n\n# 除算\n20 / 4\n#&gt; [1] 5\n\n# べき乗（累乗）\n2^3\n#&gt; [1] 8\n\n# 剰余（割り算の余り）\n10 %% 3\n#&gt; [1] 1\n\n\n\nベクトルの操作\n\n# ベクトルの定義\nx &lt;- c(1, 2, 3, 4, 5)\n\n# ベクトルに対するスカラー演算（全要素への適用）\nx * 2\n#&gt; [1]  2  4  6  8 10\n\n# 要素数の確認\nlength(x)\n#&gt; [1] 5\n\n# 総和\nsum(x)\n#&gt; [1] 15\n\n# 最大値・最小値\nmax(x)\n#&gt; [1] 5\nmin(x)\n#&gt; [1] 1",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#実践に向けた助言",
    "href": "01_intro.html#実践に向けた助言",
    "title": "第1回 RとRStudioの基礎",
    "section": "実践に向けた助言",
    "text": "実践に向けた助言\n筆者から学習者へのヒントを記す。\n\nヒント1: コメントの活用\nコード内に # を記述すると、それ以降の文字列はプログラムとして実行されない（コメントアウト）。 コードの意図や思考のプロセスを記録することは、将来の自分自身への説明責任を果たすために重要である。\n\n# 変数定義：xは観測値を表す（例）\nx &lt;- 10\n\n\n\nヒント2: エラーへの対処\nエラーの発生は学習プロセスの一部であり、失敗ではない。 エラーメッセージは「何が間違っているか」を示す論理的な指摘である。以下に代表例を挙げる。\n\ncould not find function: 関数名の誤入力、または必要なパッケージがロードされていない。\nobject not found: 変数が定義されていない（実行順序の誤りやタイポ）。\n構文エラー: 括弧 () {} の対応関係が崩れている場合など。\n\n\n\nヒント3: ドキュメントの参照\n関数の正確な仕様（定義、引数、戻り値）を確認する際は、? を用いて公式ヘルプを参照する習慣をつけること。\n\n?mean",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#なぜ今rを学ぶのか",
    "href": "01_intro.html#なぜ今rを学ぶのか",
    "title": "第1回 RとRStudioの基礎",
    "section": "",
    "text": "科学的検証のためのツール\nなぜこれほどRを推すのか。最大の理由は 再現性が確保できるから です。 Excelでの分析は、どうしても「手作業」の連続になります。どのセルをコピーし、どこでフィルタをかけ、どのグラフを選んだか。その履歴を完全に追跡するのは困難です。 一方、Rはすべての操作をコードとして残します。コードは「手順書」そのもの。第三者が同じコードを実行すれば、間違いなく同じ結果が出ます。科学的な検証において、この特性は欠かせません。\nもちろん、実利的なメリットも大きいです。\n\nOSSとコスト: 個人・組織を問わず無料（GPLライセンス）。\n統計機能: 世界中の統計家が開発に参加しており、最新の手法が22,000以上のパッケージ（CRAN）ですぐに使えます。\nキャリア: 定量的研究やデータサイエンスの職務記述書（JD）において、Rスキルは依然として強い武器になります。\n\n（Webアプリ開発やシステムへの組み込みならPythonやC++が適しています。適材適所です）\n\n\nRとExcel：対立ではなく使い分け\nよく「RかExcelか」と二項対立で語られますが、実際は「併用」が正解です。\n\n\n\n\n\n\n\n\nツール\n得意な領域\n苦手な領域\n\n\n\n\nExcel\n直感的な操作、データの閲覧、小規模な集計\n大規模データ（100万行〜）、手順の記録、複雑な統計モデル\n\n\nR\n大規模データの処理、高度な統計解析、再現性のある描画\nデータの直接入力、閲覧（スプレッドシート的な操作）\n\n\n\n私だって、データの概観やちょっとした検算にはExcelを使います。でも、論文に載せる分析や、来月も同じ処理をする業務なら、迷わずRを選びます。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#rstudioというコックピット",
    "href": "01_intro.html#rstudioというコックピット",
    "title": "第1回 RとRStudioの基礎",
    "section": "RStudioという「コックピット」",
    "text": "RStudioという「コックピット」\nR本体はただの「計算エンジン」です。人間が楽に扱うために、統合開発環境（IDE）である RStudio を使います。 画面は4分割されていますが、データの流れで考えると分かりやすいでしょう。\n\nSource Editor (左上)：ここで「指示書（スクリプト）」を書く。\n\n料理ならレシピを書く場所。ここに書いたものだけが「再現可能な記録」として残ります。\n\nConsole (左下)：指示を実行し、結果を受け取る。\n\n実際にRが計算する場所。ちょっとした計算や、中身の確認用です。\n\nEnvironment (右上)：材料（データ・変数）を確認する。\n\nいまメモリ上に何があるかが見えています。\n\nFiles / Plots (右下)：成果物を確認する。\n\n描かれたグラフや、保存されたファイルはここに出ます。\n\n\n基本は、「左上で書いて、左下で実行させて、右と右下で結果を確認する」。この繰り返しです。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#rと対話する計算と変数",
    "href": "01_intro.html#rと対話する計算と変数",
    "title": "第1回 RとRStudioの基礎",
    "section": "Rと対話する（計算と変数）",
    "text": "Rと対話する（計算と変数）\nまずは難しく考えず、Rを「やたら高機能な電卓」として使ってみましょう。 Consoleに直接入力してみてください。\n\n1 + 1\n#&gt; [1] 2\n(100 - 20) / 4\n#&gt; [1] 20\n\n\n情報を箱に入れる：変数\n計算結果を使い捨てにせず、取っておくための箱が 変数（オブジェクト） です。 R独特の記号 &lt;-（代入演算子）を使います。「右の値を左の箱に入れる」イメージの矢印です。\n\nprice &lt;- 1500\namount &lt;- 3\ntotal &lt;- price * amount\ntotal\n#&gt; [1] 4500\n\n大事なのは、price や amount という「名前」でデータを管理できること。「1500」という数値の意味を、人間が覚えておく必要はありません。\n\n\n便利な道具：関数\nよく使う処理は 関数 として用意されています。「機能名(データ)」の形で呼び出します。\n\n# 数値のベクトル（列）を作る c() 関数\nscores &lt;- c(80, 90, 75, 60, 95)\n\n# 平均値を計算する mean() 関数\nmean(scores)\n#&gt; [1] 80\n\n関数は無数にありますが、最初は「やりたいこと（機能）」と「入れるもの（引数）」の対応さえ意識できれば十分です。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#エラーはrからの返信",
    "href": "01_intro.html#エラーはrからの返信",
    "title": "第1回 RとRStudioの基礎",
    "section": "「エラー」はRからの返信",
    "text": "「エラー」はRからの返信\nプログラミング初心者にとって、赤い文字のエラーメッセージは怖いかもしれません。「お前は間違ってる」と怒られた気分になるからでしょう。 でも、誤解です。エラーはRからの「この指示だと、ここが分からなくて実行できません」という、ただの返信です。\n\ncould not find function：「その関数を知りません」（綴りが違うか、パッケージを読み忘れていませんか？）\nobject not found：「その変数が見当たりません」（作る前に使おうとしていませんか？）\n\nエラーが出たら、まずはメッセージを読んでみてください。解決のヒントは必ずそこにあります。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#グラフを描いてみる",
    "href": "01_intro.html#グラフを描いてみる",
    "title": "第1回 RとRStudioの基礎",
    "section": "グラフを描いてみる",
    "text": "グラフを描いてみる\n最後に、Rの「華」、可視化を試してみます。 解説は省きますが、数行書くだけで美しい散布図が描けることを確認してください。\n\nlibrary(tidyverse)\n# [対象注意] 日本語フォント設定は環境により異なります\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\"))\n\nggplot(cars, aes(x = speed, y = dist)) +\n  geom_point() +\n  labs(title = \"車の速度と停止距離\") \n\n\n\n\n\n\n\n\nこのグラフも、コードの数値を少し変えるだけで、明日になっても（あるいは10年後でも）全く同じものを再現できます。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "01_intro.html#構成変更の意図",
    "href": "01_intro.html#構成変更の意図",
    "title": "第1回 RとRStudioの基礎",
    "section": "構成変更の意図",
    "text": "構成変更の意図\n\n導入の刷新: 定型的な「本講義では〜」を廃止し、「なぜRなのか（科学的な正しさ）」という核心からスタートすることで、読者の動機付けを強化しました。\n情報の重み付け: Rのメリットを羅列せず、「再現性」を最重要事項として強調し、コストや機能は実利的な補足として配置しました。\n対立の解消: R vs Excelを「対立」ではなく「使い分け」として再定義し、現場の実感に近い温度感に調整しました。\n操作説明のナラティブ化: 画面構成の説明を「左上から右下へ流れる」というストーリーで繋げ、無味乾燥なリストを回避しました。\nメタファーの使用: エラーを「恐怖」ではなく「コミュニケーション」と定義し直すことで、学習者の心理的障壁を下げる工夫を入れました。",
    "crumbs": [
      "第1回 RとRStudioの基礎"
    ]
  },
  {
    "objectID": "02_data.html#データを整える思想",
    "href": "02_data.html#データを整える思想",
    "title": "第2回 データの構造と扱い",
    "section": "",
    "text": "Tidyverse：人間中心のR\nRにも元々データ操作機能（Base R）はありますが、記法が少し特殊で、覚えるのが大変でした。 そこで生まれたのが Tidyverse です。「人間が読みやすく、書きやすい」ことを最優先に設計された、Rの「新しい方言」だと思ってください。\n\nインストール（世界への入り口）：初回のみ\n\n# install.packages(\"tidyverse\") {.unnumbered}\n\nロード（道具箱を開ける）：起動するたびに必要\n\nlibrary(tidyverse)\n\n\nこれだけで、必要な道具一式（加工、可視化、読み込み…）は揃います。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データフレーム世界を表形式にする",
    "href": "02_data.html#データフレーム世界を表形式にする",
    "title": "第2回 データの構造と扱い",
    "section": "データフレーム：世界を表形式にする",
    "text": "データフレーム：世界を表形式にする\n私たちが分析する社会現象や自然現象は、混沌としています。それをコンピュータが理解できる唯一の形式が「行と列」です。 Rではこれを データフレーム と呼びます。\n\n行（Row）：ひとつの観測単位（1人の人間、1回の取引、1日の記録）\n列（Column）：属性や変数（年齢、金額、気温）\n\n\n現実をRに取り込む（CSV読み込み）\n手元にあるExcelやCSVファイルは、まだ「外の世界」のものです。これをRという「計算の世界」に引き入れる儀式が read_csv() です。\n今回は、Pythonのライブラリ等でもよく使われる tips（レストランのチップ支払い記録）[要出典] をWebから直接読み込んでみます。\n\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# データの「顔」を確認する（tidyverse版のstr()）\nglimpse(tips)\n#&gt; Rows: 244\n#&gt; Columns: 7\n#&gt; $ total_bill &lt;dbl&gt; 16.99, 10.34, 21.01, 23.68, 24.59, 25.29, 8.77, 26.88, 15.0…\n#&gt; $ tip        &lt;dbl&gt; 1.01, 1.66, 3.50, 3.31, 3.61, 4.71, 2.00, 3.12, 1.96, 3.23,…\n#&gt; $ sex        &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\",…\n#&gt; $ smoker     &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n#&gt; $ day        &lt;chr&gt; \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Su…\n#&gt; $ time       &lt;chr&gt; \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\",…\n#&gt; $ size       &lt;dbl&gt; 2, 3, 3, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 3, 3, 3, 3,…\n\n読み込んだ瞬間、変数の型（数値なのか、文字なのか）が自動的に判定されています。Excelでよくある「数字だと思ったら文字として扱われて計算できない」といったトラブルを、入り口で防いでくれるのです。\n[要一次情報: データセットの詳細な定義書の所在]",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データ操作の文法-dplyr",
    "href": "02_data.html#データ操作の文法-dplyr",
    "title": "第2回 データの構造と扱い",
    "section": "データ操作の文法 (dplyr)",
    "text": "データ操作の文法 (dplyr)\nTidyverseの中核である dplyr パッケージは、データを加工するための「5つの動詞」を提供します。 これらはプログラミングの命令というより、英語の文法に近い感覚です。\n\nパイプ演算子 %&gt;%：考えた順に書く\nまず、Tidyverseの象徴である パイプ演算子 %&gt;%（または |&gt;）を概観します。これは「左から右へ、水を流す」イメージです。\n\nBase R: head(select(tips, total_bill)) → 内側から外側へ読む（直感的じゃない）\nTidyverse: tips %&gt;% select(total_bill) %&gt;% head() → 「データを、選んで、先頭を見る」（考えた順）\n\n\n\n1. 切り分ける：select() と filter()\n分析はまず、要らない部分を削ぎ落とすことから始まります。\n列（変数）を選ぶ：select() 「分析に性別と喫煙情報は関係ない」なら、こう。\n\ntips %&gt;% \n  select(total_bill, tip) %&gt;% \n  head()\n\n\n  \n\n\n\n行（観測）を絞る：filter() 「ディナーの客だけ見たい」なら、こう。\n\ntips %&gt;% \n  filter(time == \"Dinner\") %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n2. 加工する：mutate()\n既存の列を使って新しい指標を作るときは mutate()（変化させる）を使います。 「チップの額」そのものより、「支払額に対するチップの割合」の方が意味があるでしょう。\n\ntips %&gt;% \n  mutate(tip_rate = tip / total_bill) %&gt;% \n  select(total_bill, tip, tip_rate) %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n3. 並べる：arrange()\nデータは最初、「記録順」です。これを「意味のある順」に変えます。\n\n# チップを多く払った順（降順）に並べる\ntips %&gt;% \n  arrange(desc(tip)) %&gt;% \n  head()\n\n\n  \n\n\n\n\n\n4. 要約する：group_by() と summarize()\n個別の値より「傾向」が知りたいなら、データをグループにまとめて（group_by）、縮約（summarize）します。 「ランチとディナー、どっちが羽振りがいいのか？」という問いに答えてみましょう。\n\ntips %&gt;% \n  group_by(time) %&gt;% \n  summarize(\n    平均支払額 = mean(total_bill),\n    平均チップ = mean(tip),\n    データ数 = n()\n  )",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#ストーリーとして記述する",
    "href": "02_data.html#ストーリーとして記述する",
    "title": "第2回 データの構造と扱い",
    "section": "ストーリーとして記述する",
    "text": "ストーリーとして記述する\nこれらの「動詞」と「パイプ」を組み合わせることで、複雑なデータ処理も一つのストーリーとして記述できます。\n\n問い：土曜日のディナーに来た客のうち、特にチップを弾んでくれた（総額の20%以上）のはどんな人たちか？支払額が高い順に見たい。\n\nこの思考プロセスをそのままコードにします。\n\ntips %&gt;% \n  filter(day == \"Sat\" & time == \"Dinner\") %&gt;%  # 土曜日のディナー客で\n  mutate(rate = tip / total_bill) %&gt;%          # チップ率を計算し\n  filter(rate &gt;= 0.2) %&gt;%                      # 20%以上に絞り込み\n  arrange(desc(total_bill)) %&gt;%                # 支払額が高い順に並べる\n  select(sex, size, total_bill, tip, rate)     # 必要な情報だけ見る\n\n\n  \n\n\n\nこの可読性こそが、私たちがTidyverseを選ぶ理由です。数ヶ月後の自分が読んでも、何をしたかったのか即座に理解できるでしょう。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#構成変更の意図",
    "href": "02_data.html#構成変更の意図",
    "title": "第2回 データの構造と扱い",
    "section": "構成変更の意図",
    "text": "構成変更の意図\n\n導入の物語化: 「目的」の箇条書きを廃止し、「データの掃除が8割」というデータ分析の厳しい現実と、それを解決するヒーローとしてのTidyverseという構図にしました。\nメタファーの多用: read_csvを「儀式」、変数操作を「動詞」、パイプを「思考の流れ」と例え、無機質な操作説明に血を通わせました。\n実用性の強調: filterやselectを単なる機能ではなく、「分析の第一歩」や「切り分け」という意思決定のツールとして位置づけました。\n「問い」中心の構成: 具体的な処理の説明において、「なぜその操作をするのか（例：羽振りがいいのはどっち？）」という問いを常に先行させました。\n結論の削除: 巻末の「まとめ表」は削除しました。代わりに練習問題を通じて、読者自身に要約させる形式（能動的な学習）へ誘導しています。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#データフレーム世界を表にする",
    "href": "02_data.html#データフレーム世界を表にする",
    "title": "第2回 データの構造と扱い",
    "section": "データフレーム：世界を表にする",
    "text": "データフレーム：世界を表にする\n現実のデータは、混沌としています。それをコンピュータが理解できる形は、結局「行と列」だけです。 Rでの呼び名は データフレーム。\n\n行（Row）：ひとつの観測単位（1人の人間、1回の取引、1日の記録）\n列（Column）：属性や変数（年齢、金額、気温）\n\n\n現実をRに取り込む（CSV読み込み）\n手元のExcelやCSVファイルは、まだ「外」にあります。これを「中」（Rの計算世界）に引き入れる儀式が read_csv() です。\n今回は、Pythonのライブラリ等でもよく使われる tips（レストランのチップ支払い記録）をWebから直接読み込んでみます。\n\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# データの「顔見せ」（tidyverse版のstr()）\nglimpse(tips)\n#&gt; Rows: 244\n#&gt; Columns: 7\n#&gt; $ total_bill &lt;dbl&gt; 16.99, 10.34, 21.01, 23.68, 24.59, 25.29, 8.77, 26.88, 15.0…\n#&gt; $ tip        &lt;dbl&gt; 1.01, 1.66, 3.50, 3.31, 3.61, 4.71, 2.00, 3.12, 1.96, 3.23,…\n#&gt; $ sex        &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\",…\n#&gt; $ smoker     &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n#&gt; $ day        &lt;chr&gt; \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Su…\n#&gt; $ time       &lt;chr&gt; \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\", \"Dinner\",…\n#&gt; $ size       &lt;dbl&gt; 2, 3, 3, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 3, 3, 3, 3,…\n\n読み込んだ瞬間、変数の型（数値なのか、文字なのか）は自動判定されます。Excelによくある「数字なのに文字扱い」みたいなトラブルも、入り口で防げます。\n[要一次情報: データセットの詳細な定義書の所在]",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "02_data.html#ストーリーで書く",
    "href": "02_data.html#ストーリーで書く",
    "title": "第2回 データの構造と扱い",
    "section": "ストーリーで書く",
    "text": "ストーリーで書く\nこれらの「動詞」と「パイプ」を組み合わせれば、複雑なデータ処理も一つのストーリーとして記述できます。\n\n問い：土曜日のディナーに来た客のうち、特にチップを弾んでくれた（総額の20%以上）のはどんな人たちか？支払額が高い順に見たい。\n\nこの思考プロセスをそのままコードにします。\n\ntips %&gt;% \n  filter(day == \"Sat\" & time == \"Dinner\") %&gt;%  # 土曜日のディナー客で\n  mutate(rate = tip / total_bill) %&gt;%          # チップ率を計算し\n  filter(rate &gt;= 0.2) %&gt;%                      # 20%以上に絞り込み\n  arrange(desc(total_bill)) %&gt;%                # 支払額が高い順に並べる\n  select(sex, size, total_bill, tip, rate)     # 必要な情報だけ見る\n\n\n  \n\n\n\nこの「読みやすさ」こそ、私たちがTidyverseを選ぶ理由です。数ヶ月後の自分が見ても、「何がしたかったか」一目で分かります。",
    "crumbs": [
      "第2回 データの構造と扱い"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#本節の目的",
    "href": "03_desc_stat_1.html#本節の目的",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "",
    "text": "データの「中心的傾向」を示す代表値（平均値、中央値、最頻値）の定義と性質を理解する。\nデータの「広がり」を示す散布度（分散、標準偏差、四分位範囲）の定義と性質を理解する。\nRの基本関数を用いて、これらの統計量を算出する手順を確立する。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#記述統計の定義",
    "href": "03_desc_stat_1.html#記述統計の定義",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "記述統計の定義",
    "text": "記述統計の定義\n記述統計（Descriptive Statistics）とは、手元にあるデータの特徴を、少数の数値（要約統計量）やグラフを用いて要約・記述する手法の総称です。 本講義では、データの分布を把握するために不可欠な以下の2つの側面を扱います。\n\n中心的傾向（Central Tendency）: データの分布がどこに中心を持つか（代表値）。\n散布度（Dispersion）: データが平均値の周りにどの程度広がっているか（ばらつき）。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#外れ値の検出基準",
    "href": "03_desc_stat_1.html#外れ値の検出基準",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "外れ値の検出基準",
    "text": "外れ値の検出基準\nTukeyの方法に基づき、以下の基準を超える値を統計的な「外れ値」として扱うことが一般的です。\n\n下限: 第1四分位数 - 1.5 × IQR\n上限: 第3四分位数 + 1.5 × IQR\n\n\nQ1 &lt;- quantile(tips$total_bill, 0.25)\nQ3 &lt;- quantile(tips$total_bill, 0.75)\nIQR_val &lt;- IQR(tips$total_bill)\n\n# 外れ値の境界\nlower_bound &lt;- Q1 - 1.5 * IQR_val\nupper_bound &lt;- Q3 + 1.5 * IQR_val\n\ncat(\"外れ値の下限:\", lower_bound, \"\\n\")\n#&gt; 外れ値の下限: -2.8225\ncat(\"外れ値の上限:\", upper_bound, \"\\n\")\n#&gt; 外れ値の上限: 40.2975\n\n# 定義された外れ値を持つ観測を抽出\ntips %&gt;% \n  filter(total_bill &lt; lower_bound | total_bill &gt; upper_bound) %&gt;% \n  select(total_bill, tip, day, time)",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#平均値と中央値の乖離の可視化",
    "href": "03_desc_stat_1.html#平均値と中央値の乖離の可視化",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "平均値と中央値の乖離の可視化",
    "text": "平均値と中央値の乖離の可視化\n分布が非対称である場合、平均値と中央値は一致しません。 以下はヒストグラム上に両者を描画し、その位置関係を確認するコードです。 [対象注意: 日本語フォント設定は環境依存あり]\n\n# 平均と中央値を計算 {.unnumbered}\nmean_val &lt;- mean(tips$total_bill)\nmed_val &lt;- median(tips$total_bill)\n\n# プロット {.unnumbered}\nggplot(tips, aes(x = total_bill)) +\n  # theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定のためコメントアウト\n  geom_histogram(bins = 30, fill = \"lightgray\", color = \"white\") +\n  geom_vline(xintercept = mean_val, color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = med_val, color = \"blue\", linetype = \"solid\", size = 1) +\n  annotate(\"text\", x = mean_val + 5, y = 30, label = \"Mean (Red)\", color = \"red\") +\n  annotate(\"text\", x = med_val - 5, y = 30, label = \"Median (Blue)\", color = \"blue\") +\n  labs(title = \"平均値（赤破線）と中央値（青実線）\")",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#グループごとの記述統計量",
    "href": "03_desc_stat_1.html#グループごとの記述統計量",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "グループごとの記述統計量",
    "text": "グループごとの記述統計量\n属性ごとの特徴を比較するためには、グループ別の集計が有効です。 dplyr パッケージの group_by() を使用して計算します。\n\ntips %&gt;% \n  group_by(sex) %&gt;% \n  summarize(\n    avg_bill = mean(total_bill),\n    sd_bill = sd(total_bill),\n    count = n() # サンプルサイズ\n  )",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#演習課題",
    "href": "03_desc_stat_1.html#演習課題",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "演習課題",
    "text": "演習課題\n\ntips データを使用し、時間帯 (time) ごとのチップ (tip) の平均値を算出してください。\nsummary() 関数を使用し、チップ (tip) の分布の要約統計量を確認してください。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#情報を縮約する",
    "href": "03_desc_stat_1.html#情報を縮約する",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "",
    "text": "どこに集まっているか（中心的傾向）\nどれくらい散らばっているか（散布度）",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#中心を探す代表値",
    "href": "03_desc_stat_1.html#中心を探す代表値",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "中心を探す：代表値",
    "text": "中心を探す：代表値\nまずはデータの「顔」となる中心点を探します。ただ、「中心」の定義は一つではありません。\n\n1. 全員の声を聞く：平均値 (Mean)\nすべてのデータを足し合わせ、人数で割る。一番なじみ深い「中心」でしょう。\n\\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\]\n\nmean(tips$total_bill)\n#&gt; [1] 19.78594\n\nこの指標には「全員の値を公平に扱う」という民主的な良さがあります。反面、極端な声（外れ値）に弱いのが欠点です。たった一人の超富裕層がいるだけで、全員の平均所得は跳ね上がってしまいます。\n\n\n2. 真ん中の人を見る：中央値 (Median)\nデータを一列に並べたとき、ちょうど真ん中にいる人の値です。\n\nmedian(tips$total_bill)\n#&gt; [1] 17.795\n\nこちらは「順位」しか見ないので、極端な値の影響をほとんど受けません（頑健性）。\n\n\n3. 多派を見る：最頻値 (Mode)\n最も頻繁に現れる値です。数値データよりも、アンケートの回答（賛成/反対）などのカテゴリデータで威力を発揮します。\n\n# Rには標準関数がないため、集計して確認\ntips %&gt;% \n  count(day) %&gt;% \n  arrange(desc(n))\n\n\n  \n\n\n\n\n\n意思決定：平均か、中央値か\nどっちを使うべきか。迷ったら「世界の形（分布）」を見ます。\n\n\n\n\n\n\n\n分布の形状\n選び方の指針\n\n\n\n\n左右対称（テストの点数など）\nどちらもほぼ同じ値になります。数学的に扱いやすい平均値を選びます。\n\n\n歪んでいる（年収、貯蓄額など）\n右に裾が長い場合、平均値は高すぎ​​る値になります。実感を反映する中央値を選びます。",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#広がりを測る散布度",
    "href": "03_desc_stat_1.html#広がりを測る散布度",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "広がりを測る：散布度",
    "text": "広がりを測る：散布度\nデータの特徴は「中心」だけでは語れません。「平均年収500万」と言っても、全員が500万の国と、0円と1000万がいる国では全く別物です。 この「散らばり具合」を数値にします。\n\n最大と最小：範囲 (Range)\n一番上と一番下の差です。単純ですが、全体像を掴むにはこれで十分なことも多いです。\n\nrange(tips$total_bill)  # 最小値と最大値\n#&gt; [1]  3.07 50.81\nmax(tips$total_bill) - min(tips$total_bill)  # その差（範囲）\n#&gt; [1] 47.74\n\n\n\n中心からの距離：分散 (Variance)\n「平均からどれくらい離れているか」を全データについて計算し、平均したもの。 直感的には「差の絶対値」を平均したくなりますよね。でも、統計学では数学的な都合から「差を二乗」して扱います。\nRの注意点: Rの var() 関数は、手元のデータを標本とみなした不偏分散（分母が \\(n-1\\)）を計算します。\n\\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2\\]\n\nvar(tips$total_bill)\n#&gt; [1] 79.25294\n\n\n\n単位を戻す：標準偏差 (Standard Deviation)\n分散は計算過程で「二乗」しているため、単位が「ドルの二乗」のようになり、直感的に分かりにくい。 そこで、平方根をとって元の単位に戻したのが標準偏差です。\n\\[s = \\sqrt{s^2}\\]\n\nsd(tips$total_bill)\n#&gt; [1] 8.902412\n\n「平均値 \\(\\pm\\) 標準偏差」の範囲に、多くのデータ（正規分布なら約68%）が含まれると考えるとイメージしやすいでしょう。\n\n\n単位を消す：変動係数 (CV)\n「象の体重のばらつき」と「アリの体重のばらつき」を比べたいとき、標準偏差（kgやg）そのままでは比較できません。 平均値に対する比率（%）に直すことで、スケールの異なるデータでも比べられます。\n\\[CV = \\frac{s}{\\bar{x}} \\times 100\\%\\]\n\n# チップの額と、支払総額。どちらが「ばらついて」いるか？\ncv_tip &lt;- sd(tips$tip) / mean(tips$tip) * 100\ncv_bill &lt;- sd(tips$total_bill) / mean(tips$total_bill) * 100\n\ncat(\"チップの変動係数:\", cv_tip, \"%\\n\")\n#&gt; チップの変動係数: 46.14775 %\ncat(\"支払総額の変動係数:\", cv_bill, \"%\\n\")\n#&gt; 支払総額の変動係数: 44.99362 %",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#全体像をスキャンする四分位数",
    "href": "03_desc_stat_1.html#全体像をスキャンする四分位数",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "全体像をスキャンする：四分位数",
    "text": "全体像をスキャンする：四分位数\nデータを小さい順に並べて4等分した地点（25%, 50%, 75%）を四分位数と呼びます。 summary() 関数を使えば、これらの主要な統計量を一括で確認できます。\n\nsummary(tips$total_bill)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;    3.07   13.35   17.80   19.79   24.13   50.81\n\n\nMedian（50%地点）と Mean（平均）のズレを見ることで、データの歪みを推測できます。\n1st Qu（25%）から 3rd Qu（75%）の間には、データの中央半数が含まれます。\n\n\n安定した広がり：四分位範囲 (IQR)\nデータの中央50%が収まる幅（第3四分位数 \\(-\\) 第1四分位数）を四分位範囲と呼びます。 標準偏差と違い、極端な値の影響を受けないため、外れ値を含むデータでのばらつき指標として優秀です。\n\nIQR(tips$total_bill)\n#&gt; [1] 10.78",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#ノイズかシグナルか外れ値の検出",
    "href": "03_desc_stat_1.html#ノイズかシグナルか外れ値の検出",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "ノイズか、シグナルか：外れ値の検出",
    "text": "ノイズか、シグナルか：外れ値の検出\n統計分析において、極端に離れた値（外れ値）は厄介な存在です。入力ミス（ノイズ）なのか、特異な事象（シグナル）なのかを見極める必要があります。 一般的に、箱ひげ図のTukeyの基準を用いて「外れ値候補」を機械的に検出します。\n\n下限: 第1四分位数 - 1.5 × IQR\n上限: 第3四分位数 + 1.5 × IQR\n\n\nQ1 &lt;- quantile(tips$total_bill, 0.25)\nQ3 &lt;- quantile(tips$total_bill, 0.75)\nIQR_val &lt;- IQR(tips$total_bill)\n\n# 境界線の計算\nlower_bound &lt;- Q1 - 1.5 * IQR_val\nupper_bound &lt;- Q3 + 1.5 * IQR_val\n\ncat(\"外れ値の下限:\", lower_bound, \"\\n\")\n#&gt; 外れ値の下限: -2.8225\ncat(\"外れ値の上限:\", upper_bound, \"\\n\")\n#&gt; 外れ値の上限: 40.2975\n\n# 境界を超えたデータを抽出してみる\ntips %&gt;% \n  filter(total_bill &lt; lower_bound | total_bill &gt; upper_bound) %&gt;% \n  select(total_bill, tip, day, time)",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#分布の歪みを可視化する",
    "href": "03_desc_stat_1.html#分布の歪みを可視化する",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "分布の歪みを可視化する",
    "text": "分布の歪みを可視化する\n平均値と中央値がずれているとき、実際にグラフを描くとその理由がわかります。 ヒストグラムに両者の位置を重ねてみましょう。\n\n# 統計量の計算 {.unnumbered}\nmean_val &lt;- mean(tips$total_bill)\nmed_val &lt;- median(tips$total_bill)\n\n# プロット {.unnumbered}\nggplot(tips, aes(x = total_bill)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_histogram(bins = 30, fill = \"lightgray\", color = \"white\") +\n  geom_vline(xintercept = mean_val, color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = med_val, color = \"blue\", linetype = \"solid\", size = 1) +\n  annotate(\"text\", x = mean_val + 5, y = 30, label = \"Mean (Red)\", color = \"red\") +\n  annotate(\"text\", x = med_val - 5, y = 30, label = \"Median (Blue)\", color = \"blue\") +\n  labs(title = \"平均値（赤破線）と中央値（青実線）\")",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "03_desc_stat_1.html#グループごとに要約する",
    "href": "03_desc_stat_1.html#グループごとに要約する",
    "title": "第3回 記述統計 (1) 数値要約",
    "section": "グループごとに要約する",
    "text": "グループごとに要約する\n全体の平均だけでは見えない違いもあります。性別や喫煙の有無など、属性ごとに分けて要約することで、より深い洞察が得られます。\n\ntips %&gt;% \n  group_by(sex) %&gt;% \n  summarize(\n    avg_bill = mean(total_bill),\n    sd_bill = sd(total_bill),\n    count = n() # サンプルサイズも必ず確認する\n  )",
    "crumbs": [
      "第3回 記述統計 (1) 数値要約"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#キャンバスに層を重ねるggplot2の思想",
    "href": "04_desc_stat_2.html#キャンバスに層を重ねるggplot2の思想",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "キャンバスに層を重ねる：ggplot2の思想",
    "text": "キャンバスに層を重ねる：ggplot2の思想\nRの可視化パッケージ ggplot2 の設計思想は、Wickham (2010) の “Layered Grammar of Graphics”（グラフィックスの層状文法）に基づいています。 Excelみたいに「棒グラフを作るボタン」があるわけではありません。\n\n「データ」という土台に、「座標」を定義し、「点や棒（Geom）」を乗せ、「説明（Labels）」を加える。\n\nこの工程をコードで書きます。\n\nggplot(data = tips, mapping = aes(x = total_bill, y = tip)) + # キャンバスと座標\n  geom_point()                                                # 何を描くか（点）",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#分布の形状を見る",
    "href": "04_desc_stat_2.html#分布の形状を見る",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "1. 分布の形状を見る",
    "text": "1. 分布の形状を見る\nまずは、データが「どんな形」をしているか確認します。\n\n山の形を知る：ヒストグラム\n連続した数値データ（金額など）が、どこに集まっているかを見に行きます。 山は一つか、二つか？ 左右対称か、歪んでいるか？\n\nggplot(tips, aes(x = total_bill)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"white\") +\n  labs(title = \"支払総額の分布\", x = \"支払総額 ($)\", y = \"度数\")\n\n\n\n\n\n\n\n\n\n\n構造を要約する：箱ひげ図\nヒストグラムは詳細ですが、複数のグループ比較には不向きです。重なって見づらいから。 そこで箱ひげ図の出番です。分布の情報を「箱」と「ひげ」に要約します。\n\nggplot(tips, aes(x = day, y = total_bill, fill = day)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_boxplot() +\n  labs(title = \"曜日ごとの支払額の違い\", x = \"曜日\", y = \"支払総額\")\n\n\n\n\n\n\n\n\nTukeyの箱ひげ図の定義:\n\n箱: データの中央50%（第1四分位数〜第3四分位数）。この中に「普通」のデータが入ります。\n太線: 中央値（Median）。\n点: 箱から 1.5倍の四分位範囲 以上離れた値。統計的な「外れ値候補」として扱います。\n\n\n\n分布の機微を見る：バイオリンプロット\n箱ひげ図だと「山が2つある」などの情報は消えてしまいます。分布の形状（密度）そのものを表示したい場合は、バイオリン図を使います。\n\nggplot(tips, aes(x = day, y = total_bill, fill = day)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_violin() +\n  geom_boxplot(width = 0.1, fill = \"white\") + # 箱ひげ図も重ねると最強\n  labs(title = \"分布の形状比較（バイオリン+箱ひげ）\", x = \"曜日\", y = \"支払総額\")",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#関係性を探る",
    "href": "04_desc_stat_2.html#関係性を探る",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "2. 関係性を探る",
    "text": "2. 関係性を探る\n次は、2つの変数がどう関わっているかを探ります。\n\n2つの量の相関：散布図\n「たくさん食べた人は、たくさんチップを払うのか？」 2つの連続変数（横軸と縦軸）の関係をプロットします。\n\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point(color = \"blue\", alpha = 0.5) +\n  labs(title = \"支払総額とチップの正の相関\", x = \"支払総額\", y = \"チップ\")\n\n\n\n\n\n\n\n\nここに第3の次元（情報）を加えるのも簡単です。例えば、性別によって色を変えます（color = sex）。\n\nggplot(tips, aes(x = total_bill, y = tip, color = sex)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n状況ごとの違い：ファセット分割\n色分け（color）は便利ですが、情報が増えすぎると「スパゲッティ」のように絡まって読めなくなる。 そんなときは facet_wrap() でグラフ自体を分割してしまいましょう。\n\n# 喫煙の有無 × 時間帯 で状況を分解する\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point(aes(color = smoker)) +\n  facet_wrap(~ time) +\n  labs(title = \"条件による関係性の違い\", x = \"支払総額\", y = \"チップ\")",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "04_desc_stat_2.html#グラフを語らせるための調整",
    "href": "04_desc_stat_2.html#グラフを語らせるための調整",
    "title": "第4回 記述統計 (2) データの可視化",
    "section": "グラフを「語らせる」ための調整",
    "text": "グラフを「語らせる」ための調整\nデフォルトのままでは、グラフは「下書き」です。誰かに伝えるためには、意図が伝わるよう調整します。\n\n統計情報の重ね書き\n「傾向」を見せたいなら、生のデータ点だけでなく、平均値や回帰直線を重ねるのが効果的です。\n\nggplot(tips, aes(x = day, y = total_bill)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_boxplot(fill = \"lightblue\") +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 3) + # 平均値を赤点で追加\n  stat_summary(fun = mean, geom = \"line\", aes(group = 1), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"曜日ごとの傾向（赤点は平均値）\", x = \"曜日\", y = \"支払総額\")\n\n\n\n\n\n\n\n\n\n\nユニバーサルデザインへの配慮\nあなたのグラフを見る人の中には、特定の色が見えにくい人（色覚多様性）がいるかもしれません。 「赤と緑」の色分けだけで情報を伝えてはダメです。形状（shape）や線種（linetype）の違いを併用するか、誰もが識別しやすいカラーパレット（Viridisなど）の使用をおすすめします。",
    "crumbs": [
      "第4回 記述統計 (2) データの可視化"
    ]
  },
  {
    "objectID": "05_probability.html#本節の目的",
    "href": "05_probability.html#本節の目的",
    "title": "第5回 確率論の基礎",
    "section": "",
    "text": "確率変数および確率分布の定義と、離散型・連続型の違いを理解する。\n期待値（平均）と分散の定義を理解し、その性質（線形性など）を確認する。\nRのシミュレーション機能を用いて、理論値と標本統計量の関係を検証する。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#なぜ確率論が必要か",
    "href": "05_probability.html#なぜ確率論が必要か",
    "title": "第5回 確率論の基礎",
    "section": "なぜ確率論が必要か",
    "text": "なぜ確率論が必要か\n統計学は、観測されたデータ（標本）から、背後にあるメカニズム（母集団）を推測する学問です。この推測には常に「不確実性」が伴います。 この不確実性を定量的に評価し、数学的に扱うための言語が「確率論」です。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#確率の定義",
    "href": "05_probability.html#確率の定義",
    "title": "第5回 確率論の基礎",
    "section": "確率の定義",
    "text": "確率の定義\n確率（Probability）とは、ある試行において特定の事象が生じる「起こりやすさ」を \\(0\\) から \\(1\\) の数値で定量化したものです。 数学的には、Kolmogorovの公理系等に基づきますが、本講義では直感的な理解を優先します。\n\n\\(P(A) = 0\\): 事象Aは（ほぼ）起こらない\n\\(P(A) = 1\\): 事象Aは（ほぼ）確実に起こる\n\\(P(A) = 0.5\\): 起こるかどうかが五分五分である\n\n\n計算例\n「公正な（偏りのない）サイコロ」を1回振るという試行において：\n\n# 1の目が出る確率\n1 / 6\n#&gt; [1] 0.1666667\n\n# 偶数（2, 4, 6）の目が出る確率\n3 / 6\n#&gt; [1] 0.5",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#同時確率と独立性",
    "href": "05_probability.html#同時確率と独立性",
    "title": "第5回 確率論の基礎",
    "section": "同時確率と独立性",
    "text": "同時確率と独立性\n\n独立であるとはどういうことか\n2つの事象 \\(A\\) と \\(B\\) が「独立」。これは、お互いに影響し合わないこと。 数学的な定義はシンプルです。\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n「AかつBが起こる確率」が、単純な掛け算で計算できるなら、それは独立。 逆に、掛け算で合わないなら、裏で何かがつながっています（相関や因果）。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#連続型確率変数への拡張",
    "href": "05_probability.html#連続型確率変数への拡張",
    "title": "第5回 確率論の基礎",
    "section": "連続型確率変数への拡張",
    "text": "連続型確率変数への拡張\n身長や温度のように連続的な値をとる変数の場合、特定の値をとる確率は（数学的厳密性の下では）\\(0\\) となります。 そのため、確率密度関数 (Probability Density Function, PDF) \\(f(x)\\) を用いて、「ある区間に入る確率」を面積として定義します。\n\n定義の違い\n\n\n\n\n\n\n\n\n性質\n離散型\n連続型\n\n\n\n\n確率の定義\n各点での確率 \\(P(X=x)\\)\n密度関数 \\(f(x)\\) の積分（面積）\n\n\n全確率\n\\(\\sum P(X=x_i) = 1\\)\n\\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\)\n\n\n期待値\n\\(\\sum x_i P(X=x_i)\\)\n\\(\\int x f(x) dx\\)\n\n\n特定値の確率\n正の値を取りうる\n常に \\(0\\) (\\(P(X=a) = 0\\))\n\n\n\n※連続型において \\(P(X=a)=0\\) とは、「決して起こらない（空事象）」という意味ではなく、「一点の確率は測度ゼロである」という解析学的な意味です。\n\n\n一様分布 (Uniform Distribution)\n最も基本的な連続分布です。区間 \\([a, b]\\) 内で確率密度が一定である分布を指します。 Rの runif() 関数などで生成・操作できます。\n\n# U(0, 1) の密度関数の可視化\nx &lt;- seq(0, 1, length.out = 100)\nf_x &lt;- dunif(x, min = 0, max = 1)\n\ndf &lt;- data.frame(x, f_x)\n\nggplot(df, aes(x = x, y = f_x)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") +\n  geom_line(color = \"blue\", size = 1.5) +\n  ylim(0, 1.5) +\n  labs(title = \"一様分布 U(0,1) の確率密度関数\", x = \"x\", y = \"密度 f(x)\")\n\n\n\n\n\n\n\n\n\n\nシミュレーションによる大数の法則の確認\n理論上の期待値と、実際に乱数を生成して計算した平均値（標本平均）の関係を確認します。\n\n# 乱数生成（10,000回試行）\nset.seed(123)\nsamples &lt;- runif(10000, min = 0, max = 1)\n\n# サンプル統計量の計算\ncat(\"サンプル平均:\", mean(samples), \"\\n\")\n#&gt; サンプル平均: 0.4975494\ncat(\"理論的期待値:\", 0.5, \"\\n\\n\")\n#&gt; 理論的期待値: 0.5\n\ncat(\"サンプル分散:\", var(samples), \"\\n\")\n#&gt; サンプル分散: 0.08219329\ncat(\"理論的分散:\", 1/12, \"(約 0.0833)\\n\")\n#&gt; 理論的分散: 0.08333333 (約 0.0833)\n\n試行回数を増やせば、サンプル平均は理論的期待値に収束します（大数の法則）。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#可能性の地図確率分布",
    "href": "05_probability.html#可能性の地図確率分布",
    "title": "第5回 確率論の基礎",
    "section": "可能性の地図：確率分布",
    "text": "可能性の地図：確率分布\n「次に何が起こるか」は誰にもわかりません。でも、「何がどれくらいの可能性で起こりうるか」の全体像なら描けます。\n\n確率変数 (\\(X\\)): コインの表裏やサイコロの目のように、結果が偶然で決まる変数。\n確率分布: 変数がとりうる値と、その確率の対応関係。いわば「可能性の地図」です。\n\n\nデジタルとアナログ：離散と連続\n確率変数には、大きく2つのタイプがあります。\n\n\n\n\n\n\n\n\n\nタイプ\nイメージ\n具体例\n特徴\n\n\n\n\n離散型 (Discrete)\nデジタル（飛び飛び）\nサイコロの目、人数\n1つ1つの値に確率がある (\\(P(X=x)\\))\n\n\n連続型 (Continuous)\nアナログ（連続）\n身長、時間、気温\n一点狙いの確率はゼロ。面積で確率を考える\n\n\n\n\n\n離散型の実験：サイコロの地図\n一番シンプルな離散分布、「公正なサイコロ」を考えます。 1から6までの目が、すべて均等に \\(1/6\\) の確率で出ます。\n\nx &lt;- 1:6\nprob &lt;- rep(1/6, 6) # 全て 1/6\n\n# 分布の可視化\nlibrary(tidyverse)\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\")) # [対象注意] Mac用設定\n\ndata.frame(x = factor(x), prob = prob) %&gt;% \n  ggplot(aes(x = x, y = prob)) +\n  geom_col(fill = \"orange\", width = 0.5) +\n  ylim(0, 0.5) +\n  labs(title = \"サイコロの確率分布（離散型）\", x = \"出る目\", y = \"確率\")",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#分布の特徴を捉える",
    "href": "05_probability.html#分布の特徴を捉える",
    "title": "第5回 確率論の基礎",
    "section": "分布の特徴を捉える",
    "text": "分布の特徴を捉える\n地図全体を眺めるのは大変です。特徴を一言で表す「要約」がほしい。記述統計で学んだ「平均」と「分散」。こいつらが、確率論の世界では期待値と分散として再登場します。\n\n1. 期待値 (Expected Value): 「賭け」の相場\nもしサイコロ博打を何千回も繰り返したら、平均で何点とれるか。 それが期待値 \\(E[X]\\) 。分布の「重心」です。\n\\[ E[X] = \\sum_{i} x_i P(X=x_i) \\]\nサイコロなら： \\[ 1 \\times \\frac{1}{6} + \\cdots + 6 \\times \\frac{1}{6} = 3.5 \\]\n「3.5」という目は実際には出ません。でも、長く続ければこの値に落ち着く。これがこのゲームの「平均的な相場」です。\n\n\n2. 分散 (Variance): リスクの大きさ\n期待値（重心）から、どれくらい離れた値が出やすいか。 このブレこそ、リスク。統計学では分散 \\(V[X]\\) と呼びます。\n\\[ V[X] = E[(X - E[X])^2] \\]\n\n# Rで計算\nE_X &lt;- sum(x * prob)\nV_X &lt;- sum((x - E_X)^2 * prob)\n\ncat(\"期待値:\", E_X, \"\\n\")\n#&gt; 期待値: 3.5\ncat(\"分散:\", V_X, \"\\n\")\n#&gt; 分散: 2.916667\ncat(\"標準偏差:\", sqrt(V_X), \"\\n\")\n#&gt; 標準偏差: 1.707825\n\n\n\n線形性：計算を楽にする魔法\n期待値と分散には、計算を劇的に楽にする性質（魔法）があります。 例えば、「サイコロの目を10倍して3を足したスコア」の平均を知りたいとき、いちいちシミュレーションしなくていい。\n\n期待値: \\(E[10X + 3] = 10 E[X] + 3 = 10(3.5) + 3 = 38\\)\n分散: \\(V[10X + 3] = 100 V[X]\\) （定数の足し算は無視。掛け算は二乗で効く）",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#連続の世界へ",
    "href": "05_probability.html#連続の世界へ",
    "title": "第5回 確率論の基礎",
    "section": "連続の世界へ",
    "text": "連続の世界へ\n身長や時間など、連続的な数値の場合、「ちょうど170.000…cmである確率」は実質ゼロです。 そこで、確率密度関数 (PDF) を使い、「点」ではなく「面積」で確率を考えます。\n\n確率密度関数とは\n\n\\(f(x)\\) というカーブの下側の面積が、確率になります。\n全区間の面積（全確率）は、必ず 1 。\n\n\n\n実験：一様分布シミュレーション\n0から1までの乱数を発生させる「一様分布」で、理論と現実を比べてみます。 理論上の期待値は \\(0.5\\)、分散は \\(1/12 \\approx 0.083\\) です。\n\n# 1. 密度関数の可視化（理論）\nggplot(data.frame(x = c(0, 1)), aes(x)) +\n  stat_function(fun = dunif, args = list(min = 0, max = 1), \n                geom = \"area\", fill = \"lightblue\", alpha = 0.5) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  labs(title = \"一様分布 U(0,1) の密度関数\", y = \"密度 f(x)\")\n\n\n\n\n\n\n\n\n# 2. シミュレーション（現実）\nset.seed(123)\nsamples &lt;- runif(10000)\n\ncat(\"--- シミュレーション結果 ---\\n\")\n#&gt; --- シミュレーション結果 ---\ncat(\"サンプル平均:\", mean(samples), \" (理論値: 0.5)\\n\")\n#&gt; サンプル平均: 0.4975494  (理論値: 0.5)\ncat(\"サンプル分散:\", var(samples), \" (理論値: 0.0833...)\\n\")\n#&gt; サンプル分散: 0.08219329  (理論値: 0.0833...)\n\n回数を重ねるほど、現実は理論（期待値）に近づいていきます。大数の法則です。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "05_probability.html#課題練習問題",
    "href": "05_probability.html#課題練習問題",
    "title": "第5回 確率論の基礎",
    "section": "課題/練習問題",
    "text": "課題/練習問題\n自力で計算し、Rで確かめてみてください。\n\n課題1: 歪んだコインのギャンブル\n表が出る確率が \\(0.1\\)、裏が \\(0.9\\) のコインがあります。 表なら100円、裏なら0円もらえるとき、このギャンブルの期待値（参加料の適正価格）はいくらですか？\n\n\n課題2: 独立性の検証\n「雨が降る確率」が30%、「傘を持つ確率」が50%だとします。 もし「雨が降り、かつ傘を持っている確率」が15%なら、雨と傘は独立と言えますか？ （ヒント：\\(0.3 \\times 0.5\\) と比べてください）\n※本節の公式（期待値・分散の定義、線形性）は、次回の「推測統計」でフル活用します。手計算できるようになっておいてください。",
    "crumbs": [
      "第5回 確率論の基礎"
    ]
  },
  {
    "objectID": "06_distributions.html#本節の目的",
    "href": "06_distributions.html#本節の目的",
    "title": "第6回 主要な確率分布",
    "section": "",
    "text": "連続型分布の代表である 正規分布 の性質と重要性を理解する。\n離散型分布の代表である 二項分布 の定義（ベルヌーイ試行）を理解する。\n推測統計で利用される派生分布（t分布、カイ二乗分布、F分布）の概要を把握する。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#推測統計のための派生分布",
    "href": "06_distributions.html#推測統計のための派生分布",
    "title": "第6回 主要な確率分布",
    "section": "推測統計のための派生分布",
    "text": "推測統計のための派生分布\n統計的推測（推定・検定）では、正規分布から数学的に導出される以下の確率分布が不可欠です。これらは第8回以降で詳細に扱いますが、ここではその出自と用途を定義します。\n\n1. カイ二乗分布 (\\(\\chi^2\\))\n\n定義: 標準正規分布に従う独立な確率変数の二乗和が従う分布。\n用途: 母分散の推定・検定、クロス集計表の独立性検定。\n特徴: 常に正の値をとる。自由度 \\(k\\) によって形状が決まる。\n\n\n\n2. t分布 (Student’s t)\n\n定義: 母分散が未知の場合に、標本分散を用いて標準化した平均値が従う分布。\n用途: 小標本における平均値の検定（t検定）、回帰係数の有意性検定。\n特徴: 正規分布に似ているが、裾が厚い（極端な値が出やすい）。自由度が大きくなると正規分布に収束する。\n\n\n\n3. F分布\n\n定義: 2つの独立なカイ二乗分布（をそれぞれの自由度で割ったもの）の比が従う分布。\n用途: 等分散性の検定、分散分析 (ANOVA)。\n特徴: 2つの自由度 \\((df1, df2)\\) を持つ。常に正の値をとる。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#分布リファレンス",
    "href": "06_distributions.html#分布リファレンス",
    "title": "第6回 主要な確率分布",
    "section": "分布リファレンス",
    "text": "分布リファレンス\n\n\n\n分布名\nR関数接頭辞\n主要な用途\n決定パラメータ\n\n\n\n\n正規分布\nnorm\n連続データのモデル化、誤差\nmean, sd\n\n\n二項分布\nbinom\n成功回数の確率\nsize (n), prob (p)\n\n\nt分布\nt\n平均の検定（分散未知）\ndf (自由度)\n\n\nカイ二乗分布\nchisq\n分散の検定、独立性検定\ndf (自由度)\n\n\nF分布\nf\n分散分析、等分散検定\ndf1, df2 (自由度)",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#統計学の王様正規分布",
    "href": "06_distributions.html#統計学の王様正規分布",
    "title": "第6回 主要な確率分布",
    "section": "1. 統計学の王様：正規分布",
    "text": "1. 統計学の王様：正規分布\n正規分布は、平均 \\(\\mu\\) と分散 \\(\\sigma^2\\) 。たった2つのパラメータで完全に決まる、左右対称の美しい釣鐘型をしています。\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]\n数式は複雑に見えますが、Rなら一瞬で描けます。\n\n4つの魔法の呪文\nRには確率分布を扱うための共通の「呪文（接頭辞）」があります。これさえ覚えれば、勝てます。\n\nd (Density): 確率密度。グラフの高さ。 (dnorm)\np (Probability): 累積確率。ある地点より左側の面積。 (pnorm)\nq (Quantile): 分位点。確率から値を逆算する。 (qnorm)\nr (Random): 乱数生成。シミュレーション用。 (rnorm)\n\n\n\n正規分布を描いてみる\nまずは標準正規分布（平均0、分散1）を見てみましょう。\n\nlibrary(tidyverse)\n\n# x軸の範囲定義\nx &lt;- seq(-4, 4, length.out = 100)\n# 確率密度の計算 (dnorm)\ny &lt;- dnorm(x, mean = 0, sd = 1)\n\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  labs(title = \"標準正規分布 (Mean=0, SD=1)\")\n\n\n\n\n\n\n\n\n\n\nパラメータを変えてみる\n平均がズレると山が移動し、標準偏差が大きくなると山が平らになります。\n\nx &lt;- seq(-10, 15, length.out = 200)\ndf_compare &lt;- data.frame(\n  x = rep(x, 3),\n  y = c(dnorm(x, mean = 0, sd = 1),\n        dnorm(x, mean = 5, sd = 1),\n        dnorm(x, mean = 0, sd = 2)),\n  type = rep(c(\"μ=0, σ=1\", \"μ=5, σ=1\", \"μ=0, σ=2\"), each = length(x))\n)\n\nggplot(df_compare, aes(x = x, y = y, color = type)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line(size = 1) +\n  labs(title = \"パラメータによる正規分布の変化\", color = \"設定\")",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#現実の問いに答える確率計算",
    "href": "06_distributions.html#現実の問いに答える確率計算",
    "title": "第6回 主要な確率分布",
    "section": "現実の問いに答える：確率計算",
    "text": "現実の問いに答える：確率計算\n「平均50、標準偏差10のテストで、60点以上をとる確率は？」 この問いに答えるのが p (累積確率) の関数です。\npnorm(60) は「\\(-\\infty\\) から 60 までの面積」を返します。 「60点以上」を知りたいなら、全体（100% = 1）から「60点以下」の確率を引けばいい。\n\n# P(X &gt;= 60) = 1 - P(X &lt;= 60)\n1 - pnorm(60, mean = 50, sd = 10)\n#&gt; [1] 0.1586553\n\n約15.9%。クラスの16%は、偏差値60以上ということ。\n\n68-95-99.7 ルール\n正規分布には、覚えておくべき相場観があります。 「データの大半は、平均から標準偏差の3倍以内に収まる」というルールです。\n\n\\(\\pm 1\\sigma\\): 約68% （偏差値40〜60）\n\\(\\pm 2\\sigma\\): 約95% （偏差値30〜70）\n\\(\\pm 3\\sigma\\): 約99.7% （ほぼすべて）\n\n\nx &lt;- seq(-4, 4, length.out = 100)\ny &lt;- dnorm(x)\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  geom_area(data = filter(df, x &gt;= -1 & x &lt;= 1), fill = \"blue\", alpha = 0.3) +\n  geom_area(data = filter(df, x &gt;= -2 & x &lt;= 2), fill = \"green\", alpha = 0.2) +\n  geom_area(data = filter(df, x &gt;= -3 & x &lt;= 3), fill = \"red\", alpha = 0.1) +\n  labs(title = \"正規分布の区間確率 (1SD, 2SD, 3SD)\", x = \"標準偏差 (z)\", y = \"確率密度\")",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#コイン投げの積み重ね二項分布",
    "href": "06_distributions.html#コイン投げの積み重ね二項分布",
    "title": "第6回 主要な確率分布",
    "section": "2. コイン投げの積み重ね：二項分布",
    "text": "2. コイン投げの積み重ね：二項分布\n次に、離散型の代表、二項分布。 「成功か失敗か」のギャンブル（ベルヌーイ試行）を \\(n\\) 回繰り返したとき、何回勝てるか？を表す分布です。\n\n二項分布の3条件\n単なる繰り返しではなく、3つの条件が必要です。 1. 回数 \\(n\\) が決まっている。 2. 毎回のリセット（独立性）。前の結果に引きずられない。 3. 勝率 \\(p\\) が変わらない。\n\n\nシミュレーション：運命の分かれ道\nコイン投げ（\\(p=0.5\\)）を10回行う勝負を考えます。 「ちょうど5回勝つ確率」はどれくらいか。\n\n# dbinom で確率（点）を計算\ndbinom(5, size = 10, prob = 0.5)\n#&gt; [1] 0.2460938\n\n約24.6%。意外と低いですか？ すべてのパターンの確率を並べてみます。\n\nx &lt;- 0:10\nprob &lt;- dbinom(x, size = 10, prob = 0.5)\ndf_binom &lt;- data.frame(x = factor(x), prob = prob)\n\nggplot(df_binom, aes(x = x, y = prob)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_col(fill = \"lightgreen\") +\n  labs(title = \"二項分布 (n=10, p=0.5)\", x = \"成功回数\", y = \"確率\")\n\n\n\n\n\n\n\n\n\n\n回数を増やすと、奇跡が起きる\nここからが統計学のハイライト。 このカクカクした二項分布、試行回数 \\(n\\) をどんどん増やしていくと、どうなるか。\n\n# 試行回数 n を変化させた場合の分布形状\nn_values &lt;- c(30, 10, 100) # ユーザーによる順序指定あり\np &lt;- 0.3\n\ndf_binom_approx &lt;- data.frame()\nfor(n in n_values) {\n  x &lt;- 0:n\n  prob &lt;- dbinom(x, size = n, prob = p)\n  df_binom_approx &lt;- rbind(df_binom_approx, data.frame(x=x, prob=prob, n=paste0(\"n=\", n)))\n}\n\nggplot(df_binom_approx, aes(x = x, y = prob)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_col(fill = \"steelblue\") +\n  # nの順序を整えて表示（小さいnから順に見るため）\n  facet_wrap(~ fct_relevel(n, \"n=10\", \"n=30\", \"n=100\"), scales = \"free_x\") +\n  labs(title = \"nの増加に伴う二項分布の正規近似\", x = \"成功回数\")\n\n\n\n\n\n\n\n\n\\(n\\) が増えるにつれて、分布の左右対称性が増し、きれいな釣鐘型に近づいているのがわかります。 「離散的なコイン投げ」が、積み重なることで「連続的な正規分布」に化けました。\nこれを正規近似（ド・モアブル＝ラプラスの定理）と呼び、後の中心極限定理へとつながる重要な性質です。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "06_distributions.html#正規分布の子供たち派生分布",
    "href": "06_distributions.html#正規分布の子供たち派生分布",
    "title": "第6回 主要な確率分布",
    "section": "3. 正規分布の子供たち（派生分布）",
    "text": "3. 正規分布の子供たち（派生分布）\n最後に、推測統計の現場で頻繁に使われる3つの分布を紹介します。 これらはすべて、正規分布を親として生まれた「正規分布ファミリー」。 今は定義を丸暗記する必要はありません。「何のために生まれたか」という役割だけ、押さえておきます。\n\nカイ二乗分布 (\\(\\chi^2\\))：ブレの分析官\n\n出自: 標準正規分布の2乗和。\n役割: 「分散（ばらつき）」を分析すること。\n特徴: 2乗しているのでマイナスにはなりません。適合度検定などで活躍します。\n\n\n\nt分布 (\\(t\\))：現場の代役\n\n出自: 正規分布 ÷ \\(\\sqrt{\\chi^2/k}\\)。\n役割: データ数（標本）が少ないときに、正規分布の代役を務める。\n特徴: 正規分布より裾が厚く、外れ値のリスクを織り込んでいます。「母分散がわからない」という現実的な状況で、平均値を検定するための分布です。\n\n\n\nF分布 (\\(F\\))：比較のスペシャリスト\n\n出自: 2つのカイ二乗分布の比。\n役割: 2つの「分散」を比べること。\n特徴: 分散分析（ANOVA）で、グループ間の差が誤差より大きいかを判定する際に使われます。",
    "crumbs": [
      "第6回 主要な確率分布"
    ]
  },
  {
    "objectID": "07_sampling.html#本節の目的",
    "href": "07_sampling.html#本節の目的",
    "title": "第7回 標本分布",
    "section": "",
    "text": "母集団と標本の関係、および統計的推測の枠組みを理解する。\n推測統計学の2大支柱である 大数の法則 と 中心極限定理 の違いと役割を理解する。\n標準誤差 (Standard Error) の概念を確立し、単なる標準偏差との決定的な違いを把握する。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#標本分布-sampling-distribution",
    "href": "07_sampling.html#標本分布-sampling-distribution",
    "title": "第7回 標本分布",
    "section": "標本分布 (Sampling Distribution)",
    "text": "標本分布 (Sampling Distribution)\n推測統計において極めて重要な概念が「標本分布」です。 これは、「標本そのものの分布」ではなく、「統計量（標本平均など）が従う確率分布」を指します。\n「もし同じ母集団から何度も標本抽出を繰り返して平均値を計算したら、その平均値はどのようにばらつくか？」という仮想的な分布です。\nRを使ってシミュレーションしてみましょう。 [対象注意: 日本語フォント設定は環境依存あり]\n\nlibrary(tidyverse)\nset.seed(1)\n\n# 母集団分布（平均50, 標準偏差10の正規分布）\npopulation &lt;- rnorm(100000, mean = 50, sd = 10)\n\n# 1回の抽出（n=100）\nsample1 &lt;- sample(population, 100)\nmean(sample1)\n#&gt; [1] 50.24966\n\n# もう1回抽出\nsample2 &lt;- sample(population, 100)\nmean(sample2)\n#&gt; [1] 50.48065\n\n毎回平均値が異なることがわかります。この「平均値のばらつき」を表すのが標本分布です。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#中心極限定理-central-limit-theorem-clt",
    "href": "07_sampling.html#中心極限定理-central-limit-theorem-clt",
    "title": "第7回 標本分布",
    "section": "中心極限定理 (Central Limit Theorem, CLT)",
    "text": "中心極限定理 (Central Limit Theorem, CLT)\n母集団がどのような分布（正規分布でなくてもよい）であっても、サンプルサイズ \\(n\\) が十分に大きければ、標本平均 \\(\\bar{X}\\) の分布は正規分布に近づくという定理です。\nこれが、統計的推測で正規分布が中心的な役割を果たす理由です。\n\n一様分布からのCLTシミュレーション\n母集団が一様分布（0から1の乱数）の場合で実験します。元の分布は平坦ですが、その平均値の分布はどうなるでしょうか。\n\n# 1. 一様分布のヒストグラム（母集団の形状）\nhist(runif(10000), main = \"母集団（一様分布）\", xlab = \"x\")\n\n\n\n\n\n\n\n\n# 2. 標本平均の分布（CLTの確認）\nn_samples &lt;- 1000\nn &lt;- 30 # サンプルサイズ\nmeans &lt;- numeric(n_samples)\n\nfor (i in 1:n_samples) {\n  means[i] &lt;- mean(runif(n))\n}\n\nggplot(data.frame(x = means), aes(x = x)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_histogram(bins = 30, fill = \"orange\", color = \"white\") +\n  labs(title = \"標本平均の分布 (n=30)\", x = \"標本平均\")\n\n\n\n\n\n\n\n\n母集団は平坦でも、標本平均の分布は釣鐘型（正規分布）になっています。\n\n\nサンプルサイズの影響\n\\(n\\) が大きくなるほど、分布の形状はより正規分布に近づき、かつ分散（ばらつき）が小さくなります。\n\nsample_sizes &lt;- c(5, 30, 100)\nn_samples &lt;- 2000\n\nresults &lt;- data.frame()\nfor (n in sample_sizes) {\n  # n個の平均をn_samples回計算\n  means &lt;- replicate(n_samples, mean(runif(n)))\n  results &lt;- bind_rows(results, data.frame(means = means, size = paste0(\"n=\", n)))\n}\n\n# nの順序指定\nresults$size &lt;- factor(results$size, levels = paste0(\"n=\", sample_sizes))\n\nggplot(results, aes(x = means)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  facet_wrap(~size, scales = \"free_y\") +\n  labs(title = \"中心極限定理: サンプルサイズによる標本分布の変化\", x = \"標本平均\")",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#未知の世界と鍵穴母集団と標本",
    "href": "07_sampling.html#未知の世界と鍵穴母集団と標本",
    "title": "第7回 標本分布",
    "section": "1. 未知の世界と鍵穴：母集団と標本",
    "text": "1. 未知の世界と鍵穴：母集団と標本\n私たちが本当に知りたいのは「全体」のこと。しかし、手に入るのは常に「一部」のデータだけ。\n\n母集団 (Population): 知りたい対象の全体。「未知の世界」。無限の広がりを持つ確率分布としてモデル化されます。\n標本 (Sample): そこから切り取られた一部のデータ。「鍵穴から覗いた景色」。推測の、唯一の手がかり。\n\n\n全数調査の限界\n母集団をすべて調べる「全数調査」は、コスト的にも時間的にもほぼ不可能。 すべての製品を破壊検査するわけにはいかないし、全ての消費者にアンケートを取ることもできない。 だからこそ、標本から母集団を推測する技術（推測統計学）が必要になるのです。\n\n\nランダムという名の公平性\n標本が母集団を正しく映し出すためには、ランダム標本でなければならない。 恣意的に選ばれたデータではなく、確率 \\(F(\\mu, \\sigma^2)\\) に従って選ばれた独立なデータたち。これを数学的には i.i.d. (独立同一分布) と呼びます。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#パラレルワールドの実験標本分布",
    "href": "07_sampling.html#パラレルワールドの実験標本分布",
    "title": "第7回 標本分布",
    "section": "2. パラレルワールドの実験：標本分布",
    "text": "2. パラレルワールドの実験：標本分布\nここから少し、想像力を働かせてほしい。 もし、同じ母集団から、何度も何度も標本抽出をやり直したとしたら、どうなるか？\n今回の調査では平均値が \\(50\\) だった。でも別の調査（パラレルワールド）では \\(52\\) かもしれないし、\\(48\\) かもしれない。 この「統計量（平均値など）のばらつき」を表した確率分布を、標本分布 (Sampling Distribution) と呼びます。\n現実には調査は1回しかできません。しかし、この「もし何度もやったらどうなるか」という仮想的な分布こそが、推測の精度の鍵を握っています。\nRでパラレルワールドをシミュレーションしてみましょう。\n\nlibrary(tidyverse)\nset.seed(1)\n\n# 母集団分布（平均50, 標準偏差10の正規分布）\npopulation &lt;- rnorm(100000, mean = 50, sd = 10)\n\n# パラレルワールド1：1回目の抽出（n=100）\nsample1 &lt;- sample(population, 100)\nmean(sample1)\n#&gt; [1] 50.24966\n\n# パラレルワールド2：もう1回抽出\nsample2 &lt;- sample(population, 100)\nmean(sample2)\n#&gt; [1] 50.48065\n\n毎回結果が少しずつ違う。この「ブレ」を数学的に捉えるのが目標です。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#数学的な魔法",
    "href": "07_sampling.html#数学的な魔法",
    "title": "第7回 標本分布",
    "section": "3. 数学的な魔法",
    "text": "3. 数学的な魔法\nサンプルサイズ（標本の大きさ）が増えると、2つの重要な現象が起きる。\n\n大数の法則：真実への収束\nサンプルサイズ \\(n\\) を大きくしていくと、標本平均は母平均（真の値）に限りなく近づいていく。 「数は力なり」。データが多ければ多いほど、誤差は消えていく。\n\nn &lt;- 1000\ndice_rolls &lt;- sample(1:6, n, replace = TRUE)\ncumulative_mean &lt;- cumsum(dice_rolls) / (1:n)\n\ndf &lt;- data.frame(n = 1:n, mean = cumulative_mean)\n\nggplot(df, aes(x = n, y = mean)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  geom_hline(yintercept = 3.5, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"大数の法則: 試行回数と標本平均の収束\", y = \"標本平均\")\n\n\n\n\n\n\n\n\n\n\n中心極限定理 (CLT)：混沌からの秩序\nここが統計学のハイライト。 母集団がどんなに歪な分布であっても、サンプルサイズ \\(n\\) が大きければ、その標本平均の分布は正規分布に近づいていく。\n元のデータが正規分布していなくても、平均値の分布は正規分布になる。 この定理のおかげで、私たちはあらゆるデータに対して正規分布を前提とした推測を行うことができる。\n実験：一様分布から正規分布へ 母集団として平坦な一様分布を用意し、そこから標本平均を計算する実験を行います。\n\n# 1. 一様分布のヒストグラム（母集団の形状）\nhist(runif(10000), main = \"Population (Uniform Distribution)\", xlab = \"x\")\n\n\n\n\n\n\n\n\n# 2. 標本平均の分布（CLTの確認）\nn_samples &lt;- 1000\nn &lt;- 30 # サンプルサイズ\nmeans &lt;- numeric(n_samples)\n\nfor (i in 1:n_samples) {\n  means[i] &lt;- mean(runif(n))\n}\n\nggplot(data.frame(x = means), aes(x = x)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_histogram(bins = 30, fill = \"orange\", color = \"white\") +\n  labs(title = \"標本平均の分布 (n=30)\", x = \"標本平均\")\n\n\n\n\n\n\n\n\n見事に釣鐘型（正規分布）が現れました。これが中心極限定理の威力。\n\n\nサンプルサイズと分布の鋭さ\nデータが増えると、分布はどう変化するのか。\n\nsample_sizes &lt;- c(5, 30, 100)\nn_samples &lt;- 2000\n\nresults &lt;- data.frame()\nfor (n in sample_sizes) {\n  # n個の平均をn_samples回計算\n  means &lt;- replicate(n_samples, mean(runif(n)))\n  results &lt;- bind_rows(results, data.frame(means = means, size = paste0(\"n=\", n)))\n}\n\n# nの順序指定\nresults$size &lt;- factor(results$size, levels = paste0(\"n=\", sample_sizes))\n\nggplot(results, aes(x = means)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  facet_wrap(~size, scales = \"free_y\") +\n  labs(title = \"中心極限定理: サンプルサイズによる標本分布の変化\", x = \"標本平均\")\n\n\n\n\n\n\n\n\n\\(n\\) が増えるにつれて、分布は正規分布に近づくだけでなく、その幅（ばらつき）が小さくシャープになっていく。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "07_sampling.html#信用の尺度標準誤差",
    "href": "07_sampling.html#信用の尺度標準誤差",
    "title": "第7回 標本分布",
    "section": "4. 信用の尺度：標準誤差",
    "text": "4. 信用の尺度：標準誤差\n標本平均の分布のばらつき、つまり「推測の精度」を表す指標が 標準誤差 (Standard Error, SE) 。\n\\[SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\]\nこの式は非常に重要なことを教えてくれる。 精度を上げる（SEを小さくする）には、サンプルサイズ \\(n\\) を大きくすればいい。ただし、\\(\\sqrt{n}\\) で効いてくるため、精度を2倍にするにはサンプルを4倍にする必要があります。\n\n# 理論上のSE\ntrue_se &lt;- sqrt(1/12 / 30)\n\n# シミュレーションのSE（標本平均の標準偏差）\nsim_se &lt;- sd(results %&gt;% filter(size == \"n=30\") %&gt;% pull(means))\n\ncat(\"理論的SE:\", true_se, \"\\n\")\n#&gt; 理論的SE: 0.05270463\ncat(\"シミュレーションSE:\", sim_se, \"\\n\")\n#&gt; シミュレーションSE: 0.05283213\n\n\n標準偏差(SD) vs 標準誤差(SE)\nこの2つは混同しやすいので注意してください。\n\n標準偏差 (SD): データのばらつき。「個々のデータがどれくらい散らばっているか」。\n標準誤差 (SE): 平均値のばらつき。「標本平均が真の平均からどれくらいズレうるか」。\n\n私たちが知りたい「推定の信用度」を表すのは、標準誤差のほうです。",
    "crumbs": [
      "第7回 標本分布"
    ]
  },
  {
    "objectID": "08_estimation.html#推定の基礎レシピと料理",
    "href": "08_estimation.html#推定の基礎レシピと料理",
    "title": "第8回 統計的推定",
    "section": "1. 推定の基礎：レシピと料理",
    "text": "1. 推定の基礎：レシピと料理\nまず、言葉の定義をはっきりさせておきましょう。統計的推定には、似て非なる2つの用語が登場します。\n\n推定量 (Estimator): 計算のレシピ（関数）。\n\n「データを全部足して人数で割る」という計算方法そのもの。確率的に変動します。\n\n推定値 (Estimate): 実際に作られた料理（数値）。\n\n「平均値は50.3だった」という結果。確定した数値です。\n\n\n\n良いレシピの条件\n美味しい料理（正確な推定値）を作るためには、良いレシピ（優れた推定量）が必要。統計学では、以下の要素を重視します。\n\n不偏性: 「平均的には」正解を指すこと。\n一致性: データが増えれば増えるほど、正解に近づいていくこと。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#点推定一点豪華主義",
    "href": "08_estimation.html#点推定一点豪華主義",
    "title": "第8回 統計的推定",
    "section": "2. 点推定：一点豪華主義",
    "text": "2. 点推定：一点豪華主義\n母数（知りたい真の値）を、たった一つの値で言い当てる方法です。 例えば、「日本の平均年収は450万円だ！」と言い切るのが点推定。\nTipsデータセットを使って、チップの支払総額の平均を点推定してみましょう。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# 点推定（標本平均）\nmean(tips$total_bill)\n#&gt; [1] 19.78594\n\n答えは 19.78594。これが、現時点での私たちの「ベストな予想」。 しかし、これだけでは不十分です。「で、その予想はどれくらい信用できるの？」という問いに答えられないから。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#区間推定輪投げのゲーム",
    "href": "08_estimation.html#区間推定輪投げのゲーム",
    "title": "第8回 統計的推定",
    "section": "3. 区間推定：輪投げのゲーム",
    "text": "3. 区間推定：輪投げのゲーム\nそこで登場するのが区間推定。 「平均は19.78ドルです」と言う代わりに、「平均は18.66ドルから20.91ドルの間にある確率が高い」と、幅を持たせて答える。\nこれがいわゆる信頼区間 (Confidence Interval) です。\n\n95%信頼区間の本当の意味\nよくある誤解：「真の平均値がこの区間に入る確率は95%だ」 正しくは：「この方法で輪投げ（区間推定）を100回やったら、そのうち95回は的（真の平均値）が入る」\n的（母数）は動きません。動くのは、私たちが投げる輪（信頼区間）のほう。\nシミュレーションで、実際に輪投げを100回やってみましょう。\n\nlibrary(tidyverse)\nset.seed(123)\n\n# ゲームの設定\nn_sim &lt;- 100\nn_sample &lt;- 30\nmu &lt;- 50      # 的の位置（真の母平均）\nsigma &lt;- 10   # 手ブレの大きさ（母標準偏差）\n\n# 結果の記録\nresults &lt;- data.frame(id = 1:n_sim, lower = NA, upper = NA, hit = NA)\n\nfor (i in 1:n_sim) {\n  # 1回の輪投げ（標本抽出）\n  x &lt;- rnorm(n_sample, mean = mu, sd = sigma)\n  \n  # 輪の大きさを計算（95%信頼区間）\n  test &lt;- t.test(x)\n  results$lower[i] &lt;- test$conf.int[1]\n  results$upper[i] &lt;- test$conf.int[2]\n  \n  # 的に入ったか判定\n  results$hit[i] &lt;- (mu &gt;= results$lower[i] & mu &lt;= results$upper[i])\n}\n\n# 結果発表\nggplot(results, aes(x = id, ymin = lower, ymax = upper, color = hit)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_errorbar(width = 0.5) +\n  geom_hline(yintercept = mu, linetype = \"dashed\") +\n  labs(title = \"95%信頼区間のシミュレーション (100回)\", \n       x = \"試行回数\", y = \"区間推定の結果\",\n       caption = \"赤色は的を外した失敗回\") +\n  scale_color_manual(values = c(\"TRUE\" = \"gray\", \"FALSE\" = \"red\"))\n\n\n\n\n\n\n\n\nご覧の通り、いくつかの赤い線（失敗）があります。 「95%信頼区間」とは、「長期的に見ればこれくらいの失敗率（5%）に収まるようなルールで区間を決めた」という保証書のようなもの。",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#t分布不確実性のペナルティ",
    "href": "08_estimation.html#t分布不確実性のペナルティ",
    "title": "第8回 統計的推定",
    "section": "4. t分布：不確実性のペナルティ",
    "text": "4. t分布：不確実性のペナルティ\n信頼区間を計算するとき、データ数が少ない場合はt分布という分布を使います。\nこれは「標準正規分布」によく似ていますが、少しだけ裾が広くなっています。 なぜか？\n母分散（真のばらつき）がわからないため、代わりに標本から計算した不偏分散を使うからです。 「本当のばらつきがわからない」という不確実性の分だけ、区間（輪の大きさ）を少し広めにとって安全策をとる。それが、t分布の役割。\nデータ数（サンプルサイズ）が増えれば、この不確実性は減り、t分布は正規分布に近づいていく。\n\nRで実践：平均の区間推定\nt.test() 関数を使えば、面倒な計算なしで信頼区間を求められます。\n\n# 支払総額の95%信頼区間\nt.test(tips$total_bill)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  tips$total_bill\n#&gt; t = 34.717, df = 243, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  18.66333 20.90855\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;  19.78594\n\n95 percent confidence interval の行を見てください。 これが、「今回の輪投げの結果」です。\n\n\n信頼区間の幅を決める3要素\n輪の大きさ（信頼区間の幅）は何で決まるのか？\n\n信頼係数: 「絶対に外したくない（99%）」と思えば、輪は大きくなる。\nサンプルサイズ: データが増えれば、的の位置がはっきり見えるので、輪は小さく（精度良く）なる。\nばらつき: データが暴れている（分散が大きい）と、安全のために輪を大きくする必要がある。\n\n\n# 信頼係数ごとの比較\nres_90 &lt;- t.test(tips$total_bill, conf.level = 0.90)\nres_95 &lt;- t.test(tips$total_bill, conf.level = 0.95)\nres_99 &lt;- t.test(tips$total_bill, conf.level = 0.99)\n\ndata.frame(\n  Confidence_Level = c(\"90%\", \"95%\", \"99%\"),\n  Lower = c(res_90$conf.int[1], res_95$conf.int[1], res_99$conf.int[1]),\n  Upper = c(res_90$conf.int[2], res_95$conf.int[2], res_99$conf.int[2])\n)",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#母比率の区間推定",
    "href": "08_estimation.html#母比率の区間推定",
    "title": "第8回 統計的推定",
    "section": "5. 母比率の区間推定",
    "text": "5. 母比率の区間推定\n平均値だけでなく、「割合（比率）」も区間推定できます。 「内閣支持率は 45% ± 3%」といったニュースは、これを使っています。\n例：100人中60人が賛成。母集団での賛成率は？\n\nprop.test(x = 60, n = 100)\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  60 out of 100, null probability 0.5\n#&gt; X-squared = 3.61, df = 1, p-value = 0.05743\n#&gt; alternative hypothesis: true p is not equal to 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.4970036 0.6952199\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "08_estimation.html#まとめ",
    "href": "08_estimation.html#まとめ",
    "title": "第8回 統計的推定",
    "section": "まとめ",
    "text": "まとめ\n\n\n\n\n\n\n\n\n概念\n説明\nR関数\n\n\n\n\n推定量\n計算のレシピ（関数）。\n-\n\n\n推定値\n出来上がった料理（数値）。\n-\n\n\n信頼区間\n輪投げの輪。的（母数）を捉える確率的範囲。\nt.test(), prop.test()\n\n\nt分布\nデータ不足の不確実性を考慮した、少し幅広の正規分布。\ndt(), pt()",
    "crumbs": [
      "第8回 統計的推定"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#裁判の基本ルール疑わしきは罰せず",
    "href": "09_hypothesis_1.html#裁判の基本ルール疑わしきは罰せず",
    "title": "第9回 仮説検定 (1)",
    "section": "1. 裁判の基本ルール：疑わしきは罰せず",
    "text": "1. 裁判の基本ルール：疑わしきは罰せず\n統計的検定の世界では、まず最初に「何の効果もない（無罪）」と仮定することから始めます。これを覆すだけの強力な証拠が出て初めて、「効果がある（有罪）」と認めることになる。\n\n登場人物（仮説）\n\n被告人：帰無仮説 (\\(H_0\\))\n\n「差はない」「効果はない」という、否定したい仮説。\n裁判で言えば「被告人は無罪である」という前提。\n\n検察官：対立仮説 (\\(H_1\\))\n\n「差がある」「効果がある」という、証明したい仮説。\n裁判で言えば「被告人は有罪である」という主張。\n\n\n検定のゴールは、「無罪（\\(H_0\\)）と仮定するには、証拠（データ）が不自然すぎる」ことを示し、無罪の前提を棄却すること。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#証拠の評価p値という驚き",
    "href": "09_hypothesis_1.html#証拠の評価p値という驚き",
    "title": "第9回 仮説検定 (1)",
    "section": "2. 証拠の評価：p値という驚き",
    "text": "2. 証拠の評価：p値という驚き\n裁判官であるあなたは、提出された証拠（データ）を見て判断する。 ここで重要なのが p値 (p-value) 。\np値とは、「もし被告人が無罪だとしたら、こんな証拠が出てくる確率はどれくらいか？」という値。\n\np値が大きい（0.5とか）: 「無罪の人からも、よく出る証拠だ」。\n\n判決：無罪を棄却できない（証拠不十分）。\n\np値が極めて小さい（0.001とか）: 「無罪だとしたら、こんな証拠が出るのはありえない（奇跡に近い）」。\n\n判決：無罪ではないだろう。有罪（有意）！\n\n\n\n判決の基準：有意水準 (\\(\\alpha\\))\nどこまで確率が低ければ「ありえない」と判断するのか？ その基準を有意水準と呼び、通常 5% (0.05) に設定します。\n\n「無罪なのにこんな証拠が出る確率は5%未満」なら、それはもう偶然とは考えない。\nこの基準を超えたとき、「統計的に有意である (Statistically Significant)」 と宣言します。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#シミュレーション無罪の証明",
    "href": "09_hypothesis_1.html#シミュレーション無罪の証明",
    "title": "第9回 仮説検定 (1)",
    "section": "3. シミュレーション：無罪の証明",
    "text": "3. シミュレーション：無罪の証明\nt分布を使って、「無罪（偶然）」の範囲を可視化してみましょう。\n\nlibrary(tidyverse)\n# theme_set(theme_gray(base_family = \"HiraKakuProN-W3\")) # [対象注意] Mac用設定\n\n# t分布 (自由度9)\nx &lt;- seq(-4, 4, length.out = 100)\ny &lt;- dt(x, df = 9)\ndf_t &lt;- data.frame(x, y)\n\n# 判決のライン（有意水準5%の両側）\ncritical_val &lt;- qt(0.975, df = 9)\n\nggplot(df_t, aes(x = x, y = y)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_line() +\n  geom_area(data = filter(df_t, x &gt; critical_val), fill = \"red\", alpha = 0.5) +\n  geom_area(data = filter(df_t, x &lt; -critical_val), fill = \"red\", alpha = 0.5) +\n  geom_vline(xintercept = c(critical_val, -critical_val), linetype = \"dashed\") +\n  labs(title = \"有罪判決のライン (棄却域)\", x = \"検定統計量 (t値)\", y = \"確率密度\")\n\n\n\n\n\n\n\n\n赤いエリアが「有罪（棄却域）」。データから計算したt値がここに入れば、「無罪」の前提は棄却されます。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#実践1標本のt検定",
    "href": "09_hypothesis_1.html#実践1標本のt検定",
    "title": "第9回 仮説検定 (1)",
    "section": "4. 実践：1標本のt検定",
    "text": "4. 実践：1標本のt検定\n実際の事件（データ）を裁いてみましょう。\n事件: あるクラス10人のテスト平均点は、全国平均の「50点」と違うのか？ scores &lt;- c(55, 60, 45, 70, 58, 62, 48, 52, 65, 50)\n\n帰無仮説 (\\(H_0\\)): 平均点に違いはない（\\(\\mu = 50\\)）。\n対立仮説 (\\(H_1\\)): 平均点に違いがある（\\(\\mu \\neq 50\\)）。\n\n\nscores &lt;- c(55, 60, 45, 70, 58, 62, 48, 52, 65, 50)\nt.test(scores, mu = 50)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  scores\n#&gt; t = 2.5862, df = 9, p-value = 0.02939\n#&gt; alternative hypothesis: true mean is not equal to 50\n#&gt; 95 percent confidence interval:\n#&gt;  50.81453 62.18547\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;      56.5\n\n判決: p値は 0.02939 。これは 0.05（5%）より小さい。 つまり、「平均50点の集団から、偶然この点数が取れる確率は約2.9%しかない」。 裁判官（あなた）は、「偶然にしては出来すぎている」と判断し、帰無仮説を棄却します。\n結論：このクラスの平均点は、全国平均と有意に異なる。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#冤罪のリスク2つの過誤",
    "href": "09_hypothesis_1.html#冤罪のリスク2つの過誤",
    "title": "第9回 仮説検定 (1)",
    "section": "5. 冤罪のリスク：2つの過誤",
    "text": "5. 冤罪のリスク：2つの過誤\n裁判に誤審があるように、統計的検定にも誤りのリスクがあります。\n\n\n\n\n\n\n\n\n\n被告人は無実 (\\(H_0\\) 真)\n被告人はクロ (\\(H_1\\) 真)\n\n\n\n\n有罪判決 (\\(H_0\\) 棄却)\n冤罪 (第1種の過誤)何も無いのに「ある」と言う確率 \\(\\alpha\\) (5%)\n正しい判決\n\n\n無罪判決 (\\(H_0\\) 棄却せず)\n正しい判決\n取り逃がし (第2種の過誤)あるのに「ない」と言う確率 \\(\\beta\\)\n\n\n\n我々が設定した「有意水準5%」とは、「5%の確率で冤罪（第1種の過誤）を起こすことを許容する」という宣言でもある。 だからこそ、p値が小さいことは「絶対の真実」ではなく、「かなり確からしい」という程度の意味なのだ。",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "09_hypothesis_1.html#まとめ",
    "href": "09_hypothesis_1.html#まとめ",
    "title": "第9回 仮説検定 (1)",
    "section": "まとめ",
    "text": "まとめ\n\n\n\n\n\n\n\n\n裁判用語\n統計用語\n意味\n\n\n\n\n被告人は無罪\n帰無仮説 (\\(H_0\\))\n「差はない」という前提\n\n\n被告人は有罪\n対立仮説 (\\(H_1\\))\n「差がある」という主張\n\n\n証拠の不自然さ\np値\n無罪前提でそのデータが出る確率\n\n\n判決の基準\n有意水準 (\\(\\alpha\\))\np値がこれ未満なら有罪（棄却）\n\n\n冤罪\n第1種の過誤\n無罪なのに有罪にしてしまうミス",
    "crumbs": [
      "第9回 仮説検定 (1)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#つの島を比べる対応のないt検定",
    "href": "10_hypothesis_2.html#つの島を比べる対応のないt検定",
    "title": "第10回 仮説検定 (2)",
    "section": "1. 2つの島を比べる：対応のないt検定",
    "text": "1. 2つの島を比べる：対応のないt検定\nまずは、全く別々の2つのグループを比較するケース。 例えば、「ランチ島」に住む人々と、「ディナー島」に住む人々。 彼らの支払金額に差はあるのか？\nこのように、互いに独立したデータを比較する手法を対応のないt検定 (Unpaired t-test) と呼ぶ。\n\n地形を選ばない万能車：Welchのt検定\n2つの島（グループ）は、地形（データのばらつき＝分散）が同じとは限らない。 昔の教科書には「まず地形が同じか調べて（F検定）、それから車を選べ」と書いてあった。\nしかし、現代の統計学ではWelchのt検定という「全地形対応車」を最初から使うのが常識。 これなら、分散が違っていても安全に走行（検定）できる。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# 箱ひげ図：2つの島の地形確認\nggplot(tips, aes(x = time, y = total_bill, fill = time)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_boxplot() +\n  labs(title = \"ランチとディナーの支払総額比較\")\n\n\n\n\n\n\n\n\n# Welchのt検定（デフォルトで適用されます）\nt.test(total_bill ~ time, data = tips)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  total_bill by time\n#&gt; t = 3.123, df = 143.29, p-value = 0.002167\n#&gt; alternative hypothesis: true difference in means between group Dinner and group Lunch is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  1.331877 5.925088\n#&gt; sample estimates:\n#&gt; mean in group Dinner  mean in group Lunch \n#&gt;             20.79716             17.16868\n\n判定: p値は約 0.002。これは「差がないとしたら、こんなデータは0.2%の確率でしか起きない」ことを意味する。 偶然とは考えにくい。つまり、ランチとディナーには有意な差があると結論づける。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#ビフォーアフター対応のあるt検定",
    "href": "10_hypothesis_2.html#ビフォーアフター対応のあるt検定",
    "title": "第10回 仮説検定 (2)",
    "section": "2. ビフォー・アフター：対応のあるt検定",
    "text": "2. ビフォー・アフター：対応のあるt検定\n次は、同じ人が「変身」するケース。 ダイエット前とダイエット後。テスト勉強前と勉強後。\nここでは、グループ全体の平均を見るのではなく、「一人ひとりの変化（差分）」に注目する。 これを対応のあるt検定 (Paired t-test) と呼ぶ。\n\n変化を捕まえる\n同じ人のデータを追跡することで、個人の「もともとの性質」をキャンセルし、純粋な「変化」だけを取り出すことができる。\n\n# 5人のダイエット記録\nbefore &lt;- c(70, 80, 75, 60, 65)\nafter  &lt;- c(68, 78, 74, 58, 64)\n\n# paired = TRUE で「対応あり」を指定\nt.test(before, after, paired = TRUE)\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  before and after\n#&gt; t = 6.532, df = 4, p-value = 0.002838\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.9199126 2.2800874\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;             1.6\n\n事実確認: もしこれを「対応なし（別人のデータ）」として分析してしまうと、p値は 0.75 になり、「差なし」と判定されてしまう。 対応のある検定を使うことで初めて、微小な変化（-1.6kg）を「有意」として検出できるのだ。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#その差はどれくらい凄いのか効果量",
    "href": "10_hypothesis_2.html#その差はどれくらい凄いのか効果量",
    "title": "第10回 仮説検定 (2)",
    "section": "3. その差は、どれくらい凄いのか？：効果量",
    "text": "3. その差は、どれくらい凄いのか？：効果量\np値が小さいことは、「偶然ではない」ことを保証するだけ。 「すごい差がある」ことの証明ではない。\n1万人調査すれば、0.1ミリの身長差でも「有意差あり（p &lt; 0.05）」になる。でも、0.1ミリに意味はあるか？\nそこで必要なのが、差の実質的な大きさを表す「スコア」、すなわち効果量 (Effect Size) 。 代表的なスコアである Cohen’s d を使おう。\n\nシグナルの強さを測る\n\\[Cohen's \\ d = \\frac{\\text{平均値の差}}{\\text{標準偏差（ばらつき）}}\\]\nこれは、「データのばらつき（ノイズ）」に対して、「平均値の差（シグナル）」がどれくらい突き抜けているかを表す。\n\n0.2: 小さい（ノイズに埋もれがち）\n0.5: 中くらい（肉眼でもなんとなく分かる）\n0.8: 大きい（誰が見ても明らか）\n\n\n# ランチとディナーの差のスコア（Cohen's d）\nd_val &lt;- (mean(tips$total_bill[tips$time==\"Dinner\"]) - mean(tips$total_bill[tips$time==\"Lunch\"])) /\n         sd(tips$total_bill)\n\nd_val\n#&gt; [1] 0.4075842\n\nスコアは約 0.41。中程度の効果だ。 「この差は統計的に有意であり、実質的にも中程度の意味がある」と、胸を張って報告しよう。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#まとめ",
    "href": "10_hypothesis_2.html#まとめ",
    "title": "第10回 仮説検定 (2)",
    "section": "まとめ",
    "text": "まとめ\n\n\n\n\n\n\n\n\n検定手法\n適用場面\nキャッチコピー\n\n\n\n\nWelchのt検定\n独立した2群\n全地形対応の万能車。デフォルトはこれ。\n\n\n対応のあるt検定\n同一ペアの比較\n変化（差分）狙い撃ち。検出力高め。\n\n\n効果量 (Cohen’s d)\n関係性の強さ\np値に頼らない、実力のスコア。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#課題-1",
    "href": "10_hypothesis_2.html#課題-1",
    "title": "第10回 仮説検定 (2)",
    "section": "課題",
    "text": "課題\n\n喫煙の有無とチップ: tips データを使って、喫煙者 (Smoker) と非喫煙者 (Non-Smoker) で、チップの額 (tip) に差があるかを検定してください（Welchのt検定）。 また、その差の効果量 (Cohen’s d) を計算し、統計的有意性と実質的意味について論じてください。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#練習問題-1",
    "href": "10_hypothesis_2.html#練習問題-1",
    "title": "第10回 仮説検定 (2)",
    "section": "練習問題",
    "text": "練習問題\n\n練習1: 検定の選択\n以下のシナリオにおいて、最も適切な検定手法（対応ありt検定 / 対応なし(Welch)t検定）を選んでください。\n\nA組30人とB組30人のテストの平均点の比較。\n高血圧患者30人の、降圧剤投与前と投与後の血圧の比較。\n10組の双子における、兄と弟の身長の比較。\n\n\n\n練習2: サンプルサイズとp値\n効果量 \\(d=0.5\\) （中程度）の差がある2つの母集団から、 (a) \\(n=10\\) ずつ (b) \\(n=100\\) ずつ データを抽出し、t検定を行った場合のp値をシミュレーションで比較してください。サンプルサイズがp値に与える影響を確認します。\n\n\n練習3: 等分散性の確認はいらない？\n「まずF検定をしてからt検定の種類を選ぶ」という手順が、現在では推奨されない理由を自分の言葉で説明してください。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "10_hypothesis_2.html#まとめ-1",
    "href": "10_hypothesis_2.html#まとめ-1",
    "title": "第10回 仮説検定 (2)",
    "section": "まとめ",
    "text": "まとめ\n\n\n\n\n\n\n\n\n\n検定手法\n適用場面\nRコード\n備考\n\n\n\n\nWelchのt検定\n独立した2群の比較\nt.test(y ~ x)\nデフォルト。等分散を仮定しない。\n\n\n対応のあるt検定\n同一対象・ペアの比較\nt.test(y1, y2, paired=TRUE)\n差分の1標本検定と等価。検出力が高い。\n\n\n効果量 (Cohen’s d)\n差の実質的な大きさ\n(計算式参照)\nサンプルサイズに依存しない指標。",
    "crumbs": [
      "第10回 仮説検定 (2)"
    ]
  },
  {
    "objectID": "11_regression_1.html#人のダンス相関-correlation",
    "href": "11_regression_1.html#人のダンス相関-correlation",
    "title": "第11回 相関と単回帰分析",
    "section": "1. 2人のダンス：相関 (Correlation)",
    "text": "1. 2人のダンス：相関 (Correlation)\n予測の第一歩は、「2つのデータに関係があるか？」を知ること。 これを相関と呼ぶ。\nイメージしてほしい。2人のダンサーが踊っている。 片方が右に動いたとき、もう片方も必ず右に動くなら、2人の息はピッタリだ（強い正の相関）。 バラバラに動いているなら、関係はない（無相関）。\nこの「息の合い具合」を数値化したのが 相関係数 \\(r\\) 。\n\n\\(r = 1\\): 完全なシンクロ（正）。\n\\(r = -1\\): 正反対の動き（負）。\n\\(r = 0\\): 全くの無関係。\n\n\n実践: 支払額とチップの関係\n「支払額 (\\(X\\)) が多い客ほど、チップ (\\(Y\\)) も多く払うのか？」を確認してみよう。\n\nlibrary(tidyverse)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# 相関係数の算出\ncor(tips$total_bill, tips$tip)\n#&gt; [1] 0.6757341\n\n# 検定: その相関は偶然ではないか？\ncor.test(tips$total_bill, tips$tip)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  tips$total_bill and tips$tip\n#&gt; t = 14.26, df = 242, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.6011647 0.7386372\n#&gt; sample estimates:\n#&gt;       cor \n#&gt; 0.6757341\n\n結果は \\(r \\approx 0.68\\)。 「かなり息が合っている（強い正の相関）」と言える。支払額が増えれば、チップも増える傾向がはっきりとある。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#予測マシンを作る単回帰分析",
    "href": "11_regression_1.html#予測マシンを作る単回帰分析",
    "title": "第11回 相関と単回帰分析",
    "section": "2. 予測マシンを作る：単回帰分析",
    "text": "2. 予測マシンを作る：単回帰分析\n相関があることが分かったら、次は具体的に予測をする。 「支払いが10ドル増えたら、チップはいくら増えるの？」\nこの問いに答えるために、データの真ん中を貫く「運命の赤い糸（回帰直線）」を引く。 この直線の式が、私たちの予測マシンになる。\n\\[ \\text{予測値} = \\text{切片} + \\text{傾き} \\times \\text{支払額} \\]\n\n交換レートとしての「傾き」\nここで最も重要なのが 傾き (\\(\\beta_1\\)) 。 これは、\\(X\\) と \\(Y\\) の交換レートのようなもの。 「支払額を1ドル投入すると、チップが何ドル返ってくるか？」を表す。\n\n# 予測モデルの作成\nmodel &lt;- lm(tip ~ total_bill, data = tips)\nsummary(model)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.1982 -0.5652 -0.0974  0.4863  3.7434 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 0.920270   0.159735   5.761 2.53e-08 ***\n#&gt; total_bill  0.105025   0.007365  14.260  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.022 on 242 degrees of freedom\n#&gt; Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 \n#&gt; F-statistic: 203.4 on 1 and 242 DF,  p-value: &lt; 2.2e-16\n\n解析結果: - 傾き (Estimate of total_bill): 0.105\nこれは、「支払額が1ドル増えるごとに、チップは約10.5セント増える」 という法則を表している。 これさえ分かれば、まだ見ぬ客のチップ額も予測できる。\n\n\n直線の可視化\n\nggplot(tips, aes(x = total_bill, y = tip)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"予測マシン（回帰直線）の可視化\")\n\n\n\n\n\n\n\n\n赤い線が、推定された予測モデルだ。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#モデルの品質チェック残差診断",
    "href": "11_regression_1.html#モデルの品質チェック残差診断",
    "title": "第11回 相関と単回帰分析",
    "section": "3. モデルの品質チェック：残差診断",
    "text": "3. モデルの品質チェック：残差診断\nモデルを作って終わりではない。 「この予測マシンは本当に優秀か？」をチェックする必要がある。\n注目するのは、予測と実測のズレ、すなわち 残差 (Residuals) 。 完璧なモデルなら、残差は単なる「ランダムなノイズ」になる。もし残差に何らかのパターン（癖）が残っていたら、モデルはまだ何か重要な情報を見落としていることになる。\n\n決定係数 (\\(R^2\\)): 説明力\nまず、このモデルがデータのバラつきの何％を説明できたかを確認する。\n\nMultiple R-squared: 0.4566\n\n「チップの変動の約46%は、支払額の違いで説明できる」\n残りの54%は、支払額以外の要因（客の気前の良さや接客態度など）。\n\n\n\n\n残差の健康診断\nモデル変な癖がないか、レントゲン（残差プロット）を撮って確認する。\n\n# 予測値と残差の準備\ntips_aug &lt;- tips %&gt;%\n  mutate(pred = predict(model), resid = residuals(model))\n\n# 1. 残差プロット（クセがないか？）\np1 &lt;- ggplot(tips_aug, aes(x = pred, y = resid)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"残差の散らばり\")\n\n# 2. Q-Qプロット（正規分布しているか？）\np2 &lt;- ggplot(tips_aug, aes(sample = resid)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"残差の正規性\")\n\n# 並べて表示\np1\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\n\n\n残差プロット: 0の周りにバランスよく散らばっていれば合格。\nQ-Qプロット: 赤い線の上に並んでいれば合格。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "11_regression_1.html#まとめ",
    "href": "11_regression_1.html#まとめ",
    "title": "第11回 相関と単回帰分析",
    "section": "まとめ",
    "text": "まとめ\n\n\n\n\n\n\n\n\n概念\nアナロジー\n意味\n\n\n\n\n相関\nダンスのシンクロ率\n2つの変数の動きの連動性。\n\n\n回帰直線\n予測マシン\n\\(X\\) から \\(Y\\) を弾き出す数式。\n\n\n傾き (\\(\\beta_1\\))\n交換レート\n\\(X\\) が1増えると \\(Y\\) がどれだけ増えるか。\n\n\n残差\n削りカス\nモデルが説明しきれなかったノイズ。\n\n\n決定係数 (\\(R^2\\))\nテストの点数\nモデルがどれくらい優秀かのスコア (0-1)。",
    "crumbs": [
      "第11回 相関と単回帰分析"
    ]
  },
  {
    "objectID": "12_regression_2.html#複数のツマミを操る重回帰分析",
    "href": "12_regression_2.html#複数のツマミを操る重回帰分析",
    "title": "第12回 重回帰分析と因果推論",
    "section": "1. 複数のツマミを操る：重回帰分析",
    "text": "1. 複数のツマミを操る：重回帰分析\nデータ分析を「ミキシングコンソール」の操作だと想像してほしい。 単回帰分析は「ボリューム」という一つのツマミしか持たなかった。 重回帰分析では、「ボリューム」「低音」「高音」など、複数のツマミ（説明変数）を同時に操作して、最適なサウンド（予測）を作り出す。\n\\[ \\text{結果} \\ (Y) = \\text{切片} + (\\beta_1 \\times \\text{要因1}) + (\\beta_2 \\times \\text{要因2}) + \\dots + \\text{誤差} \\]\n\n「他を固定して」見る技術 (Ceteris Paribus)\n重回帰分析の凄さは、「他の条件が同じならば」 という仮定を数式の中で実現できる点にある。\n例えば、チップ額 (\\(Y\\)) を支払額 (\\(X_1\\)) と客数 (\\(X_2\\)) で説明する場合：\n係数 \\(\\beta_1\\) は、「客数が同じグループの中で比べたとき、支払額が1ドル増えるとチップはどうなるか」を表す。\nあたかも実験室で条件を統制したかのように、純粋な効果を取り出せるのだ。\n\n\n実践: 支払いと人数の分離\n\nlibrary(tidyverse)\nlibrary(broom)\nurl &lt;- \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips &lt;- read_csv(url)\n\n# 重回帰モデル：チップを「支払額」と「人数」で説明する\nmodel_multi &lt;- lm(tip ~ total_bill + size, data = tips)\nsummary(model_multi)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill + size, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.9279 -0.5547 -0.0852  0.5095  4.0425 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 0.668945   0.193609   3.455  0.00065 ***\n#&gt; total_bill  0.092713   0.009115  10.172  &lt; 2e-16 ***\n#&gt; size        0.192598   0.085315   2.258  0.02487 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.014 on 241 degrees of freedom\n#&gt; Multiple R-squared:  0.4679, Adjusted R-squared:  0.4635 \n#&gt; F-statistic: 105.9 on 2 and 241 DF,  p-value: &lt; 2.2e-16\n\n解釈: - total_bill: 0.093 - 「もし人数が同じなら」、支払いが1ドル増えるごとにチップは約9.3セント増える。 - size: 0.193 - 「もし支払額が同じなら」、人数が1人増えるごとにチップは約19.3セント増える。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#実践的モデリング",
    "href": "12_regression_2.html#実践的モデリング",
    "title": "第12回 重回帰分析と因果推論",
    "section": "2. 実践的モデリング",
    "text": "2. 実践的モデリング\n現実は数値データだけではない。「性別」や「曜日」といった文字データ（カテゴリ変数）も分析に使える。\n\nダミー変数：スイッチのON/OFF\n「喫煙席か？」のような情報は、計算できるよう 0 (No) と 1 (Yes) に変換する。これをダミー変数と呼ぶ。\n\n# 喫煙者ダミー（Yes/No）を追加\nmodel_dummy &lt;- lm(tip ~ total_bill + size + smoker, data = tips)\ntidy(model_dummy)\n\n\n  \n\n\n\nsmokerYes の係数は、喫煙席に座ることで生じる「上乗せ分」を表す。\n\n\n交互作用：「相乗効果」に気づく\n「ビールと枝豆」のように、組み合わせることで効果が変わることもある。 例えば、「喫煙者の方が、支払額に対するチップの払いっぷりが良い（傾きが急）」かもしれない。\n\n# : は交互作用のみ、* は主効果＋交互作用\nmodel_inter &lt;- lm(tip ~ total_bill * smoker, data = tips)\nsummary(model_inter)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = tip ~ total_bill * smoker, data = tips)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.6789 -0.5238 -0.1205  0.4749  4.8999 \n#&gt; \n#&gt; Coefficients:\n#&gt;                       Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           0.360069   0.202058   1.782 0.076012 .  \n#&gt; total_bill            0.137156   0.009678  14.172  &lt; 2e-16 ***\n#&gt; smokerYes             1.204203   0.312263   3.856 0.000148 ***\n#&gt; total_bill:smokerYes -0.067566   0.014189  -4.762 3.32e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9785 on 240 degrees of freedom\n#&gt; Multiple R-squared:  0.506,  Adjusted R-squared:  0.4998 \n#&gt; F-statistic: 81.95 on 3 and 240 DF,  p-value: &lt; 2.2e-16\n\ntotal_bill:smokerYes が有意なら、2つの要因には相乗効果（あるいは相殺効果）があると言える。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#真犯人を探せ因果推論とバイアス",
    "href": "12_regression_2.html#真犯人を探せ因果推論とバイアス",
    "title": "第12回 重回帰分析と因果推論",
    "section": "3. 真犯人を探せ：因果推論とバイアス",
    "text": "3. 真犯人を探せ：因果推論とバイアス\n「相関関係があっても因果関係とは限らない」。耳にタコができるほど聞いた言葉だが、その正体は何だろうか？ 最大の原因は、交絡因子（こうらくいんし） という「裏で糸を引く黒幕」の存在だ。\n\n典型例：教育と賃金のミステリー\n「高学歴な人は給料が高い」というデータがある。 しかし、これは純粋に教育のおかげだろうか？ もしかすると、「元々の能力が高い人」が「高学歴になりやすく」、かつ「給料も高い」だけかもしれない。\nこの「能力」こそが交絡因子だ。これを無視して分析すると、教育の効果を過大評価してしまう（除外変数バイアス）。\n\n\nシミュレーション：バイアスの除去\n重回帰分析を使えば、この黒幕（交絡因子）を表舞台に引きずり出し、無力化できる。\n\nset.seed(123)\nn &lt;- 200\n# 真実はこうだ：\nability &lt;- rnorm(n, 100, 15) # 能力（黒幕）\neducation &lt;- 12 + 0.05 * ability + rnorm(n, 0, 2) # 能力が高いと教育も長い\nwage &lt;- 20 + 2 * education + 0.3 * ability + rnorm(n, 0, 5) # 賃金は両方で決まる\n\nsim_data &lt;- tibble(wage, education, ability)\n\n# 1. 失敗：黒幕（能力）を無視\nlm(wage ~ education, data = sim_data) %&gt;% coef()\n#&gt; (Intercept)   education \n#&gt;   41.674916    2.494524\n\n# 2. 成功：黒幕をモデルに入れてコントロール\nlm(wage ~ education + ability, data = sim_data) %&gt;% coef()\n#&gt; (Intercept)   education     ability \n#&gt;  22.7681915   1.8733537   0.2955295\n\n能力をモデルに加えることで、教育の係数は真の値（2.0）に近づく。 重回帰分析は、予測だけでなく、偏りのない因果推論を行うための強力なツールなのだ。",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#良いモデルの選び方",
    "href": "12_regression_2.html#良いモデルの選び方",
    "title": "第12回 重回帰分析と因果推論",
    "section": "4. 良いモデルの選び方",
    "text": "4. 良いモデルの選び方\n変数を増やせば増やすほどモデルは現実に合致していくが、やりすぎは禁物。\n\n多重共線性（マルチコ）：似た者同士の喧嘩\n似たような変数（例：身長と座高）を両方入れると、お互いが邪魔をし合って、係数の推定がおかしくなる。 VIF という指標チェックし、10を超えていたら要注意。\n\nlibrary(car)\nvif(model_multi)\n#&gt; total_bill       size \n#&gt;   1.557586   1.557586\n\n\n\n調整済み決定係数：シンプルさへのボーナス\n通常の決定係数 \\(R^2\\) は、無駄な変数を足しても増えてしまう。 「変数の数」のペナルティを加味した 調整済み決定係数 (Adjusted \\(R^2\\)) を使おう。 情報量規準 AIC や BIC も、シンプルで高性能なモデルを選ぶための指標だ。\n\n# 調整済みR²の比較\nmodel_simple &lt;- lm(tip ~ total_bill, data = tips) # 単回帰モデルの再定義\n\nmodels &lt;- list(\n  \"Simple\" = model_simple,\n  \"Multi\" = model_multi,\n  \"Dummy\" = model_dummy\n)\nsapply(models, function(m) summary(m)$adj.r.squared)\n#&gt;    Simple     Multi     Dummy \n#&gt; 0.4543712 0.4634533 0.4620370",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  },
  {
    "objectID": "12_regression_2.html#係数の可視化",
    "href": "12_regression_2.html#係数の可視化",
    "title": "第12回 重回帰分析と因果推論",
    "section": "係数の可視化",
    "text": "係数の可視化\n数字の羅列を見るよりも、グラフで可視化したほうが直感的に理解できる。\n\ntheme_set(theme_gray(base_family = \"HiraKakuProN-W3\")) # [対象注意] Mac用設定\n\ntidy(model_dummy, conf.int = TRUE) %&gt;%\n  filter(term != \"(Intercept)\") %&gt;%\n  ggplot(aes(x = estimate, y = term)) +\n  theme_gray(base_family = \"HiraKakuProN-W3\") + # [対象注意] Mac用設定\n  geom_point() +\n  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"重回帰分析の係数プロット\")",
    "crumbs": [
      "第12回 重回帰分析と因果推論"
    ]
  }
]